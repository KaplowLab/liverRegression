{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7a68dfd-ce12-4a64-ae68-cb6343fd342b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Correlating foldchange model predictions with real signal values.\n",
    "\n",
    "This notebook evaluates the accuracy of inter-species accessibility fold-change predictions. Performance is assessed by comparing the predicted difference between two species against the real signal difference at orthologous regions.\n",
    "\n",
    "$\\text{Foldchange} = \\Delta \\text{Accessibility} = \\text{Value}_{\\text{Species A}} - \\text{Value}_{\\text{Species B}}$\n",
    "\n",
    "### Correlation Analysis: \n",
    "Measures linear (Pearson $r$) and rank-based (Spearman $\\rho$) relationships. Uses Mean Squared Error (MSE) to measure prediction deviation. Organizes performance metrics by Species and Group (e.g., Test sets).\n",
    "\n",
    "### Example output table \n",
    "\n",
    "| Species | Group | Metric | Model ID |\n",
    "|:--- | :--- | :--- | :--- |\n",
    "| Cow | Val2 | Same Sign Count | 2001 |\n",
    "| Cow | Val2 | Total Count | 3302 |\n",
    "| Cow | Val2 | Same Sign % | 0.606 |\n",
    "| Cow | Val2 | Pearson ($r$) | 0.259 |\n",
    "| Cow | Val2 | Pearson $p$-val | $2.3 \\times 10^{-82}$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92062342-24d1-478e-94d5-8fa8a9e8ab86",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def pearson_spearman(x, y):\n",
    "    pearson_corr, pearson_p_value = scipy.stats.pearsonr(x, y)\n",
    "    print(f\"Pearson correlation coefficient: {pearson_corr:.3f}, p-value: {pearson_p_value:.3g}\")\n",
    "\n",
    "    spearman_corr, spearman_p_value = scipy.stats.spearmanr(x, y)\n",
    "    print(f\"Spearman correlation coefficient: {spearman_corr:.3f}, p-value: {spearman_p_value:.3g}\")\n",
    "    \n",
    "def collapse_if_identical(lst):\n",
    "    return lst[0] if all(x == lst[0] for x in lst) else lst\n",
    "    \n",
    "\n",
    "# takes in list and returns peak with largest signal\n",
    "def keep_largest_signal(lst, qn_df):\n",
    "    if isinstance(lst, list):\n",
    "        maxPeakName = ''\n",
    "        maxPeakStrength = 0\n",
    "        for peak in lst:\n",
    "            matching_rows = qn_df[qn_df[3] == peak]\n",
    "            if not matching_rows.empty:\n",
    "                signal = matching_rows[4].iloc[0]\n",
    "                if signal > maxPeakStrength:\n",
    "                    maxPeakStrength = signal\n",
    "                    maxPeakName = peak\n",
    "        return maxPeakName\n",
    "    else: \n",
    "        return lst\n",
    "\n",
    "def get_biggest_overlap(lst, col, df):\n",
    "    maxOverlap = 0\n",
    "    maxPeakOverlap = \"\"\n",
    "    for peak in lst:\n",
    "        row = df[df[col] == peak].iloc[0] #iloc bc possible to return multiple rows (never will based on th\n",
    "        overlap = max(0, min(row[2], row[12])-max(row[1], row[11]))\n",
    "        if overlap > maxOverlap:\n",
    "            maxOverlap = overlap\n",
    "            maxPeakOverlap = peak\n",
    "    return peak\n",
    "\n",
    "def mean_squared_error(x, y):\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    return np.mean((x - y) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4913d5ac-4f66-4fed-8db4-3a06c677a4b9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## One-to-one OCR Matched Generation\n",
    "Example below is between macaque and mouse:\n",
    "\n",
    "The matching algorithm for orthologous regions between macaque and mouse is as follows: \n",
    "1. If regions have a unique 1 to 1 overlap, done.\n",
    "2. If there are multiple overlaps, select the pair with the largest overlap.\n",
    "3. If overlap sizes are equal, select the pair with the highest signal value.\n",
    "\n",
    "Example Output:\n",
    "\n",
    "Note Mac2Mou are the coordinates of macaque OCRs mapped to the Mouse genome.\n",
    "\n",
    "| Index | Mac2Mou_Chr | Mac2Mou_Start | Mac2Mou_End | Mac_Peak_Name | Score1 | Dot | - | - | - | Mac2Mou_Peak | Mou_Chr | Mou_Start | Mou_End | Mou_Peak_Name | Score2 | Dot2 | - | - | - | Mou_Peak |\n",
    "| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n",
    "| 0 | chr9 | 6668262 | 6668828 | peak24458 | -1 | . | -1 | -1 | -1 | 370 | chr9 | 6668246 | 6669123 | peak20464 | 1000 | . | 10.41801 | 106.9844 | 104.00175 | 372 |\n",
    "| 1 | chr9 | 7603389 | 7603594 | peak64793 | -1 | . | -1 | -1 | -1 | 114 | chr9 | 7603184 | 7603794 | peak20478 | 1000 | . | 18.10567 | 247.4437 | 243.99432 | 315 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "139b49d8-4225-4ec6-9714-81c4622d9ca7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr9</td>\n",
       "      <td>6668262</td>\n",
       "      <td>6668828</td>\n",
       "      <td>peak24458</td>\n",
       "      <td>-1</td>\n",
       "      <td>.</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>370</td>\n",
       "      <td>chr9</td>\n",
       "      <td>6668246</td>\n",
       "      <td>6669123</td>\n",
       "      <td>peak20464</td>\n",
       "      <td>1000</td>\n",
       "      <td>.</td>\n",
       "      <td>10.41801</td>\n",
       "      <td>106.98440</td>\n",
       "      <td>104.00175</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr9</td>\n",
       "      <td>7603389</td>\n",
       "      <td>7603594</td>\n",
       "      <td>peak64793</td>\n",
       "      <td>-1</td>\n",
       "      <td>.</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>114</td>\n",
       "      <td>chr9</td>\n",
       "      <td>7603184</td>\n",
       "      <td>7603794</td>\n",
       "      <td>peak20478</td>\n",
       "      <td>1000</td>\n",
       "      <td>.</td>\n",
       "      <td>18.10567</td>\n",
       "      <td>247.44370</td>\n",
       "      <td>243.99432</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr9</td>\n",
       "      <td>7914492</td>\n",
       "      <td>7914988</td>\n",
       "      <td>peak729</td>\n",
       "      <td>-1</td>\n",
       "      <td>.</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>141</td>\n",
       "      <td>chr9</td>\n",
       "      <td>7914173</td>\n",
       "      <td>7914971</td>\n",
       "      <td>peak20484</td>\n",
       "      <td>1000</td>\n",
       "      <td>.</td>\n",
       "      <td>15.21739</td>\n",
       "      <td>160.17427</td>\n",
       "      <td>156.98676</td>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr8</td>\n",
       "      <td>8733638</td>\n",
       "      <td>8734157</td>\n",
       "      <td>peak30058</td>\n",
       "      <td>-1</td>\n",
       "      <td>.</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>379</td>\n",
       "      <td>chr8</td>\n",
       "      <td>8733751</td>\n",
       "      <td>8734148</td>\n",
       "      <td>peak19418</td>\n",
       "      <td>1000</td>\n",
       "      <td>.</td>\n",
       "      <td>12.36603</td>\n",
       "      <td>110.58308</td>\n",
       "      <td>107.58508</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr8</td>\n",
       "      <td>8992445</td>\n",
       "      <td>8993220</td>\n",
       "      <td>peak5261</td>\n",
       "      <td>-1</td>\n",
       "      <td>.</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>506</td>\n",
       "      <td>chr8</td>\n",
       "      <td>8992509</td>\n",
       "      <td>8993074</td>\n",
       "      <td>peak19424</td>\n",
       "      <td>1000</td>\n",
       "      <td>.</td>\n",
       "      <td>6.54450</td>\n",
       "      <td>48.63282</td>\n",
       "      <td>45.97403</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>chr8</td>\n",
       "      <td>126824543</td>\n",
       "      <td>126825031</td>\n",
       "      <td>peak57495</td>\n",
       "      <td>-1</td>\n",
       "      <td>.</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>266</td>\n",
       "      <td>chr8</td>\n",
       "      <td>126824525</td>\n",
       "      <td>126825188</td>\n",
       "      <td>peak20431</td>\n",
       "      <td>1000</td>\n",
       "      <td>.</td>\n",
       "      <td>6.61796</td>\n",
       "      <td>38.65833</td>\n",
       "      <td>36.08059</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>chr8</td>\n",
       "      <td>126838305</td>\n",
       "      <td>126839235</td>\n",
       "      <td>peak50766</td>\n",
       "      <td>-1</td>\n",
       "      <td>.</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>182</td>\n",
       "      <td>chr8</td>\n",
       "      <td>126839044</td>\n",
       "      <td>126839256</td>\n",
       "      <td>peak20435</td>\n",
       "      <td>829</td>\n",
       "      <td>.</td>\n",
       "      <td>5.00771</td>\n",
       "      <td>21.68738</td>\n",
       "      <td>19.29232</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>chr8</td>\n",
       "      <td>126849473</td>\n",
       "      <td>126850187</td>\n",
       "      <td>peak58047</td>\n",
       "      <td>-1</td>\n",
       "      <td>.</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>560</td>\n",
       "      <td>chr8</td>\n",
       "      <td>126849637</td>\n",
       "      <td>126850309</td>\n",
       "      <td>peak20437</td>\n",
       "      <td>836</td>\n",
       "      <td>.</td>\n",
       "      <td>4.81874</td>\n",
       "      <td>20.20660</td>\n",
       "      <td>17.83258</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>chr8</td>\n",
       "      <td>126920866</td>\n",
       "      <td>126921347</td>\n",
       "      <td>peak14712</td>\n",
       "      <td>-1</td>\n",
       "      <td>.</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>189</td>\n",
       "      <td>chr8</td>\n",
       "      <td>126920865</td>\n",
       "      <td>126921188</td>\n",
       "      <td>peak20441</td>\n",
       "      <td>1000</td>\n",
       "      <td>.</td>\n",
       "      <td>6.42499</td>\n",
       "      <td>33.74764</td>\n",
       "      <td>31.21361</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>chr8</td>\n",
       "      <td>127104674</td>\n",
       "      <td>127104970</td>\n",
       "      <td>peak11504</td>\n",
       "      <td>-1</td>\n",
       "      <td>.</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>176</td>\n",
       "      <td>chr8</td>\n",
       "      <td>127104687</td>\n",
       "      <td>127104941</td>\n",
       "      <td>peak20442</td>\n",
       "      <td>1000</td>\n",
       "      <td>.</td>\n",
       "      <td>8.50367</td>\n",
       "      <td>53.94794</td>\n",
       "      <td>51.25016</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0          1          2          3  4  5  6  7  8    9    10  \\\n",
       "0    chr9    6668262    6668828  peak24458 -1  . -1 -1 -1  370  chr9   \n",
       "1    chr9    7603389    7603594  peak64793 -1  . -1 -1 -1  114  chr9   \n",
       "2    chr9    7914492    7914988    peak729 -1  . -1 -1 -1  141  chr9   \n",
       "3    chr8    8733638    8734157  peak30058 -1  . -1 -1 -1  379  chr8   \n",
       "4    chr8    8992445    8993220   peak5261 -1  . -1 -1 -1  506  chr8   \n",
       "..    ...        ...        ...        ... .. .. .. .. ..  ...   ...   \n",
       "255  chr8  126824543  126825031  peak57495 -1  . -1 -1 -1  266  chr8   \n",
       "256  chr8  126838305  126839235  peak50766 -1  . -1 -1 -1  182  chr8   \n",
       "257  chr8  126849473  126850187  peak58047 -1  . -1 -1 -1  560  chr8   \n",
       "258  chr8  126920866  126921347  peak14712 -1  . -1 -1 -1  189  chr8   \n",
       "259  chr8  127104674  127104970  peak11504 -1  . -1 -1 -1  176  chr8   \n",
       "\n",
       "            11         12         13    14 15        16         17         18  \\\n",
       "0      6668246    6669123  peak20464  1000  .  10.41801  106.98440  104.00175   \n",
       "1      7603184    7603794  peak20478  1000  .  18.10567  247.44370  243.99432   \n",
       "2      7914173    7914971  peak20484  1000  .  15.21739  160.17427  156.98676   \n",
       "3      8733751    8734148  peak19418  1000  .  12.36603  110.58308  107.58508   \n",
       "4      8992509    8993074  peak19424  1000  .   6.54450   48.63282   45.97403   \n",
       "..         ...        ...        ...   ... ..       ...        ...        ...   \n",
       "255  126824525  126825188  peak20431  1000  .   6.61796   38.65833   36.08059   \n",
       "256  126839044  126839256  peak20435   829  .   5.00771   21.68738   19.29232   \n",
       "257  126849637  126850309  peak20437   836  .   4.81874   20.20660   17.83258   \n",
       "258  126920865  126921188  peak20441  1000  .   6.42499   33.74764   31.21361   \n",
       "259  127104687  127104941  peak20442  1000  .   8.50367   53.94794   51.25016   \n",
       "\n",
       "      19  \n",
       "0    372  \n",
       "1    315  \n",
       "2    531  \n",
       "3    270  \n",
       "4    451  \n",
       "..   ...  \n",
       "255  314  \n",
       "256  109  \n",
       "257  402  \n",
       "258  172  \n",
       "259  130  \n",
       "\n",
       "[260 rows x 20 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make and save one_to_one_peaks for every non-training species (e.g. macaque, rat, cow, pig)\n",
    "\n",
    "species = 'macaque'\n",
    "both_df = pd.read_csv(f\"/home/azstephe/liverRegression/regression_liver/data/splits/{species}Mouse/{species}ToMouse_liver_{species}Enhancer_mouseEnhancer_val_wawb.narrowPeak\", sep=\"\\t\", header=None)\n",
    "nonMouse_true = pd.read_csv(f\"/home/azstephe/liverRegression/regression_liver/data/log/{species}_liver_pos_ALL.bed\", sep=\"\\t\", header=None)\n",
    "mouse_true = pd.read_csv(\"/home/azstephe/liverRegression/regression_liver/data/log/mouse_liver_pos_ALL.bed\", sep=\"\\t\", header=None)\n",
    "\n",
    "unique1_2 = both_df[~both_df.duplicated(subset=[1, 2], keep=False)] # entries with unique mac mapped to mouse start and end\n",
    "all_unique = unique1_2[~unique1_2.duplicated(subset=[11,12], keep=False)]\n",
    "\n",
    "#### COL1,2 DUPLICATES\n",
    "\n",
    "duplicates3 = both_df[both_df.duplicated(subset=[1, 2], keep=False)] # entries with duplicated mac mapped to mouse start and end \n",
    "grouped_dups3 = duplicates3.groupby([1, 2])[3].apply(list).reset_index(name='col3')\n",
    "\n",
    "# grouped dups: start | end | [peaks with these endpoints]\n",
    "grouped_dups3['col3'] = grouped_dups3['col3'].apply(collapse_if_identical) \n",
    "\n",
    "grouped_dups3['col3'] = grouped_dups3['col3'].apply(lambda x: keep_largest_signal(x, nonMouse_true)) # redundant endpoints now map to 1 peak in col3\n",
    "grouped_dups3 = grouped_dups3[grouped_dups3['col3'] != ''] # remove macaque peaks that aren't large enough\n",
    "\n",
    "# df of duplicated col1,2 with strongest peak\n",
    "keep_strongestcol3 = duplicates3.merge(grouped_dups3[['col3']], left_on=3, right_on='col3', how='inner').drop('col3', axis=1) # keeps the strongest signal in col3 for redundant endpoints\n",
    "\n",
    "#### COL11,12 DUPLICATES\n",
    "\n",
    "grouped_dups13 = keep_strongestcol3.groupby([11, 12])[13].apply(list).reset_index(name='col13')\n",
    "grouped_dups13['col13'] = grouped_dups13['col13'].apply(collapse_if_identical)\n",
    "\n",
    "grouped_dups13['col13'] = grouped_dups13['col13'].apply(lambda x: keep_largest_signal(x, mouse_true))\n",
    "grouped_dups13 = grouped_dups13[grouped_dups13['col13'] != '']\n",
    "\n",
    "keep_strongestcol13 = keep_strongestcol3.merge(grouped_dups13[['col13']], left_on=13, right_on='col13', how='inner').drop('col13', axis=1)\n",
    "\n",
    "unique_endpoints = keep_strongestcol13 #rows with unique endpoints from the duplicated endpoints set\n",
    "\n",
    "####\n",
    "\n",
    "# col3 peakname duplicates with different endpoints\n",
    "still_dups_col3 = unique_endpoints[unique_endpoints.duplicated(subset=[3], keep=False)]\n",
    "\n",
    "# col3peaks | [col13 peaks intersecting col3 peak]\n",
    "grouped_dcol3 = still_dups_col3.groupby(3)[13].apply(list).reset_index(name='col13')\n",
    "\n",
    "# get the col13 peak with most overlap of col3\n",
    "grouped_dcol3['col13'] = grouped_dcol3['col13'].apply(lambda x: get_biggest_overlap(x, 13, still_dups_col3))\n",
    "\n",
    "merged3 = still_dups_col3.merge(grouped_dcol3[[3, 'col13']], left_on=[3, 13], right_on=[3, 'col13'], how='left', indicator=True)\n",
    "\n",
    "remove3 = merged3[merged3['_merge'] == 'left_only'].drop(columns=['_merge']) # col13 is what we want to remove\n",
    "\n",
    "unique_endpoints_subset = unique_endpoints.iloc[:,:20]\n",
    "remove3_subset = remove3.iloc[:,:20]\n",
    "\n",
    "# all col3 entries unique\n",
    "unique3 = unique_endpoints[~unique_endpoints_subset.apply(tuple, axis=1).isin(remove3_subset.apply(tuple, axis=1))] \n",
    "\n",
    "####\n",
    "\n",
    "# col13 peakname duplicates with different endpoints\n",
    "still_dups_col13 = unique3[unique3.duplicated(subset=[13], keep=False)]\n",
    "\n",
    "# col13peaks | [col3 peaks intersecting col13 peak]\n",
    "grouped_dcol13 = still_dups_col13.groupby(13)[3].apply(list).reset_index(name='col3')\n",
    "\n",
    "# get the col3 peak with most overlap of col13\n",
    "grouped_dcol13['col3'] = grouped_dcol13['col3'].apply(lambda x: get_biggest_overlap(x, 3, still_dups_col13))\n",
    "\n",
    "merged13 = still_dups_col13.merge(grouped_dcol13[[13, 'col3']], left_on=[3, 13], right_on=['col3', 13], how='left', indicator=True)\n",
    "\n",
    "remove13 = merged13[merged13['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\n",
    "unique3_subset = unique3.iloc[:, :20]\n",
    "remove13_subset = remove13.iloc[:, :20]\n",
    "\n",
    "# Identify rows in u3 that are NOT in remove3\n",
    "filtered_peaks_unique = unique3[~unique3_subset.apply(tuple, axis=1).isin(remove13_subset.apply(tuple, axis=1))]\n",
    "\n",
    "full_unique = pd.concat([all_unique, filtered_peaks_unique])\n",
    "\n",
    "# Sort by column '1'\n",
    "one_to_one_peaks = full_unique.sort_values(by=1).reset_index(drop=True)\n",
    "# one_to_one_peaks.to_csv(f'~/data/splits/oneToOnePeaks_val/{species}_mouse.bed', header=None, sep='\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e222fc4c-bd4c-44c2-b9c1-a4841cc0762f",
   "metadata": {},
   "source": [
    "### Set global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0524498-1b37-40a0-b2c1-0fd48e777fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple hypothesis correction coefficient\n",
    "MHC = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04edfc3-cdae-4f61-901a-0f076fb8d9f8",
   "metadata": {},
   "source": [
    "### Declare the species and model lists for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0afcd54-612d-4746-98dc-75d1ed2c2ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_list = ['macaque', 'rat', 'cow', 'pig']\n",
    "model_list = ['bdbi7l3n'] # Can list any set of models that are trained on data with same processing strategy (ie. 500bp log-transofrmed signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f05fa5-9455-4408-a6ff-96d7ae937d03",
   "metadata": {},
   "source": [
    "### Helper function\n",
    "\n",
    "`correlate` calculates the number of OCRs where the predicted change in accessibility matches the observed direction (same sign). It reports this as both a 'Same Sign Count' and a Percentage. It also calculates the Pearson correlation coefficient ($r$), the Spearman rank correlation coefficient ($\\rho$), and the Mean Squared Error (MSE) for val2 and test2.\n",
    "\n",
    "Goal: Same Sign Count = Total Count; Same Sign % ~ 1; Correlation Coefficients ~ 1; MSE ~ 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cc7a3a0-cd58-46d6-b473-bc916cab8309",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def correlate(mhc):\n",
    "    rows = []\n",
    "    # Lists for correlation calculations\n",
    "    groups = ['Val2', 'Test2']\n",
    "    dfs = [val2_foldchange_df, test2_foldchange_df]\n",
    "\n",
    "    # Calculate correlations\n",
    "    for group, df in zip(groups, dfs):\n",
    "        x = df['true'].squeeze()\n",
    "        y = df['pred'].squeeze()\n",
    "        pearson, pp = scipy.stats.pearsonr(x, y)\n",
    "        spearman, ps = scipy.stats.spearmanr(x, y)\n",
    "\n",
    "        mse = mean_squared_error(x, y)\n",
    "        \n",
    "        same_sign = np.sign(df['true']) == np.sign(df['pred'])\n",
    "        num_ss = same_sign.sum()\n",
    "        len_ss = len(df)\n",
    "        perc_ss = num_ss / len_ss\n",
    "        \n",
    "        same_sign_avg = np.sign(df.loc[::2]['true']) == np.sign(df.loc[::2]['avg_pred'])\n",
    "        num_ssa = same_sign_avg.sum()\n",
    "        len_ssa = len(df) / 2\n",
    "        perc_ssa = num_ssa / len_ssa\n",
    "        \n",
    "        rows.append({'Group': group, 'Metric': 'Same Sign Count', 'Value': num_ss})\n",
    "        rows.append({'Group': group, 'Metric': 'Total Count', 'Value': len_ss})\n",
    "        rows.append({'Group': group, 'Metric': 'Same Sign %', 'Value': perc_ss})\n",
    "     \n",
    "        rows.append({'Group': group, 'Metric': 'Pearson', 'Value': pearson})\n",
    "        rows.append({'Group': group, 'Metric': 'Pearson P-Val', 'Value': pp*mhc})\n",
    "        rows.append({'Group': group, 'Metric': 'Spearman', 'Value': spearman})\n",
    "        rows.append({'Group': group, 'Metric': 'Spearman P-Val', 'Value': ps*mhc})\n",
    "\n",
    "        rows.append({'Group': group, 'Metric': 'MSE', 'Value': mse})\n",
    "        \n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef2d0566-3e38-4e96-a39d-9d177410f86d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model</th>\n",
       "      <th>Species</th>\n",
       "      <th>Group</th>\n",
       "      <th>Metric</th>\n",
       "      <th>bdbi7l3n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cow</td>\n",
       "      <td>Val2</td>\n",
       "      <td>Same Sign Count</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cow</td>\n",
       "      <td>Val2</td>\n",
       "      <td>Total Count</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cow</td>\n",
       "      <td>Val2</td>\n",
       "      <td>Same Sign %</td>\n",
       "      <td>0.606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cow</td>\n",
       "      <td>Val2</td>\n",
       "      <td>Pearson</td>\n",
       "      <td>0.259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cow</td>\n",
       "      <td>Val2</td>\n",
       "      <td>Pearson P-Val</td>\n",
       "      <td>3.80e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>rat</td>\n",
       "      <td>Test2</td>\n",
       "      <td>Pearson</td>\n",
       "      <td>0.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>rat</td>\n",
       "      <td>Test2</td>\n",
       "      <td>Pearson P-Val</td>\n",
       "      <td>2.53e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>rat</td>\n",
       "      <td>Test2</td>\n",
       "      <td>Spearman</td>\n",
       "      <td>0.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>rat</td>\n",
       "      <td>Test2</td>\n",
       "      <td>Spearman P-Val</td>\n",
       "      <td>1.17e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>rat</td>\n",
       "      <td>Test2</td>\n",
       "      <td>MSE</td>\n",
       "      <td>0.201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "model Species  Group           Metric  bdbi7l3n\n",
       "0         cow   Val2  Same Sign Count       200\n",
       "1         cow   Val2      Total Count       330\n",
       "2         cow   Val2      Same Sign %     0.606\n",
       "3         cow   Val2          Pearson     0.259\n",
       "4         cow   Val2    Pearson P-Val  3.80e-04\n",
       "..        ...    ...              ...       ...\n",
       "59        rat  Test2          Pearson     0.177\n",
       "60        rat  Test2    Pearson P-Val  2.53e-09\n",
       "61        rat  Test2         Spearman     0.153\n",
       "62        rat  Test2   Spearman P-Val  1.17e-06\n",
       "63        rat  Test2              MSE     0.201\n",
       "\n",
       "[64 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "for species in species_list:\n",
    "    for model in model_list:\n",
    "        model_dir = f'{model}_FINAL'\n",
    "\n",
    "        nonMouse_true = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/log/{species}_liver_pos_ALL.bed', sep=\"\\t\", header=None)\n",
    "        mouse_true = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/log/mouse_liver_pos_ALL.bed', sep=\"\\t\", header=None)\n",
    "        one_to_one_peaks_TEST = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/oneToOnePeaks/{species}_mouse.bed', header=None, sep='\\t')\n",
    "        one_to_one_peaks_VAL = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/splits/oneToOnePeaks/{species}_mouse.bed', header=None, sep='\\t')\n",
    "\n",
    "        peaks = one_to_one_peaks_VAL[[4, 14]]\n",
    "\n",
    "        merged_df = peaks.merge(nonMouse_true, how='left', left_on=4, right_on=3, suffixes=('', '_non'))\n",
    "        \n",
    "        # Aligned orthologous peaks\n",
    "        merged_df = merged_df.merge(mouse_true, how='left', left_on=14, right_on=3, suffixes=('_NON', '_mouse'))\n",
    "\n",
    "        #############################################################################\n",
    "        # load MOUSE VAL DF\n",
    "\n",
    "        pred_mouse_VAL = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_mouse_TRAIN_VAL.csv', header=None)\n",
    "        \n",
    "        mouse_train = pd.read_csv('/home/azstephe/liverRegression/regression_liver/data/splits/logPos/mouse_liver_TRAINONLY.narrowPeak', sep=\"\\t\", header=None)\n",
    "        mouse_val = pd.read_csv('/home/azstephe/liverRegression/regression_liver/data/splits/logPos/mouse_liver_VAL.narrowPeak', sep=\"\\t\", header=None)\n",
    "        \n",
    "        mouse_train_len = 2*len(mouse_train)\n",
    "        mouse_val_len = 2*len(mouse_val)\n",
    "\n",
    "        doubled_mouse_val_df = pd.concat([mouse_val, mouse_val]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_mouse_val_df = doubled_mouse_val_df.rename(columns={0:'mouse_chr'})\n",
    "    \n",
    "        pred_mouse_val_df = pred_mouse_VAL.iloc[mouse_train_len:mouse_train_len + mouse_val_len].reset_index(drop=True)\n",
    "        pred_mouse_val_df = pd.concat([doubled_mouse_val_df.drop(columns=5), pred_mouse_val_df], axis=1)\n",
    "        pred_mouse_val_df = pred_mouse_val_df.rename(columns={4:'mouse_true', 0:'mouse_pred'}).reset_index(drop=True)\n",
    "        \n",
    "        merged_mouse_val_true_pred = peaks.merge(pred_mouse_val_df, how='left', left_on=14, right_on=3)\n",
    "        mouse_val_true_pred = merged_mouse_val_true_pred.rename(columns={3:'mouse_peak'}).drop([14], axis=1)\n",
    "\n",
    "        #############################################################################\n",
    "        # load non-mouse VAL2 DF\n",
    "\n",
    "        pred_VAL = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_{species}_VAL.csv', header=None)\n",
    "        \n",
    "        val1_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/val_splits/val1/{species}_liver_VAL_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        val2_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/splits/log_val2/{species}_liver_VAL.narrowPeak', header=None, delim_whitespace=True).rename(columns={0: 'mac_chr'})\n",
    "        \n",
    "        val1_len = 2*len(val1_df)\n",
    "        val2_len = 2*len(val2_df)\n",
    "        \n",
    "        doubled_val2_df = pd.concat([val2_df, val2_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        pred_val2_df = pred_VAL.iloc[val1_len:val1_len + val2_len].reset_index(drop=True)\n",
    "        doubled_val2_combined = pd.concat([doubled_val2_df, pred_val2_df], axis=1)\n",
    "\n",
    "        non_val2_true_pred = doubled_val2_combined.rename(columns={4: 'non_true', 0:'non_pred'})\n",
    "        merged_non_val2_true_pred = peaks.merge(non_val2_true_pred, how='left', left_on=4, right_on=3).drop(14, axis=1)\n",
    "        non_val2_true_pred = merged_non_val2_true_pred.rename(columns={3:'non_peak'}).drop(4, axis=1)\n",
    "        #############################################################################\n",
    "\n",
    "        # make VAL2 merged df\n",
    "        val2_foldchange_df = pd.concat([mouse_val_true_pred, non_val2_true_pred], axis=1)\n",
    "        \n",
    "        val2_foldchange_df['true'] = val2_foldchange_df['mouse_true']-val2_foldchange_df['non_true']\n",
    "        val2_foldchange_df['pred'] = val2_foldchange_df['mouse_pred']-val2_foldchange_df['non_pred']\n",
    "        \n",
    "        mouse_av = (val2_foldchange_df.loc[::2, 'mouse_pred'].values + val2_foldchange_df.loc[1::2, 'mouse_pred'].values) / 2\n",
    "        mac_av = (val2_foldchange_df.loc[::2, 'non_pred'].values + val2_foldchange_df.loc[1::2, 'non_pred'].values) / 2\n",
    "        \n",
    "        # Add the averages back to the DataFrame as a new column\n",
    "        val2_foldchange_df.loc[::2, 'mouse_pred_avg'] = mouse_av\n",
    "        val2_foldchange_df.loc[::2, 'non_pred_avg'] = mac_av \n",
    "        val2_foldchange_df['avg_pred'] = val2_foldchange_df['mouse_pred_avg']-val2_foldchange_df['non_pred_avg']\n",
    "\n",
    "        #############################################################################\n",
    "        # TEST2 FOLDCHANGE\n",
    "\n",
    "        peaks = one_to_one_peaks_TEST[[4, 14]]\n",
    "\n",
    "        merged_df = peaks.merge(nonMouse_true, how='left', left_on=4, right_on=3, suffixes=('', '_non'))\n",
    "        \n",
    "        # Aligned orthologous peaks\n",
    "        merged_df = merged_df.merge(mouse_true, how='left', left_on=14, right_on=3, suffixes=('_NON', '_mouse'))\n",
    "\n",
    "        #############################################################################\n",
    "        \n",
    "        # load MOUSE TEST DF\n",
    "\n",
    "        pred_mouse_TEST = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_mouse_TEST.csv', header=None)\n",
    "        \n",
    "        mouse_test = pd.read_csv('/home/azstephe/liverRegression/regression_liver/data/test_splits/log_pos/mouse_liver_TEST_500bp.bed', sep=\"\\t\", header=None)\n",
    "        \n",
    "        mouse_test_len = 2*len(mouse_test)\n",
    "\n",
    "        doubled_mouse_test_df = pd.concat([mouse_test, mouse_test]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_mouse_test_df = doubled_mouse_test_df.rename(columns={0:'mouse_chr'})\n",
    "    \n",
    "        pred_mouse_test_df = pred_mouse_TEST.head(mouse_test_len).reset_index(drop=True)\n",
    "        pred_mouse_test_df = pd.concat([doubled_mouse_test_df.drop(columns=5), pred_mouse_test_df], axis=1)\n",
    "        pred_mouse_test_df = pred_mouse_test_df.rename(columns={4:'mouse_true', 0:'mouse_pred'}).reset_index(drop=True)\n",
    "        \n",
    "        merged_mouse_test_true_pred = peaks.merge(pred_mouse_test_df, how='left', left_on=14, right_on=3)\n",
    "        mouse_test_true_pred = merged_mouse_test_true_pred.rename(columns={3:'mouse_peak'}).drop([14], axis=1)\n",
    "\n",
    "        #############################################################################\n",
    "        # load nonmouse TEST2 DF\n",
    "        \n",
    "        pred_TEST = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_{species}_TEST.csv', header=None)\n",
    "        \n",
    "        test1_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_LiuAll_test1/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        test2_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_test2/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).rename(columns={0: 'mac_chr'})\n",
    "        \n",
    "        test1_len = 2*len(test1_df)\n",
    "        test2_len = 2*len(test2_df)\n",
    "        \n",
    "        doubled_test2_df = pd.concat([test2_df, test2_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        pred_test2_df = pred_TEST.iloc[test1_len:test1_len + test2_len].reset_index(drop=True)\n",
    "        doubled_test2_combined = pd.concat([doubled_test2_df, pred_test2_df], axis=1)\n",
    "\n",
    "        non_test2_true_pred = doubled_test2_combined.rename(columns={4: 'non_true', 0:'non_pred'})\n",
    "        merged_non_test2_true_pred = peaks.merge(non_test2_true_pred, how='left', left_on=4, right_on=3).drop(14, axis=1)\n",
    "        non_test2_true_pred = merged_non_test2_true_pred.rename(columns={3:'non_peak'}).drop(4, axis=1)\n",
    "\n",
    "        #############################################################################\n",
    "\n",
    "        # make TEST2 merged df\n",
    "        test2_foldchange_df = pd.concat([mouse_test_true_pred, non_test2_true_pred], axis=1)\n",
    "        \n",
    "        test2_foldchange_df['true'] = test2_foldchange_df['mouse_true']-test2_foldchange_df['non_true']\n",
    "        test2_foldchange_df['pred'] = test2_foldchange_df['mouse_pred']-test2_foldchange_df['non_pred']\n",
    "        \n",
    "        mouse_av = (test2_foldchange_df.loc[::2, 'mouse_pred'].values + test2_foldchange_df.loc[1::2, 'mouse_pred'].values) / 2\n",
    "        non_av = (test2_foldchange_df.loc[::2, 'non_pred'].values + test2_foldchange_df.loc[1::2, 'non_pred'].values) / 2\n",
    "        \n",
    "        # Add the averages back to the DataFrame as a new column\n",
    "        test2_foldchange_df.loc[::2, 'mouse_pred_avg'] = mouse_av\n",
    "        test2_foldchange_df.loc[::2, 'non_pred_avg'] = non_av \n",
    "        test2_foldchange_df['avg_pred'] = test2_foldchange_df['mouse_pred_avg']-test2_foldchange_df['non_pred_avg']\n",
    "        \n",
    "        corr_df = correlate(MHC)\n",
    "        corr_df['Species'] = species\n",
    "        corr_df['model'] = model\n",
    "        all_results.append(corr_df)\n",
    "        \n",
    "#############################################################################\n",
    "\n",
    "summary_df = pd.concat(all_results)\n",
    "\n",
    "custom_group_order = [ 'Val2', 'Test2' ]\n",
    "custom_metric_order = ['Same Sign Count', 'Total Count', 'Same Sign %', 'Pearson', 'Pearson P-Val', 'Spearman', 'Spearman P-Val', 'MSE']\n",
    "\n",
    "# # Convert 'group' to a categorical type with the specified order.\n",
    "summary_df['Group'] = pd.Categorical(summary_df['Group'], categories=custom_group_order, ordered=True)\n",
    "summary_df['Metric'] = pd.Categorical(summary_df['Metric'], categories=custom_metric_order, ordered=True)\n",
    "\n",
    "\n",
    "pivot_df = summary_df.pivot_table(\n",
    "    index=[\"Species\", \"Group\", \"Metric\"],\n",
    "    columns=\"model\",\n",
    "    values=\"Value\"\n",
    ").reset_index()\n",
    "\n",
    "pivot_df = pivot_df.sort_values(by=[\"Species\", \"Group\", \"Metric\"])\n",
    "\n",
    "pivot_df = pivot_df[[\"Species\", \"Group\", \"Metric\"] + model_list]\n",
    "# pivot_df_reordered = pivot_df[model_list]\n",
    "\n",
    "def format_value(metric, value):\n",
    "    \"\"\"Format values depending on whether it's a P-Val metric or not.\"\"\"\n",
    "    if \"P-Val\" in metric:\n",
    "        return f\"{value:.2e}\"   # scientific notation, 3 sig figs\n",
    "    else:\n",
    "        return f\"{value:.3g}\"   # regular decimal, 3 sig figs\n",
    "\n",
    "# Apply formatting to a copy just for display/export\n",
    "pivot_df_display = pivot_df.copy()\n",
    "for col in model_list:  # each model column\n",
    "    pivot_df_display[col] = pivot_df_display.apply(\n",
    "        lambda row: format_value(row[\"Metric\"], row[col]),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "display(pivot_df_display)\n",
    "\n",
    "output_filename = '~/data/tables/log_model_foldchange_table.tsv'\n",
    "# pivot_df_display.to_csv(output_filename, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec0407b-9531-473d-b3dd-7686c9481273",
   "metadata": {},
   "source": [
    "### Final Output:\n",
    "`~/data/tables/log_model_foldchange_table.tsv`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
