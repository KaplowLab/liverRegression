{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1303eeae-4361-47de-85b9-e73b5e49b197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def pearson_spearman(x, y):\n",
    "    pearson_corr, pearson_p_value = scipy.stats.pearsonr(x, y)\n",
    "    print(f\"Pearson correlation coefficient: {pearson_corr:.4f}, p-value: {pearson_p_value:.4g}\")\n",
    "\n",
    "    spearman_corr, spearman_p_value = scipy.stats.spearmanr(x, y)\n",
    "    print(f\"Spearman correlation coefficient: {spearman_corr:.4f}, p-value: {spearman_p_value:.4g}\")\n",
    "\n",
    "species_list = ['macaque', 'rat', 'cow', 'pig']\n",
    "\n",
    "def mean_squared_error(x, y):\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    return np.mean((x - y) ** 2)\n",
    "\n",
    "def format_value(metric_name, value):\n",
    "    \"\"\"Format values depending on whether it's a P-value metric or not.\"\"\"\n",
    "    # Check for '_p' which is more general for 'pearson_p', 'spearman_p' etc.\n",
    "    if \"_p\" in metric_name:\n",
    "        return f\"{value:.2e}\"  # Scientific notation for p-values\n",
    "    else:\n",
    "        return f\"{value:.3g}\"  # General format for other metrics\n",
    "\n",
    "mhc = 200\n",
    "        \n",
    "        pearson, pearson_p = scipy.stats.pearsonr(x, y)\n",
    "        spearman, spearman_p = scipy.stats.spearmanr(x, y)\n",
    "        mse = mean_squared_error(x, y)\n",
    "        pearson_p *= mhc\n",
    "        spearman_p *= mhc\n",
    "        rows.append({'Group': group, 'Metric': 'Pearson', 'Value': pearson})\n",
    "        rows.append({'Group': group, 'Metric': 'Pearson_p', 'Value': pearson_p})\n",
    "        rows.append({'Group': group, 'Metric': 'Spearman', 'Value': spearman})\n",
    "        rows.append({'Group': group, 'Metric': 'Spearman_p', 'Value': spearman_p})\n",
    "        rows.append({'Group': group, 'Metric': 'MSE', 'Value': mse})\n",
    "\n",
    "metric_vars = ['Pearson', 'Pearson_p', 'Spearman', 'Spearman_p', 'MSE']\n",
    "pivot_df_reordered = pivot_df_reordered.reindex(metric_vars, level='Metric')\n",
    "\n",
    "# Loop through each model's column to apply the formatting\n",
    "for col in pivot_df_reordered.columns:\n",
    "    pivot_df_reordered[col] = pivot_df_reordered.apply(\n",
    "        # Access the 'metric' from the index using row.name[2]\n",
    "        # (assuming it's the 3rd level of your index)\n",
    "        lambda row: format_value(row.name[2], row[col]),\n",
    "        axis=1)\n",
    "\n",
    "display(pivot_df_reordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0c51da5-5eab-41ca-b973-2fa9a9bc6be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>bdbi7l3n</th>\n",
       "      <th>7vsdq5k2</th>\n",
       "      <th>wnfdrgcc</th>\n",
       "      <th>8i7h7nsh</th>\n",
       "      <th>ph4wrpxu</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>species</th>\n",
       "      <th>Group</th>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">cow</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">Train</th>\n",
       "      <th>Pearson</th>\n",
       "      <td>0.406</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pearson_p</th>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spearman</th>\n",
       "      <td>0.401</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spearman_p</th>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>2.27</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.81</td>\n",
       "      <td>1.79</td>\n",
       "      <td>1.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">rat</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">Test Cow+Pig</th>\n",
       "      <th>Pearson</th>\n",
       "      <td>0.435</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pearson_p</th>\n",
       "      <td>3.52e-06</td>\n",
       "      <td>1.89e-04</td>\n",
       "      <td>2.56e-06</td>\n",
       "      <td>2.24e-03</td>\n",
       "      <td>4.63e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spearman</th>\n",
       "      <td>0.456</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spearman_p</th>\n",
       "      <td>5.75e-07</td>\n",
       "      <td>6.79e-06</td>\n",
       "      <td>5.68e-08</td>\n",
       "      <td>3.16e-04</td>\n",
       "      <td>8.75e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>2.19</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.76</td>\n",
       "      <td>1.76</td>\n",
       "      <td>1.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "model                            bdbi7l3n  7vsdq5k2  wnfdrgcc  8i7h7nsh  \\\n",
       "species Group        Metric                                               \n",
       "cow     Train        Pearson        0.406      0.39     0.387     0.384   \n",
       "                     Pearson_p   0.00e+00  0.00e+00  0.00e+00  0.00e+00   \n",
       "                     Spearman       0.401     0.385     0.381     0.375   \n",
       "                     Spearman_p  0.00e+00  0.00e+00  0.00e+00  0.00e+00   \n",
       "                     MSE             2.27      1.87      1.81      1.79   \n",
       "...                                   ...       ...       ...       ...   \n",
       "rat     Test Cow+Pig Pearson        0.435     0.383     0.439     0.346   \n",
       "                     Pearson_p   3.52e-06  1.89e-04  2.56e-06  2.24e-03   \n",
       "                     Spearman       0.456     0.427     0.481     0.376   \n",
       "                     Spearman_p  5.75e-07  6.79e-06  5.68e-08  3.16e-04   \n",
       "                     MSE             2.19       1.9      1.76      1.76   \n",
       "\n",
       "model                            ph4wrpxu  \n",
       "species Group        Metric                \n",
       "cow     Train        Pearson        0.388  \n",
       "                     Pearson_p   0.00e+00  \n",
       "                     Spearman       0.381  \n",
       "                     Spearman_p  0.00e+00  \n",
       "                     MSE             1.94  \n",
       "...                                   ...  \n",
       "rat     Test Cow+Pig Pearson        0.402  \n",
       "                     Pearson_p   4.63e-05  \n",
       "                     Spearman       0.451  \n",
       "                     Spearman_p  8.75e-07  \n",
       "                     MSE             1.92  \n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5 BEST LOG MODELS\n",
    "mhc = 200\n",
    "# FUNCTIONS SPECIFIC TO THIS SET\n",
    "def correlate():\n",
    "    rows = []\n",
    "    # Lists for correlation calculations\n",
    "    groups = ['Train', 'Validation', 'Test', 'Val2', 'Val3', 'Test2', 'Test3', 'Train Cow+Pig', 'Val Cow+Pig', 'Test Cow+Pig']\n",
    "    preds = [pred_trainPos, pred_valPos, pred_testPos, pred_val2_df, pred_val3_df, pred_test2_df, pred_test3_df, pred_train4_df, pred_val4_df, pred_test4_df]\n",
    "    trues = [doubled_trainPos, doubled_valPos, doubled_testPos, doubled_val2_df, doubled_val3_df, doubled_test2_df, doubled_test3_df, doubled_train4_df, doubled_val4_df, doubled_test4_df]\n",
    "\n",
    "    # Calculate correlations\n",
    "    for group, pred_df, true_df in zip(groups, preds, trues):\n",
    "        x = true_df.squeeze()\n",
    "        y = pred_df.squeeze()\n",
    "        pearson, pearson_p = scipy.stats.pearsonr(x, y)\n",
    "        spearman, spearman_p = scipy.stats.spearmanr(x, y)\n",
    "        mse = mean_squared_error(x, y)\n",
    "        pearson_p *= mhc\n",
    "        spearman_p *= mhc\n",
    "        rows.append({'Group': group, 'Metric': 'Pearson', 'Value': pearson})\n",
    "        rows.append({'Group': group, 'Metric': 'Pearson_p', 'Value': pearson_p})\n",
    "        rows.append({'Group': group, 'Metric': 'Spearman', 'Value': spearman})\n",
    "        rows.append({'Group': group, 'Metric': 'Spearman_p', 'Value': spearman_p})\n",
    "        rows.append({'Group': group, 'Metric': 'MSE', 'Value': mse})\n",
    "          \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def negatives():\n",
    "    rows = []\n",
    "     # Lists for negative average calculations\n",
    "    negGroup = ['Train neg', 'Val neg', 'Test neg', 'Val1 avg pred', 'Test1 avg pred', 'Train Cow+Pig Pred', 'Val Cow+Pig Pred', 'Test Cow+Pig Pred']\n",
    "    negValues = [pred_trainNeg.mean().iloc[0], pred_valNeg.mean().iloc[0], pred_testNeg.mean().iloc[0], pred_val1_df.mean().iloc[0], pred_test1_df.mean().iloc[0], pred_train5_df.mean().iloc[0], pred_val5_df.mean().iloc[0], pred_test5_df.mean().iloc[0]]\n",
    "    \n",
    "    # Add negative value averages\n",
    "    for group, negv in zip(negGroup, negValues):\n",
    "        rows.append({'Group': group, 'Metric': 'Avg Neg Prediction', 'Value': negv})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# MAIN SCRIPT\n",
    "all_results = []\n",
    "neg_results = []\n",
    "model_list = ['bdbi7l3n', '7vsdq5k2', 'wnfdrgcc', '8i7h7nsh', 'ph4wrpxu']\n",
    "\n",
    "for species in species_list:\n",
    "    for model in model_list:\n",
    "        model_dir = f'{model}_FINAL'\n",
    "        \n",
    "        # Load and process all dfs so correlate() function can access them\n",
    "        \n",
    "        #############################################################################\n",
    "        # load TRAIN DFs\n",
    "        negTrainPath = f'/home/azstephe/liverRegression/regression_liver/data/splits/negatives/nonRat_liver_andMacaque_andCow_andPig_TRAIN_500bp.bed'\n",
    "        if species == 'macaque':\n",
    "            negTrainPath = f'/home/azstephe/liverRegression/regression_liver/data/splits/negatives/nonMacaque_liver_andRat_andCow_andPig_TRAIN_500bp.bed'\n",
    "        elif species == 'cow':\n",
    "            negTrainPath = f'/home/azstephe/liverRegression/regression_liver/data/splits/negatives/nonCow_liver_andMacaque_andRat_andPig_TRAIN_500bp.bed'\n",
    "        elif species == 'pig':\n",
    "            negTrainPath = f'/home/azstephe/liverRegression/regression_liver/data/splits/negatives/nonPig_liver_andMacaque_andRat_andCow_TRAIN_500bp.bed'\n",
    "        \n",
    "        pred_TRAIN = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_{species}_TRAIN.csv', header=None)\n",
    "        \n",
    "        trainPos = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/splits/logPos/{species}_liver_TRAINONLY.narrowPeak', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        trainNeg = pd.read_csv(negTrainPath, header=None, delim_whitespace=True).iloc[:,4]\n",
    "\n",
    "        trainPos_len = 2*len(trainPos)\n",
    "        trainNeg_len = 2*len(trainNeg)\n",
    "        \n",
    "        if len(pred_TRAIN) != trainPos_len+trainNeg_len:\n",
    "            print(f\"ERROR TRAIN ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_trainPos = pd.concat([trainPos, trainPos]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_trainNeg = pd.concat([trainNeg, trainNeg]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_trainPos = pred_TRAIN.head(trainPos_len)\n",
    "        pred_trainNeg = pred_TRAIN.tail(trainNeg_len)\n",
    "\n",
    "        #############################################################################\n",
    "        # load VALIDATION DFs\n",
    "\n",
    "        negValPath = f'/home/azstephe/liverRegression/regression_liver/data/splits/negatives/nonRat_liver_andMacaque_andCow_andPig_VAL_500bp.bed'\n",
    "        if species == 'macaque':\n",
    "            negValPath = f'/home/azstephe/liverRegression/regression_liver/data/splits/negatives/nonMacaque_liver_andRat_andCow_andPig_VAL_500bp.bed'\n",
    "        elif species == 'cow':\n",
    "            negValPath = f'/home/azstephe/liverRegression/regression_liver/data/splits/negatives/nonCow_liver_andMacaque_andRat_andPig_VAL_500bp.bed'\n",
    "        elif species == 'pig':\n",
    "            negValPath = f'/home/azstephe/liverRegression/regression_liver/data/splits/negatives/nonPig_liver_andMacaque_andRat_andCow_VAL_500bp.bed'\n",
    "        \n",
    "        pred_VAL_ortho = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_{species}_VAL_orthologs.csv', header=None)\n",
    "        \n",
    "        valPos = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/splits/logPos/{species}_liver_VAL.narrowPeak', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        valNeg = pd.read_csv(negValPath, header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        valPos_len = 2*len(valPos)\n",
    "        valNeg_len = 2*len(valNeg)\n",
    "        \n",
    "        if len(pred_VAL_ortho) != valPos_len+valNeg_len:\n",
    "            print(f\"ERROR VALORTHO ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_valPos = pd.concat([valPos, valPos]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_valNeg = pd.concat([valNeg, valNeg]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_valPos = pred_VAL_ortho.head(valPos_len)\n",
    "        pred_valNeg = pred_VAL_ortho.tail(valNeg_len)\n",
    "\n",
    "        #############################################################################\n",
    "        # load TEST DFs\n",
    "        \n",
    "        pred_TEST_ortho = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_{species}_TEST_orthologs.csv', header=None)\n",
    "        \n",
    "        testPos = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_pos_LiuAll/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        testNeg = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/neg/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        testPos_len = 2*len(testPos)\n",
    "        testNeg_len = 2*len(testNeg)\n",
    "        \n",
    "        if len(pred_TEST_ortho) != testPos_len+testNeg_len:\n",
    "            print(f\"ERROR TEST ORTHO ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_testPos = pd.concat([testPos, testPos]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_testNeg = pd.concat([testNeg, testNeg]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_testPos = pred_TEST_ortho.head(testPos_len)\n",
    "        pred_testNeg = pred_TEST_ortho.tail(testNeg_len)\n",
    "\n",
    "        #############################################################################\n",
    "        # load VAL 1,2,3 DFs\n",
    "        pred_VAL = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_{species}_VAL.csv', header=None)\n",
    "        \n",
    "        val1_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/val_splits/val1/{species}_liver_VAL_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        val2_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/splits/log_val2/{species}_liver_VAL.narrowPeak', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        val3_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/splits/log_val3/{species}_liver_VAL.narrowPeak', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        val1_len = 2*len(val1_df)\n",
    "        val2_len = 2*len(val2_df)\n",
    "        val3_len = 2*len(val3_df)\n",
    "        \n",
    "        if len(pred_VAL) != val1_len+val2_len+val3_len:\n",
    "            print(f\"ERROR VAL ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_val1_df = pd.concat([val1_df, val1_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_val2_df = pd.concat([val2_df, val2_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_val3_df = pd.concat([val3_df, val3_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_val1_df = pred_VAL.head(val1_len)\n",
    "        pred_val2_df = pred_VAL.iloc[val1_len:val1_len + val2_len]\n",
    "        pred_val3_df = pred_VAL.tail(val3_len)\n",
    "\n",
    "        #############################################################################\n",
    "        # load TEST 1,2,3 DFs\n",
    "        pred_TEST = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_{species}_TEST.csv', header=None)\n",
    "        \n",
    "        test1_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_LiuAll_test1/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        test2_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_test2/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        test3_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_test3/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        test1_len = 2*len(test1_df)\n",
    "        test2_len = 2*len(test2_df)\n",
    "        test3_len = 2*len(test3_df)\n",
    "        \n",
    "        if len(pred_TEST) != test1_len+test2_len+test3_len:\n",
    "            print(f\"ERROR TEST ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_test1_df = pd.concat([test1_df, test1_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_test2_df = pd.concat([test2_df, test2_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_test3_df = pd.concat([test3_df, test3_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_test1_df = pred_TEST.head(test1_len)\n",
    "        pred_test2_df = pred_TEST.iloc[test1_len:test1_len + test2_len]\n",
    "        pred_test3_df = pred_TEST.tail(test3_len)\n",
    "\n",
    "        #############################################################################\n",
    "        # load cow + pig TRAIN DFs\n",
    "        pred_cow_pig_TRAIN = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_cow_pig_TRAIN.csv', header=None)\n",
    "        \n",
    "        train4Pos_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/splits/cow_pig/cow_pig_liver_pos_mouse_macaque_rat_closed_TRAIN_chromName_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        train5Neg_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/splits/cow_pig/cow_pig_liver_neg_mouse_macaque_rat_open_TRAIN_chromName_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        train4_len = 2*len(train4Pos_df)\n",
    "        train5_len = 2*len(train5Neg_df)\n",
    "        \n",
    "        if len(pred_cow_pig_TRAIN) != train4_len+train5_len:\n",
    "            print(f\"ERROR TEST ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_train4_df = pd.concat([train4Pos_df, train4Pos_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_train5_df = pd.concat([train5Neg_df, train5Neg_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_train4_df = pred_cow_pig_TRAIN.head(train4_len)\n",
    "        pred_train5_df = pred_cow_pig_TRAIN.tail(train5_len)\n",
    "\n",
    "        #############################################################################\n",
    "        # load cow + pig VAL DFs\n",
    "        pred_cow_pig_VAL = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_cow_pig_VAL.csv', header=None)\n",
    "        \n",
    "        val4Pos_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/splits/cow_pig/cow_pig_liver_pos_mouse_macaque_rat_closed_VAL_chromName_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        val5Neg_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/splits/cow_pig/cow_pig_liver_neg_mouse_macaque_rat_open_VAL_chromName_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        val4_len = 2*len(val4Pos_df)\n",
    "        val5_len = 2*len(val5Neg_df)\n",
    "        \n",
    "        if len(pred_cow_pig_VAL) != val4_len+val5_len:\n",
    "            print(f\"ERROR TEST ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_val4_df = pd.concat([val4Pos_df, val4Pos_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_val5_df = pd.concat([val5Neg_df, val5Neg_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_val4_df = pred_cow_pig_VAL.head(val4_len)\n",
    "        pred_val5_df = pred_cow_pig_VAL.tail(val5_len)\n",
    "        \n",
    "        #############################################################################\n",
    "        # load cow + pig TEST DFs\n",
    "        pred_cow_pig_TEST = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_cow_pig_TEST.csv', header=None)\n",
    "        \n",
    "        test4Pos_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_test4/cow_pig_liver_pos_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        test5Neg_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_test5/cow_pig_liver_neg_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        test4_len = 2*len(test4Pos_df)\n",
    "        test5_len = 2*len(test5Neg_df)\n",
    "        \n",
    "        if len(pred_cow_pig_TEST) != test4_len+test5_len:\n",
    "            print(f\"ERROR TEST ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_test4_df = pd.concat([test4Pos_df, test4Pos_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_test5_df = pd.concat([test5Neg_df, test5Neg_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_test4_df = pred_cow_pig_TEST.head(test4_len)\n",
    "        pred_test5_df = pred_cow_pig_TEST.tail(test5_len)\n",
    "        \n",
    "        #############################################################################\n",
    "        # Call the correlate function which now uses the globally available DFs\n",
    "        corr_df = correlate()\n",
    "        corr_df['species'] = species\n",
    "        corr_df['model'] = model\n",
    "        all_results.append(corr_df)\n",
    "        \n",
    "        neg_df = negatives()\n",
    "        neg_df['species'] = species\n",
    "        neg_df['model'] = model\n",
    "        neg_results.append(neg_df)\n",
    "        \n",
    "\n",
    "# #############################################################################\n",
    "# FINAL PROCESSING\n",
    "# #############################################################################\n",
    "\n",
    "summary_df = pd.concat(all_results)\n",
    "summary_neg_df = pd.concat(neg_results)\n",
    "\n",
    "# Define the custom order to place negative groups at the bottom.\n",
    "custom_group_order = [\n",
    "    'Train', 'Validation', 'Test', 'Val2', 'Val3', 'Test2', 'Test3', 'Train Cow+Pig', 'Val Cow+Pig', 'Test Cow+Pig'\n",
    "]\n",
    "\n",
    "custom_group_order_neg = [\n",
    "    'Train neg', 'Val neg', 'Test neg', 'Val1 avg pred', 'Test1 avg pred', 'Train Cow+Pig Pred', 'Val Cow+Pig Pred', 'Test Cow+Pig Pred'\n",
    "]\n",
    "\n",
    "# Convert 'group' to a categorical type with the specified order.\n",
    "summary_df['Group'] = pd.Categorical(summary_df['Group'], categories=custom_group_order, ordered=True)\n",
    "summary_neg_df['Group'] = pd.Categorical(summary_neg_df['Group'], categories=custom_group_order_neg, ordered=True)\n",
    "\n",
    "\n",
    "# Pivot so each model is a column\n",
    "pivot_df = summary_df.pivot_table(\n",
    "    index=['species', 'Group', 'Metric'],\n",
    "    columns='model',\n",
    "    values='Value'\n",
    ")\n",
    "\n",
    "pivot_neg_df = summary_neg_df.pivot_table(\n",
    "    index=['species', 'Group', 'Metric'],\n",
    "    columns='model',\n",
    "    values='Value'\n",
    ")\n",
    "\n",
    "# Sort the index to maintain a logical order (will now use the custom group order)\n",
    "pivot_df = pivot_df.sort_index(level=['species', 'Group', 'Metric'])\n",
    "pivot_neg_df = pivot_neg_df.sort_index(level=['species', 'Group', 'Metric'])\n",
    "\n",
    "pivot_df_reordered = pivot_df[model_list]\n",
    "pivot_neg_df_reordered = pivot_neg_df[model_list]\n",
    "\n",
    "\n",
    "\n",
    "metric_vars = ['Pearson', 'Pearson_p', 'Spearman', 'Spearman_p', 'MSE']\n",
    "pivot_df_reordered = pivot_df_reordered.reindex(metric_vars, level='Metric')\n",
    "\n",
    "# Loop through each model's column to apply the formatting\n",
    "for col in pivot_df_reordered.columns:\n",
    "    pivot_df_reordered[col] = pivot_df_reordered.apply(\n",
    "        # Access the 'metric' from the index using row.name[2]\n",
    "        # (assuming it's the 3rd level of your index)\n",
    "        lambda row: format_value(row.name[2], row[col]),\n",
    "        axis=1)\n",
    "\n",
    "display(pivot_df_reordered)\n",
    "# display(pivot_df_reordered.style.format(\"{:.3f}\"))\n",
    "        \n",
    "# display(pivot_neg_df_reordered.style.format(\"{:.3f}\"))\n",
    "\n",
    "output_filename = '/home/azstephe/liverRegression/regression_liver/data/figs/tables/log_model_eval_table_FINAL_mse.tsv'\n",
    "# pivot_df_reordered.to_csv(output_filename, sep='\\t')\n",
    "\n",
    "output_neg_filename = '/home/azstephe/liverRegression/regression_liver/data/figs/tables/log_model_neg_table_FINAL.tsv'\n",
    "# pivot_neg_df_reordered.to_csv(output_neg_filename, sep='\\t', float_format='%.3f')\n",
    "\n",
    "# print(f'Results successfully saved to: {output_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d041dca-e447-44dc-a121-a350c8f051de",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>bdbi7l3n</th>\n",
       "      <th>kf8188qf</th>\n",
       "      <th>cq45eb2s</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>species</th>\n",
       "      <th>Group</th>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">cow</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">Train</th>\n",
       "      <th>Pearson</th>\n",
       "      <td>0.406</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pearson_p</th>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spearman</th>\n",
       "      <td>0.401</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spearman_p</th>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>2.27</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">rat</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">Test Cow+Pig</th>\n",
       "      <th>Pearson</th>\n",
       "      <td>0.435</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pearson_p</th>\n",
       "      <td>1.76e-06</td>\n",
       "      <td>3.60e-05</td>\n",
       "      <td>1.57e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spearman</th>\n",
       "      <td>0.456</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spearman_p</th>\n",
       "      <td>2.88e-07</td>\n",
       "      <td>2.02e-06</td>\n",
       "      <td>4.70e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>2.19</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "model                            bdbi7l3n  kf8188qf  cq45eb2s\n",
       "species Group        Metric                                  \n",
       "cow     Train        Pearson        0.406     0.429     0.518\n",
       "                     Pearson_p   0.00e+00  0.00e+00  0.00e+00\n",
       "                     Spearman       0.401     0.429     0.518\n",
       "                     Spearman_p  0.00e+00  0.00e+00  0.00e+00\n",
       "                     MSE             2.27      1.11      1.05\n",
       "...                                   ...       ...       ...\n",
       "rat     Test Cow+Pig Pearson        0.435     0.396     0.436\n",
       "                     Pearson_p   1.76e-06  3.60e-05  1.57e-06\n",
       "                     Spearman       0.456     0.433     0.475\n",
       "                     Spearman_p  2.88e-07  2.02e-06  4.70e-08\n",
       "                     MSE             2.19      1.19      1.35\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1 3 5 LOG MODELS\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "def correlate(mhc):\n",
    "    rows = []\n",
    "    # Lists for correlation calculations\n",
    "    groups = ['Train', 'Validation', 'Test', 'Val2', 'Val3', 'Test2', 'Test3', 'Train Cow+Pig', 'Val Cow+Pig', 'Test Cow+Pig']\n",
    "    preds = [pred_trainPos, pred_valPos, pred_testPos, pred_val2_df, pred_val3_df, pred_test2_df, pred_test3_df, pred_train4_df, pred_val4_df, pred_test4_df]\n",
    "    trues = [doubled_trainPos, doubled_valPos, doubled_testPos, doubled_val2_df, doubled_val3_df, doubled_test2_df, doubled_test3_df, doubled_train4_df, doubled_val4_df, doubled_test4_df]\n",
    "\n",
    "    # Calculate correlations\n",
    "    for group, pred_df, true_df in zip(groups, preds, trues):\n",
    "        x = true_df.squeeze()\n",
    "        y = pred_df.squeeze()\n",
    "        pearson, pearson_p = scipy.stats.pearsonr(x, y)\n",
    "        spearman, spearman_p = scipy.stats.spearmanr(x, y)\n",
    "        mse = mean_squared_error(x, y)\n",
    "        pearson_p *= mhc\n",
    "        spearman_p *= mhc\n",
    "        \n",
    "        rows.append({'Group': group, 'Metric': 'Pearson', 'Value': pearson})\n",
    "        rows.append({'Group': group, 'Metric': 'Pearson_p', 'Value': pearson_p})\n",
    "        rows.append({'Group': group, 'Metric': 'Spearman', 'Value': spearman})\n",
    "        rows.append({'Group': group, 'Metric': 'Spearman_p', 'Value': spearman_p})\n",
    "        rows.append({'Group': group, 'Metric': 'MSE', 'Value': mse})\n",
    "          \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def negatives():\n",
    "    rows = []\n",
    "     # Lists for negative average calculations\n",
    "    negGroup = ['Train neg', 'Val neg', 'Test neg', 'Val1 avg pred', 'Test1 avg pred', 'Train Cow+Pig Pred', 'Val Cow+Pig Pred', 'Test Cow+Pig Pred']\n",
    "    negValues = [pred_trainNeg.mean().iloc[0], pred_valNeg.mean().iloc[0], pred_testNeg.mean().iloc[0], pred_val1_df.mean().iloc[0], pred_test1_df.mean().iloc[0], pred_train5_df.mean().iloc[0], pred_val5_df.mean().iloc[0], pred_test5_df.mean().iloc[0]]\n",
    "    \n",
    "    # Add negative value averages\n",
    "    for group, negv in zip(negGroup, negValues):\n",
    "        rows.append({'Group': group, 'Metric': 'Avg Neg Prediction', 'Value': negv})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "mhc = 200\n",
    "\n",
    "all_results = []\n",
    "neg_results = []\n",
    "species_list = ['macaque', 'rat', 'cow', 'pig']\n",
    "model_list = ['bdbi7l3n', 'kf8188qf', 'cq45eb2s']\n",
    "\n",
    "for species in species_list:\n",
    "    for model in model_list:\n",
    "        model_dir = f'{model}_FINAL'\n",
    "\n",
    "        if model == 'kf8188qf':\n",
    "            mhc = 100\n",
    "        \n",
    "        # Load and process all dfs so correlate() function can access them\n",
    "        #############################################################################\n",
    "\n",
    "        # load TRAIN DFs\n",
    "        negTrainPath = f'/home/azstephe/liverRegression/regression_liver/data/splits/negatives/nonRat_liver_andMacaque_andCow_andPig_TRAIN_500bp.bed'\n",
    "        if species == 'macaque':\n",
    "            negTrainPath = f'/home/azstephe/liverRegression/regression_liver/data/splits/negatives/nonMacaque_liver_andRat_andCow_andPig_TRAIN_500bp.bed'\n",
    "        elif species == 'cow':\n",
    "            negTrainPath = f'/home/azstephe/liverRegression/regression_liver/data/splits/negatives/nonCow_liver_andMacaque_andRat_andPig_TRAIN_500bp.bed'\n",
    "        elif species == 'pig':\n",
    "            negTrainPath = f'/home/azstephe/liverRegression/regression_liver/data/splits/negatives/nonPig_liver_andMacaque_andRat_andCow_TRAIN_500bp.bed'\n",
    "        \n",
    "        pred_TRAIN = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_{species}_TRAIN.csv', header=None)\n",
    "        \n",
    "        trainPos = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/splits/logPos/{species}_liver_TRAINONLY.narrowPeak', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        trainNeg = pd.read_csv(negTrainPath, header=None, delim_whitespace=True).iloc[:,4]\n",
    "\n",
    "        trainPos_len = 2*len(trainPos)\n",
    "        trainNeg_len = 2*len(trainNeg)\n",
    "        \n",
    "        if len(pred_TRAIN) != trainPos_len+trainNeg_len:\n",
    "            print(f\"ERROR TRAIN ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_trainPos = pd.concat([trainPos, trainPos]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_trainNeg = pd.concat([trainNeg, trainNeg]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_trainPos = pred_TRAIN.head(trainPos_len)\n",
    "        pred_trainNeg = pred_TRAIN.tail(trainNeg_len)\n",
    "\n",
    "        #############################################################################\n",
    "\n",
    "        negValPath = f'/home/azstephe/liverRegression/regression_liver/data/splits/negatives/nonRat_liver_andMacaque_andCow_andPig_VAL_500bp.bed'\n",
    "        if species == 'macaque':\n",
    "            negValPath = f'/home/azstephe/liverRegression/regression_liver/data/splits/negatives/nonMacaque_liver_andRat_andCow_andPig_VAL_500bp.bed'\n",
    "        elif species == 'cow':\n",
    "            negValPath = f'/home/azstephe/liverRegression/regression_liver/data/splits/negatives/nonCow_liver_andMacaque_andRat_andPig_VAL_500bp.bed'\n",
    "        elif species == 'pig':\n",
    "            negValPath = f'/home/azstephe/liverRegression/regression_liver/data/splits/negatives/nonPig_liver_andMacaque_andRat_andCow_VAL_500bp.bed'\n",
    "        \n",
    "        # load VAL ORTHO DFs\n",
    "        pred_VAL_ortho = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_{species}_VAL_orthologs.csv', header=None)\n",
    "        \n",
    "        valPos = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/splits/logPos/{species}_liver_VAL.narrowPeak', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        valNeg = pd.read_csv(negValPath, header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        valPos_len = 2*len(valPos)\n",
    "        valNeg_len = 2*len(valNeg)\n",
    "        \n",
    "        if len(pred_VAL_ortho) != valPos_len+valNeg_len:\n",
    "            print(f\"ERROR VALORTHO ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_valPos = pd.concat([valPos, valPos]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_valNeg = pd.concat([valNeg, valNeg]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_valPos = pred_VAL_ortho.head(valPos_len)\n",
    "        pred_valNeg = pred_VAL_ortho.tail(valNeg_len)\n",
    "\n",
    "        #############################################################################\n",
    "\n",
    "        # load TEST ORTHO DFs\n",
    "        pred_TEST_ortho = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_{species}_TEST_orthologs.csv', header=None)\n",
    "        \n",
    "        testPos = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_pos_LiuAll/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        testNeg = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/neg/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        testPos_len = 2*len(testPos)\n",
    "        testNeg_len = 2*len(testNeg)\n",
    "        \n",
    "        if len(pred_TEST_ortho) != testPos_len+testNeg_len:\n",
    "            print(f\"ERROR TEST ORTHO ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_testPos = pd.concat([testPos, testPos]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_testNeg = pd.concat([testNeg, testNeg]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_testPos = pred_TEST_ortho.head(testPos_len)\n",
    "        pred_testNeg = pred_TEST_ortho.tail(testNeg_len)\n",
    "\n",
    "        #############################################################################\n",
    "        # load VAL DFs\n",
    "        pred_VAL = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_{species}_VAL.csv', header=None)\n",
    "        \n",
    "        val1_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/val_splits/val1/{species}_liver_VAL_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        val2_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/splits/log_val2/{species}_liver_VAL.narrowPeak', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        val3_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/splits/log_val3/{species}_liver_VAL.narrowPeak', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        val1_len = 2*len(val1_df)\n",
    "        val2_len = 2*len(val2_df)\n",
    "        val3_len = 2*len(val3_df)\n",
    "        \n",
    "        if len(pred_VAL) != val1_len+val2_len+val3_len:\n",
    "            print(f\"ERROR VAL ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_val1_df = pd.concat([val1_df, val1_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_val2_df = pd.concat([val2_df, val2_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_val3_df = pd.concat([val3_df, val3_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_val1_df = pred_VAL.head(val1_len)\n",
    "        pred_val2_df = pred_VAL.iloc[val1_len:val1_len + val2_len]\n",
    "        pred_val3_df = pred_VAL.tail(val3_len)\n",
    "\n",
    "        #############################################################################\n",
    "        # load TEST DFs\n",
    "        pred_TEST = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_{species}_TEST.csv', header=None)\n",
    "        \n",
    "        test1_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_LiuAll_test1/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        test2_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_test2/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        test3_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_test3/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        test1_len = 2*len(test1_df)\n",
    "        test2_len = 2*len(test2_df)\n",
    "        test3_len = 2*len(test3_df)\n",
    "        \n",
    "        if len(pred_TEST) != test1_len+test2_len+test3_len:\n",
    "            print(f\"ERROR TEST ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_test1_df = pd.concat([test1_df, test1_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_test2_df = pd.concat([test2_df, test2_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_test3_df = pd.concat([test3_df, test3_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_test1_df = pred_TEST.head(test1_len)\n",
    "        pred_test2_df = pred_TEST.iloc[test1_len:test1_len + test2_len]\n",
    "        pred_test3_df = pred_TEST.tail(test3_len)\n",
    "\n",
    "        #############################################################################\n",
    "        # load cow+pig TRAIN DFs\n",
    "        pred_cow_pig_TRAIN = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_cow_pig_TRAIN.csv', header=None)\n",
    "        \n",
    "        train4Pos_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/splits/cow_pig/cow_pig_liver_pos_mouse_macaque_rat_closed_TRAIN_chromName_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        train5Neg_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/splits/cow_pig/cow_pig_liver_neg_mouse_macaque_rat_open_TRAIN_chromName_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        train4_len = 2*len(train4Pos_df)\n",
    "        train5_len = 2*len(train5Neg_df)\n",
    "        \n",
    "        if len(pred_cow_pig_TRAIN) != train4_len+train5_len:\n",
    "            print(f\"ERROR TEST ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_train4_df = pd.concat([train4Pos_df, train4Pos_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_train5_df = pd.concat([train5Neg_df, train5Neg_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_train4_df = pred_cow_pig_TRAIN.head(train4_len)\n",
    "        pred_train5_df = pred_cow_pig_TRAIN.tail(train5_len)\n",
    "\n",
    "        #############################################################################\n",
    "        # load cow+pig VAL DFs\n",
    "        pred_cow_pig_VAL = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_cow_pig_VAL.csv', header=None)\n",
    "        \n",
    "        val4Pos_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/splits/cow_pig/cow_pig_liver_pos_mouse_macaque_rat_closed_VAL_chromName_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        val5Neg_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/splits/cow_pig/cow_pig_liver_neg_mouse_macaque_rat_open_VAL_chromName_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        val4_len = 2*len(val4Pos_df)\n",
    "        val5_len = 2*len(val5Neg_df)\n",
    "        \n",
    "        if len(pred_cow_pig_VAL) != val4_len+val5_len:\n",
    "            print(f\"ERROR TEST ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_val4_df = pd.concat([val4Pos_df, val4Pos_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_val5_df = pd.concat([val5Neg_df, val5Neg_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_val4_df = pred_cow_pig_VAL.head(val4_len)\n",
    "        pred_val5_df = pred_cow_pig_VAL.tail(val5_len)\n",
    "        \n",
    "        #############################################################################\n",
    "\n",
    "        # load TEST DFs\n",
    "        pred_cow_pig_TEST = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_cow_pig_TEST.csv', header=None)\n",
    "        \n",
    "        test4Pos_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_test4/cow_pig_liver_pos_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        test5Neg_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_test5/cow_pig_liver_neg_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        test4_len = 2*len(test4Pos_df)\n",
    "        test5_len = 2*len(test5Neg_df)\n",
    "        \n",
    "        if len(pred_cow_pig_TEST) != test4_len+test5_len:\n",
    "            print(f\"ERROR TEST ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_test4_df = pd.concat([test4Pos_df, test4Pos_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_test5_df = pd.concat([test5Neg_df, test5Neg_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_test4_df = pred_cow_pig_TEST.head(test4_len)\n",
    "        pred_test5_df = pred_cow_pig_TEST.tail(test5_len)\n",
    "        \n",
    "        # Call the correlate function which now uses the globally available DFs\n",
    "        corr_df = correlate(mhc)\n",
    "        corr_df['species'] = species\n",
    "        corr_df['model'] = model\n",
    "        all_results.append(corr_df)\n",
    "\n",
    "        neg_df = negatives()\n",
    "        neg_df['species'] = species\n",
    "        neg_df['model'] = model\n",
    "        neg_results.append(neg_df)\n",
    "\n",
    "# #############################################################################\n",
    "# FINAL PROCESSING\n",
    "# #############################################################################\n",
    "\n",
    "summary_df = pd.concat(all_results)\n",
    "\n",
    "summary_neg_df = pd.concat(neg_results)\n",
    "\n",
    "# Define the custom order to place negative groups at the bottom.\n",
    "custom_group_order = [\n",
    "    'Train', 'Validation', 'Test', 'Val2', 'Val3', 'Test2', 'Test3', 'Train Cow+Pig', 'Val Cow+Pig', 'Test Cow+Pig'\n",
    "]\n",
    "\n",
    "custom_group_order_neg = [\n",
    "    'Train neg', 'Val neg', 'Test neg', 'Val1 avg pred', 'Test1 avg pred', 'Train Cow+Pig Pred', 'Val Cow+Pig Pred', 'Test Cow+Pig Pred'\n",
    "]\n",
    "\n",
    "# Convert 'group' to a categorical type with the specified order.\n",
    "summary_df['Group'] = pd.Categorical(summary_df['Group'], categories=custom_group_order, ordered=True)\n",
    "summary_neg_df['Group'] = pd.Categorical(summary_neg_df['Group'], categories=custom_group_order_neg, ordered=True)\n",
    "\n",
    "\n",
    "# Pivot so each model is a column\n",
    "pivot_df = summary_df.pivot_table(\n",
    "    index=['species', 'Group', 'Metric'],\n",
    "    columns='model',\n",
    "    values='Value'\n",
    ")\n",
    "\n",
    "pivot_neg_df = summary_neg_df.pivot_table(\n",
    "    index=['species', 'Group', 'Metric'],\n",
    "    columns='model',\n",
    "    values='Value'\n",
    ")\n",
    "\n",
    "# Sort the index to maintain a logical order (will now use the custom group order)\n",
    "pivot_df = pivot_df.sort_index(level=['species', 'Group', 'Metric'])\n",
    "pivot_neg_df = pivot_neg_df.sort_index(level=['species', 'Group', 'Metric'])\n",
    "\n",
    "pivot_df_reordered = pivot_df[model_list]\n",
    "pivot_neg_df_reordered = pivot_neg_df[model_list]\n",
    "\n",
    "metric_vars = ['Pearson', 'Pearson_p', 'Spearman', 'Spearman_p', 'MSE']\n",
    "pivot_df_reordered = pivot_df_reordered.reindex(metric_vars, level='Metric')\n",
    "\n",
    "# Loop through each model's column to apply the formatting\n",
    "for col in pivot_df_reordered.columns:\n",
    "    pivot_df_reordered[col] = pivot_df_reordered.apply(\n",
    "        # Access the 'metric' from the index using row.name[2]\n",
    "        # (assuming it's the 3rd level of your index)\n",
    "        lambda row: format_value(row.name[2], row[col]),\n",
    "        axis=1)\n",
    "\n",
    "display(pivot_df_reordered)\n",
    "\n",
    "output_filename = '/home/azstephe/liverRegression/regression_liver/data/figs/tables/135log_model_eval_table_FINAL_mse.tsv'\n",
    "pivot_df_reordered.to_csv(output_filename, sep='\\t', float_format='%.3f')\n",
    "\n",
    "# output_neg_filename = '/home/azstephe/liverRegression/regression_liver/data/figs/tables/135log_model_neg_table_FINAL.tsv'\n",
    "# pivot_neg_df_reordered.to_csv(output_neg_filename, sep='\\t', float_format='%.3f')\n",
    "\n",
    "# print(f'Results successfully saved to: {output_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db190c4f-1049-4459-ab50-8daf0b0574ed",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Final Pivoted Results ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_3a673\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"index_name level0\" >model</th>\n",
       "      <th id=\"T_3a673_level0_col0\" class=\"col_heading level0 col0\" >im88hepv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >species</th>\n",
       "      <th class=\"index_name level1\" >Group</th>\n",
       "      <th class=\"index_name level2\" >Metric</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"8\">cow</th>\n",
       "      <th id=\"T_3a673_level1_row0\" class=\"row_heading level1 row0\" rowspan=\"2\">Test</th>\n",
       "      <th id=\"T_3a673_level2_row0\" class=\"row_heading level2 row0\" >Pearson</th>\n",
       "      <td id=\"T_3a673_row0_col0\" class=\"data row0 col0\" >0.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level2_row1\" class=\"row_heading level2 row1\" >Spearman</th>\n",
       "      <td id=\"T_3a673_row1_col0\" class=\"data row1 col0\" >0.430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level1_row2\" class=\"row_heading level1 row2\" rowspan=\"2\">Test2</th>\n",
       "      <th id=\"T_3a673_level2_row2\" class=\"row_heading level2 row2\" >Pearson</th>\n",
       "      <td id=\"T_3a673_row2_col0\" class=\"data row2 col0\" >0.370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level2_row3\" class=\"row_heading level2 row3\" >Spearman</th>\n",
       "      <td id=\"T_3a673_row3_col0\" class=\"data row3 col0\" >0.380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level1_row4\" class=\"row_heading level1 row4\" rowspan=\"2\">Test3</th>\n",
       "      <th id=\"T_3a673_level2_row4\" class=\"row_heading level2 row4\" >Pearson</th>\n",
       "      <td id=\"T_3a673_row4_col0\" class=\"data row4 col0\" >0.371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level2_row5\" class=\"row_heading level2 row5\" >Spearman</th>\n",
       "      <td id=\"T_3a673_row5_col0\" class=\"data row5 col0\" >0.370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level1_row6\" class=\"row_heading level1 row6\" rowspan=\"2\">Test Cow+Pig</th>\n",
       "      <th id=\"T_3a673_level2_row6\" class=\"row_heading level2 row6\" >Pearson</th>\n",
       "      <td id=\"T_3a673_row6_col0\" class=\"data row6 col0\" >0.459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level2_row7\" class=\"row_heading level2 row7\" >Spearman</th>\n",
       "      <td id=\"T_3a673_row7_col0\" class=\"data row7 col0\" >0.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level0_row8\" class=\"row_heading level0 row8\" rowspan=\"8\">macaque</th>\n",
       "      <th id=\"T_3a673_level1_row8\" class=\"row_heading level1 row8\" rowspan=\"2\">Test</th>\n",
       "      <th id=\"T_3a673_level2_row8\" class=\"row_heading level2 row8\" >Pearson</th>\n",
       "      <td id=\"T_3a673_row8_col0\" class=\"data row8 col0\" >0.348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level2_row9\" class=\"row_heading level2 row9\" >Spearman</th>\n",
       "      <td id=\"T_3a673_row9_col0\" class=\"data row9 col0\" >0.359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level1_row10\" class=\"row_heading level1 row10\" rowspan=\"2\">Test2</th>\n",
       "      <th id=\"T_3a673_level2_row10\" class=\"row_heading level2 row10\" >Pearson</th>\n",
       "      <td id=\"T_3a673_row10_col0\" class=\"data row10 col0\" >0.289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level2_row11\" class=\"row_heading level2 row11\" >Spearman</th>\n",
       "      <td id=\"T_3a673_row11_col0\" class=\"data row11 col0\" >0.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level1_row12\" class=\"row_heading level1 row12\" rowspan=\"2\">Test3</th>\n",
       "      <th id=\"T_3a673_level2_row12\" class=\"row_heading level2 row12\" >Pearson</th>\n",
       "      <td id=\"T_3a673_row12_col0\" class=\"data row12 col0\" >0.362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level2_row13\" class=\"row_heading level2 row13\" >Spearman</th>\n",
       "      <td id=\"T_3a673_row13_col0\" class=\"data row13 col0\" >0.380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level1_row14\" class=\"row_heading level1 row14\" rowspan=\"2\">Test Cow+Pig</th>\n",
       "      <th id=\"T_3a673_level2_row14\" class=\"row_heading level2 row14\" >Pearson</th>\n",
       "      <td id=\"T_3a673_row14_col0\" class=\"data row14 col0\" >0.459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level2_row15\" class=\"row_heading level2 row15\" >Spearman</th>\n",
       "      <td id=\"T_3a673_row15_col0\" class=\"data row15 col0\" >0.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level0_row16\" class=\"row_heading level0 row16\" rowspan=\"8\">pig</th>\n",
       "      <th id=\"T_3a673_level1_row16\" class=\"row_heading level1 row16\" rowspan=\"2\">Test</th>\n",
       "      <th id=\"T_3a673_level2_row16\" class=\"row_heading level2 row16\" >Pearson</th>\n",
       "      <td id=\"T_3a673_row16_col0\" class=\"data row16 col0\" >0.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level2_row17\" class=\"row_heading level2 row17\" >Spearman</th>\n",
       "      <td id=\"T_3a673_row17_col0\" class=\"data row17 col0\" >0.430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level1_row18\" class=\"row_heading level1 row18\" rowspan=\"2\">Test2</th>\n",
       "      <th id=\"T_3a673_level2_row18\" class=\"row_heading level2 row18\" >Pearson</th>\n",
       "      <td id=\"T_3a673_row18_col0\" class=\"data row18 col0\" >0.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level2_row19\" class=\"row_heading level2 row19\" >Spearman</th>\n",
       "      <td id=\"T_3a673_row19_col0\" class=\"data row19 col0\" >0.371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level1_row20\" class=\"row_heading level1 row20\" rowspan=\"2\">Test3</th>\n",
       "      <th id=\"T_3a673_level2_row20\" class=\"row_heading level2 row20\" >Pearson</th>\n",
       "      <td id=\"T_3a673_row20_col0\" class=\"data row20 col0\" >0.376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level2_row21\" class=\"row_heading level2 row21\" >Spearman</th>\n",
       "      <td id=\"T_3a673_row21_col0\" class=\"data row21 col0\" >0.381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level1_row22\" class=\"row_heading level1 row22\" rowspan=\"2\">Test Cow+Pig</th>\n",
       "      <th id=\"T_3a673_level2_row22\" class=\"row_heading level2 row22\" >Pearson</th>\n",
       "      <td id=\"T_3a673_row22_col0\" class=\"data row22 col0\" >0.459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level2_row23\" class=\"row_heading level2 row23\" >Spearman</th>\n",
       "      <td id=\"T_3a673_row23_col0\" class=\"data row23 col0\" >0.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level0_row24\" class=\"row_heading level0 row24\" rowspan=\"8\">rat</th>\n",
       "      <th id=\"T_3a673_level1_row24\" class=\"row_heading level1 row24\" rowspan=\"2\">Test</th>\n",
       "      <th id=\"T_3a673_level2_row24\" class=\"row_heading level2 row24\" >Pearson</th>\n",
       "      <td id=\"T_3a673_row24_col0\" class=\"data row24 col0\" >0.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level2_row25\" class=\"row_heading level2 row25\" >Spearman</th>\n",
       "      <td id=\"T_3a673_row25_col0\" class=\"data row25 col0\" >0.331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level1_row26\" class=\"row_heading level1 row26\" rowspan=\"2\">Test2</th>\n",
       "      <th id=\"T_3a673_level2_row26\" class=\"row_heading level2 row26\" >Pearson</th>\n",
       "      <td id=\"T_3a673_row26_col0\" class=\"data row26 col0\" >0.274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level2_row27\" class=\"row_heading level2 row27\" >Spearman</th>\n",
       "      <td id=\"T_3a673_row27_col0\" class=\"data row27 col0\" >0.259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level1_row28\" class=\"row_heading level1 row28\" rowspan=\"2\">Test3</th>\n",
       "      <th id=\"T_3a673_level2_row28\" class=\"row_heading level2 row28\" >Pearson</th>\n",
       "      <td id=\"T_3a673_row28_col0\" class=\"data row28 col0\" >0.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level2_row29\" class=\"row_heading level2 row29\" >Spearman</th>\n",
       "      <td id=\"T_3a673_row29_col0\" class=\"data row29 col0\" >0.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level1_row30\" class=\"row_heading level1 row30\" rowspan=\"2\">Test Cow+Pig</th>\n",
       "      <th id=\"T_3a673_level2_row30\" class=\"row_heading level2 row30\" >Pearson</th>\n",
       "      <td id=\"T_3a673_row30_col0\" class=\"data row30 col0\" >0.459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3a673_level2_row31\" class=\"row_heading level2 row31\" >Spearman</th>\n",
       "      <td id=\"T_3a673_row31_col0\" class=\"data row31 col0\" >0.484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff69a2f3d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_f9f91\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"index_name level0\" >model</th>\n",
       "      <th id=\"T_f9f91_level0_col0\" class=\"col_heading level0 col0\" >im88hepv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >species</th>\n",
       "      <th class=\"index_name level1\" >Group</th>\n",
       "      <th class=\"index_name level2\" >Metric</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f9f91_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"3\">cow</th>\n",
       "      <th id=\"T_f9f91_level1_row0\" class=\"row_heading level1 row0\" >Test neg</th>\n",
       "      <th id=\"T_f9f91_level2_row0\" class=\"row_heading level2 row0\" >Avg Neg Prediction</th>\n",
       "      <td id=\"T_f9f91_row0_col0\" class=\"data row0 col0\" >0.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9f91_level1_row1\" class=\"row_heading level1 row1\" >Test1 avg pred</th>\n",
       "      <th id=\"T_f9f91_level2_row1\" class=\"row_heading level2 row1\" >Avg Neg Prediction</th>\n",
       "      <td id=\"T_f9f91_row1_col0\" class=\"data row1 col0\" >0.642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9f91_level1_row2\" class=\"row_heading level1 row2\" >Test Cow+Pig Pred</th>\n",
       "      <th id=\"T_f9f91_level2_row2\" class=\"row_heading level2 row2\" >Avg Neg Prediction</th>\n",
       "      <td id=\"T_f9f91_row2_col0\" class=\"data row2 col0\" >0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9f91_level0_row3\" class=\"row_heading level0 row3\" rowspan=\"3\">macaque</th>\n",
       "      <th id=\"T_f9f91_level1_row3\" class=\"row_heading level1 row3\" >Test neg</th>\n",
       "      <th id=\"T_f9f91_level2_row3\" class=\"row_heading level2 row3\" >Avg Neg Prediction</th>\n",
       "      <td id=\"T_f9f91_row3_col0\" class=\"data row3 col0\" >0.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9f91_level1_row4\" class=\"row_heading level1 row4\" >Test1 avg pred</th>\n",
       "      <th id=\"T_f9f91_level2_row4\" class=\"row_heading level2 row4\" >Avg Neg Prediction</th>\n",
       "      <td id=\"T_f9f91_row4_col0\" class=\"data row4 col0\" >0.638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9f91_level1_row5\" class=\"row_heading level1 row5\" >Test Cow+Pig Pred</th>\n",
       "      <th id=\"T_f9f91_level2_row5\" class=\"row_heading level2 row5\" >Avg Neg Prediction</th>\n",
       "      <td id=\"T_f9f91_row5_col0\" class=\"data row5 col0\" >0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9f91_level0_row6\" class=\"row_heading level0 row6\" rowspan=\"3\">pig</th>\n",
       "      <th id=\"T_f9f91_level1_row6\" class=\"row_heading level1 row6\" >Test neg</th>\n",
       "      <th id=\"T_f9f91_level2_row6\" class=\"row_heading level2 row6\" >Avg Neg Prediction</th>\n",
       "      <td id=\"T_f9f91_row6_col0\" class=\"data row6 col0\" >0.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9f91_level1_row7\" class=\"row_heading level1 row7\" >Test1 avg pred</th>\n",
       "      <th id=\"T_f9f91_level2_row7\" class=\"row_heading level2 row7\" >Avg Neg Prediction</th>\n",
       "      <td id=\"T_f9f91_row7_col0\" class=\"data row7 col0\" >0.638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9f91_level1_row8\" class=\"row_heading level1 row8\" >Test Cow+Pig Pred</th>\n",
       "      <th id=\"T_f9f91_level2_row8\" class=\"row_heading level2 row8\" >Avg Neg Prediction</th>\n",
       "      <td id=\"T_f9f91_row8_col0\" class=\"data row8 col0\" >0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9f91_level0_row9\" class=\"row_heading level0 row9\" rowspan=\"3\">rat</th>\n",
       "      <th id=\"T_f9f91_level1_row9\" class=\"row_heading level1 row9\" >Test neg</th>\n",
       "      <th id=\"T_f9f91_level2_row9\" class=\"row_heading level2 row9\" >Avg Neg Prediction</th>\n",
       "      <td id=\"T_f9f91_row9_col0\" class=\"data row9 col0\" >0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9f91_level1_row10\" class=\"row_heading level1 row10\" >Test1 avg pred</th>\n",
       "      <th id=\"T_f9f91_level2_row10\" class=\"row_heading level2 row10\" >Avg Neg Prediction</th>\n",
       "      <td id=\"T_f9f91_row10_col0\" class=\"data row10 col0\" >0.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f9f91_level1_row11\" class=\"row_heading level1 row11\" >Test Cow+Pig Pred</th>\n",
       "      <th id=\"T_f9f91_level2_row11\" class=\"row_heading level2 row11\" >Avg Neg Prediction</th>\n",
       "      <td id=\"T_f9f91_row11_col0\" class=\"data row11 col0\" >0.708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff69a3a95e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2KB MODEL\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "def correlate():\n",
    "    rows = []\n",
    "    # Lists for correlation calculations\n",
    "    groups = ['Test','Test2', 'Test3', 'Test Cow+Pig']\n",
    "    preds = [pred_testPos, pred_test2_df, pred_test3_df, pred_test4_df]\n",
    "    trues = [doubled_testPos, doubled_test2_df, doubled_test3_df, doubled_test4_df]\n",
    "\n",
    "    # Calculate correlations\n",
    "    for group, pred_df, true_df in zip(groups, preds, trues):\n",
    "        x = true_df.squeeze()\n",
    "        y = pred_df.squeeze()\n",
    "        pearson, _ = scipy.stats.pearsonr(x, y)\n",
    "        spearman, _ = scipy.stats.spearmanr(x, y)\n",
    "        rows.append({'Group': group, 'Metric': 'Pearson', 'Value': pearson})\n",
    "        rows.append({'Group': group, 'Metric': 'Spearman', 'Value': spearman})\n",
    "          \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def negatives():\n",
    "    rows = []\n",
    "     # Lists for negative average calculations\n",
    "    negGroup = ['Test neg', 'Test1 avg pred', 'Test Cow+Pig Pred']\n",
    "    negValues = [pred_testNeg.mean().iloc[0], pred_test1_df.mean().iloc[0], pred_test5_df.mean().iloc[0]]\n",
    "    \n",
    "    # Add negative value averages\n",
    "    for group, negv in zip(negGroup, negValues):\n",
    "        rows.append({'Group': group, 'Metric': 'Avg Neg Prediction', 'Value': negv})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# --- Main Script ---\n",
    "all_results = []\n",
    "neg_results = []\n",
    "species_list = ['macaque', 'rat', 'cow', 'pig']\n",
    "model_list = ['im88hepv']\n",
    "\n",
    "for species in species_list:\n",
    "    for model in model_list:\n",
    "        model_dir = f'{model}_FINAL'\n",
    "        #############################################################################\n",
    "\n",
    "        # load TEST ORTHO DFs\n",
    "        pred_TEST_ortho = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_{species}_TEST_orthologs.csv', header=None)\n",
    "        \n",
    "        testPos = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits_2kb/log_pos_LiuAll/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        testNeg = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits_2kb/neg/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        testPos_len = 2*len(testPos)\n",
    "        testNeg_len = 2*len(testNeg)\n",
    "        \n",
    "        if len(pred_TEST_ortho) != testPos_len+testNeg_len:\n",
    "            print(f\"ERROR TEST ORTHO ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_testPos = pd.concat([testPos, testPos]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_testNeg = pd.concat([testNeg, testNeg]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_testPos = pred_TEST_ortho.head(testPos_len)\n",
    "        pred_testNeg = pred_TEST_ortho.tail(testNeg_len)\n",
    "\n",
    "\n",
    "        #############################################################################\n",
    "        # load TEST DFs\n",
    "        pred_TEST = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_{species}_TEST.csv', header=None)\n",
    "        \n",
    "        test1_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits_2kb/log_LiuAll_test1/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        test2_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits_2kb/log_test2/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        test3_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits_2kb/log_test3/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        test1_len = 2*len(test1_df)\n",
    "        test2_len = 2*len(test2_df)\n",
    "        test3_len = 2*len(test3_df)\n",
    "        \n",
    "        if len(pred_TEST) != test1_len+test2_len+test3_len:\n",
    "            print(f\"ERROR TEST ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_test1_df = pd.concat([test1_df, test1_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_test2_df = pd.concat([test2_df, test2_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_test3_df = pd.concat([test3_df, test3_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_test1_df = pred_TEST.head(test1_len)\n",
    "        pred_test2_df = pred_TEST.iloc[test1_len:test1_len + test2_len]\n",
    "        pred_test3_df = pred_TEST.tail(test3_len)\n",
    "        \n",
    "        #############################################################################\n",
    "        # load TEST DFs\n",
    "        pred_cow_pig_TEST = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_cow_pig_TEST.csv', header=None)\n",
    "        \n",
    "        test4Pos_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits_2kb/log_test4/cow_pig_liver_pos_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        test5Neg_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits_2kb/log_test5/cow_pig_liver_neg_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        test4_len = 2*len(test4Pos_df)\n",
    "        test5_len = 2*len(test5Neg_df)\n",
    "        \n",
    "        if len(pred_cow_pig_TEST) != test4_len+test5_len:\n",
    "            print(f\"ERROR TEST ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_test4_df = pd.concat([test4Pos_df, test4Pos_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_test5_df = pd.concat([test5Neg_df, test5Neg_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_test4_df = pred_cow_pig_TEST.head(test4_len)\n",
    "        pred_test5_df = pred_cow_pig_TEST.tail(test5_len)\n",
    "        \n",
    "        # Call the correlate function which now uses the globally available DFs\n",
    "        corr_df = correlate()\n",
    "        corr_df['species'] = species\n",
    "        corr_df['model'] = model\n",
    "        all_results.append(corr_df)\n",
    "\n",
    "        neg_df = negatives()\n",
    "        neg_df['species'] = species\n",
    "        neg_df['model'] = model\n",
    "        neg_results.append(neg_df)\n",
    "\n",
    "# #############################################################################\n",
    "# FINAL PROCESSING\n",
    "# #############################################################################\n",
    "\n",
    "summary_df = pd.concat(all_results)\n",
    "\n",
    "summary_neg_df = pd.concat(neg_results)\n",
    "\n",
    "# Define the custom order to place negative groups at the bottom.\n",
    "custom_group_order = [\n",
    "    'Test', 'Test2', 'Test3','Test Cow+Pig'\n",
    "]\n",
    "\n",
    "custom_group_order_neg = [\n",
    "    'Test neg', 'Test1 avg pred','Test Cow+Pig Pred'\n",
    "]\n",
    "\n",
    "# Convert 'group' to a categorical type with the specified order.\n",
    "summary_df['Group'] = pd.Categorical(summary_df['Group'], categories=custom_group_order, ordered=True)\n",
    "summary_neg_df['Group'] = pd.Categorical(summary_neg_df['Group'], categories=custom_group_order_neg, ordered=True)\n",
    "\n",
    "\n",
    "# Pivot so each model is a column\n",
    "pivot_df = summary_df.pivot_table(\n",
    "    index=['species', 'Group', 'Metric'],\n",
    "    columns='model',\n",
    "    values='Value'\n",
    ")\n",
    "\n",
    "pivot_neg_df = summary_neg_df.pivot_table(\n",
    "    index=['species', 'Group', 'Metric'],\n",
    "    columns='model',\n",
    "    values='Value'\n",
    ")\n",
    "\n",
    "# Sort the index to maintain a logical order (will now use the custom group order)\n",
    "pivot_df = pivot_df.sort_index(level=['species', 'Group', 'Metric'])\n",
    "pivot_neg_df = pivot_neg_df.sort_index(level=['species', 'Group', 'Metric'])\n",
    "\n",
    "pivot_df_2kb = pivot_df[model_list]\n",
    "pivot_neg_df_2kb = pivot_neg_df[model_list]\n",
    "\n",
    "# Display the final pivoted DataFrame\n",
    "print(\"--- Final Pivoted Results ---\")\n",
    "display(pivot_df_2kb.style.format(\"{:.3f}\"))\n",
    "display(pivot_neg_df_2kb.style.format(\"{:.3f}\"))\n",
    "\n",
    "# print(f'Results successfully saved to: {output_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12d17fe2-4f41-4b38-872f-911a7f9224cd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Final Pivoted Results ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_366a5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"index_name level0\" >model</th>\n",
       "      <th id=\"T_366a5_level0_col0\" class=\"col_heading level0 col0\" >mcf297qb</th>\n",
       "      <th id=\"T_366a5_level0_col1\" class=\"col_heading level0 col1\" >7l12zan1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >species</th>\n",
       "      <th class=\"index_name level1\" >Group</th>\n",
       "      <th class=\"index_name level2\" >Metric</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"8\">cow</th>\n",
       "      <th id=\"T_366a5_level1_row0\" class=\"row_heading level1 row0\" rowspan=\"2\">Test</th>\n",
       "      <th id=\"T_366a5_level2_row0\" class=\"row_heading level2 row0\" >Pearson</th>\n",
       "      <td id=\"T_366a5_row0_col0\" class=\"data row0 col0\" >0.355</td>\n",
       "      <td id=\"T_366a5_row0_col1\" class=\"data row0 col1\" >0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level2_row1\" class=\"row_heading level2 row1\" >Spearman</th>\n",
       "      <td id=\"T_366a5_row1_col0\" class=\"data row1 col0\" >0.366</td>\n",
       "      <td id=\"T_366a5_row1_col1\" class=\"data row1 col1\" >0.383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level1_row2\" class=\"row_heading level1 row2\" rowspan=\"2\">Test2</th>\n",
       "      <th id=\"T_366a5_level2_row2\" class=\"row_heading level2 row2\" >Pearson</th>\n",
       "      <td id=\"T_366a5_row2_col0\" class=\"data row2 col0\" >0.360</td>\n",
       "      <td id=\"T_366a5_row2_col1\" class=\"data row2 col1\" >0.383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level2_row3\" class=\"row_heading level2 row3\" >Spearman</th>\n",
       "      <td id=\"T_366a5_row3_col0\" class=\"data row3 col0\" >0.369</td>\n",
       "      <td id=\"T_366a5_row3_col1\" class=\"data row3 col1\" >0.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level1_row4\" class=\"row_heading level1 row4\" rowspan=\"2\">Test3</th>\n",
       "      <th id=\"T_366a5_level2_row4\" class=\"row_heading level2 row4\" >Pearson</th>\n",
       "      <td id=\"T_366a5_row4_col0\" class=\"data row4 col0\" >0.283</td>\n",
       "      <td id=\"T_366a5_row4_col1\" class=\"data row4 col1\" >0.298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level2_row5\" class=\"row_heading level2 row5\" >Spearman</th>\n",
       "      <td id=\"T_366a5_row5_col0\" class=\"data row5 col0\" >0.284</td>\n",
       "      <td id=\"T_366a5_row5_col1\" class=\"data row5 col1\" >0.299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level1_row6\" class=\"row_heading level1 row6\" rowspan=\"2\">Test Cow+Pig</th>\n",
       "      <th id=\"T_366a5_level2_row6\" class=\"row_heading level2 row6\" >Pearson</th>\n",
       "      <td id=\"T_366a5_row6_col0\" class=\"data row6 col0\" >0.422</td>\n",
       "      <td id=\"T_366a5_row6_col1\" class=\"data row6 col1\" >0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level2_row7\" class=\"row_heading level2 row7\" >Spearman</th>\n",
       "      <td id=\"T_366a5_row7_col0\" class=\"data row7 col0\" >0.455</td>\n",
       "      <td id=\"T_366a5_row7_col1\" class=\"data row7 col1\" >0.449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level0_row8\" class=\"row_heading level0 row8\" rowspan=\"8\">macaque</th>\n",
       "      <th id=\"T_366a5_level1_row8\" class=\"row_heading level1 row8\" rowspan=\"2\">Test</th>\n",
       "      <th id=\"T_366a5_level2_row8\" class=\"row_heading level2 row8\" >Pearson</th>\n",
       "      <td id=\"T_366a5_row8_col0\" class=\"data row8 col0\" >0.371</td>\n",
       "      <td id=\"T_366a5_row8_col1\" class=\"data row8 col1\" >0.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level2_row9\" class=\"row_heading level2 row9\" >Spearman</th>\n",
       "      <td id=\"T_366a5_row9_col0\" class=\"data row9 col0\" >0.372</td>\n",
       "      <td id=\"T_366a5_row9_col1\" class=\"data row9 col1\" >0.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level1_row10\" class=\"row_heading level1 row10\" rowspan=\"2\">Test2</th>\n",
       "      <th id=\"T_366a5_level2_row10\" class=\"row_heading level2 row10\" >Pearson</th>\n",
       "      <td id=\"T_366a5_row10_col0\" class=\"data row10 col0\" >0.325</td>\n",
       "      <td id=\"T_366a5_row10_col1\" class=\"data row10 col1\" >0.282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level2_row11\" class=\"row_heading level2 row11\" >Spearman</th>\n",
       "      <td id=\"T_366a5_row11_col0\" class=\"data row11 col0\" >0.305</td>\n",
       "      <td id=\"T_366a5_row11_col1\" class=\"data row11 col1\" >0.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level1_row12\" class=\"row_heading level1 row12\" rowspan=\"2\">Test3</th>\n",
       "      <th id=\"T_366a5_level2_row12\" class=\"row_heading level2 row12\" >Pearson</th>\n",
       "      <td id=\"T_366a5_row12_col0\" class=\"data row12 col0\" >0.417</td>\n",
       "      <td id=\"T_366a5_row12_col1\" class=\"data row12 col1\" >0.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level2_row13\" class=\"row_heading level2 row13\" >Spearman</th>\n",
       "      <td id=\"T_366a5_row13_col0\" class=\"data row13 col0\" >0.424</td>\n",
       "      <td id=\"T_366a5_row13_col1\" class=\"data row13 col1\" >0.380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level1_row14\" class=\"row_heading level1 row14\" rowspan=\"2\">Test Cow+Pig</th>\n",
       "      <th id=\"T_366a5_level2_row14\" class=\"row_heading level2 row14\" >Pearson</th>\n",
       "      <td id=\"T_366a5_row14_col0\" class=\"data row14 col0\" >0.422</td>\n",
       "      <td id=\"T_366a5_row14_col1\" class=\"data row14 col1\" >0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level2_row15\" class=\"row_heading level2 row15\" >Spearman</th>\n",
       "      <td id=\"T_366a5_row15_col0\" class=\"data row15 col0\" >0.455</td>\n",
       "      <td id=\"T_366a5_row15_col1\" class=\"data row15 col1\" >0.449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level0_row16\" class=\"row_heading level0 row16\" rowspan=\"8\">pig</th>\n",
       "      <th id=\"T_366a5_level1_row16\" class=\"row_heading level1 row16\" rowspan=\"2\">Test</th>\n",
       "      <th id=\"T_366a5_level2_row16\" class=\"row_heading level2 row16\" >Pearson</th>\n",
       "      <td id=\"T_366a5_row16_col0\" class=\"data row16 col0\" >0.349</td>\n",
       "      <td id=\"T_366a5_row16_col1\" class=\"data row16 col1\" >0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level2_row17\" class=\"row_heading level2 row17\" >Spearman</th>\n",
       "      <td id=\"T_366a5_row17_col0\" class=\"data row17 col0\" >0.358</td>\n",
       "      <td id=\"T_366a5_row17_col1\" class=\"data row17 col1\" >0.382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level1_row18\" class=\"row_heading level1 row18\" rowspan=\"2\">Test2</th>\n",
       "      <th id=\"T_366a5_level2_row18\" class=\"row_heading level2 row18\" >Pearson</th>\n",
       "      <td id=\"T_366a5_row18_col0\" class=\"data row18 col0\" >0.293</td>\n",
       "      <td id=\"T_366a5_row18_col1\" class=\"data row18 col1\" >0.331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level2_row19\" class=\"row_heading level2 row19\" >Spearman</th>\n",
       "      <td id=\"T_366a5_row19_col0\" class=\"data row19 col0\" >0.280</td>\n",
       "      <td id=\"T_366a5_row19_col1\" class=\"data row19 col1\" >0.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level1_row20\" class=\"row_heading level1 row20\" rowspan=\"2\">Test3</th>\n",
       "      <th id=\"T_366a5_level2_row20\" class=\"row_heading level2 row20\" >Pearson</th>\n",
       "      <td id=\"T_366a5_row20_col0\" class=\"data row20 col0\" >0.329</td>\n",
       "      <td id=\"T_366a5_row20_col1\" class=\"data row20 col1\" >0.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level2_row21\" class=\"row_heading level2 row21\" >Spearman</th>\n",
       "      <td id=\"T_366a5_row21_col0\" class=\"data row21 col0\" >0.329</td>\n",
       "      <td id=\"T_366a5_row21_col1\" class=\"data row21 col1\" >0.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level1_row22\" class=\"row_heading level1 row22\" rowspan=\"2\">Test Cow+Pig</th>\n",
       "      <th id=\"T_366a5_level2_row22\" class=\"row_heading level2 row22\" >Pearson</th>\n",
       "      <td id=\"T_366a5_row22_col0\" class=\"data row22 col0\" >0.422</td>\n",
       "      <td id=\"T_366a5_row22_col1\" class=\"data row22 col1\" >0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level2_row23\" class=\"row_heading level2 row23\" >Spearman</th>\n",
       "      <td id=\"T_366a5_row23_col0\" class=\"data row23 col0\" >0.455</td>\n",
       "      <td id=\"T_366a5_row23_col1\" class=\"data row23 col1\" >0.449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level0_row24\" class=\"row_heading level0 row24\" rowspan=\"8\">rat</th>\n",
       "      <th id=\"T_366a5_level1_row24\" class=\"row_heading level1 row24\" rowspan=\"2\">Test</th>\n",
       "      <th id=\"T_366a5_level2_row24\" class=\"row_heading level2 row24\" >Pearson</th>\n",
       "      <td id=\"T_366a5_row24_col0\" class=\"data row24 col0\" >0.341</td>\n",
       "      <td id=\"T_366a5_row24_col1\" class=\"data row24 col1\" >0.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level2_row25\" class=\"row_heading level2 row25\" >Spearman</th>\n",
       "      <td id=\"T_366a5_row25_col0\" class=\"data row25 col0\" >0.335</td>\n",
       "      <td id=\"T_366a5_row25_col1\" class=\"data row25 col1\" >0.329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level1_row26\" class=\"row_heading level1 row26\" rowspan=\"2\">Test2</th>\n",
       "      <th id=\"T_366a5_level2_row26\" class=\"row_heading level2 row26\" >Pearson</th>\n",
       "      <td id=\"T_366a5_row26_col0\" class=\"data row26 col0\" >0.267</td>\n",
       "      <td id=\"T_366a5_row26_col1\" class=\"data row26 col1\" >0.251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level2_row27\" class=\"row_heading level2 row27\" >Spearman</th>\n",
       "      <td id=\"T_366a5_row27_col0\" class=\"data row27 col0\" >0.256</td>\n",
       "      <td id=\"T_366a5_row27_col1\" class=\"data row27 col1\" >0.236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level1_row28\" class=\"row_heading level1 row28\" rowspan=\"2\">Test3</th>\n",
       "      <th id=\"T_366a5_level2_row28\" class=\"row_heading level2 row28\" >Pearson</th>\n",
       "      <td id=\"T_366a5_row28_col0\" class=\"data row28 col0\" >0.324</td>\n",
       "      <td id=\"T_366a5_row28_col1\" class=\"data row28 col1\" >0.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level2_row29\" class=\"row_heading level2 row29\" >Spearman</th>\n",
       "      <td id=\"T_366a5_row29_col0\" class=\"data row29 col0\" >0.310</td>\n",
       "      <td id=\"T_366a5_row29_col1\" class=\"data row29 col1\" >0.313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level1_row30\" class=\"row_heading level1 row30\" rowspan=\"2\">Test Cow+Pig</th>\n",
       "      <th id=\"T_366a5_level2_row30\" class=\"row_heading level2 row30\" >Pearson</th>\n",
       "      <td id=\"T_366a5_row30_col0\" class=\"data row30 col0\" >0.422</td>\n",
       "      <td id=\"T_366a5_row30_col1\" class=\"data row30 col1\" >0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_366a5_level2_row31\" class=\"row_heading level2 row31\" >Spearman</th>\n",
       "      <td id=\"T_366a5_row31_col0\" class=\"data row31 col0\" >0.455</td>\n",
       "      <td id=\"T_366a5_row31_col1\" class=\"data row31 col1\" >0.449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff69a2d2a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_b2f42\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"index_name level0\" >model</th>\n",
       "      <th id=\"T_b2f42_level0_col0\" class=\"col_heading level0 col0\" >mcf297qb</th>\n",
       "      <th id=\"T_b2f42_level0_col1\" class=\"col_heading level0 col1\" >7l12zan1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >species</th>\n",
       "      <th class=\"index_name level1\" >Group</th>\n",
       "      <th class=\"index_name level2\" >Metric</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b2f42_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"3\">cow</th>\n",
       "      <th id=\"T_b2f42_level1_row0\" class=\"row_heading level1 row0\" >Test neg</th>\n",
       "      <th id=\"T_b2f42_level2_row0\" class=\"row_heading level2 row0\" >Avg Neg Prediction</th>\n",
       "      <td id=\"T_b2f42_row0_col0\" class=\"data row0 col0\" >0.568</td>\n",
       "      <td id=\"T_b2f42_row0_col1\" class=\"data row0 col1\" >0.476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2f42_level1_row1\" class=\"row_heading level1 row1\" >Test1 avg pred</th>\n",
       "      <th id=\"T_b2f42_level2_row1\" class=\"row_heading level2 row1\" >Avg Neg Prediction</th>\n",
       "      <td id=\"T_b2f42_row1_col0\" class=\"data row1 col0\" >0.520</td>\n",
       "      <td id=\"T_b2f42_row1_col1\" class=\"data row1 col1\" >0.453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2f42_level1_row2\" class=\"row_heading level1 row2\" >Test Cow+Pig Pred</th>\n",
       "      <th id=\"T_b2f42_level2_row2\" class=\"row_heading level2 row2\" >Avg Neg Prediction</th>\n",
       "      <td id=\"T_b2f42_row2_col0\" class=\"data row2 col0\" >0.717</td>\n",
       "      <td id=\"T_b2f42_row2_col1\" class=\"data row2 col1\" >0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2f42_level0_row3\" class=\"row_heading level0 row3\" rowspan=\"3\">macaque</th>\n",
       "      <th id=\"T_b2f42_level1_row3\" class=\"row_heading level1 row3\" >Test neg</th>\n",
       "      <th id=\"T_b2f42_level2_row3\" class=\"row_heading level2 row3\" >Avg Neg Prediction</th>\n",
       "      <td id=\"T_b2f42_row3_col0\" class=\"data row3 col0\" >0.542</td>\n",
       "      <td id=\"T_b2f42_row3_col1\" class=\"data row3 col1\" >0.447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2f42_level1_row4\" class=\"row_heading level1 row4\" >Test1 avg pred</th>\n",
       "      <th id=\"T_b2f42_level2_row4\" class=\"row_heading level2 row4\" >Avg Neg Prediction</th>\n",
       "      <td id=\"T_b2f42_row4_col0\" class=\"data row4 col0\" >0.515</td>\n",
       "      <td id=\"T_b2f42_row4_col1\" class=\"data row4 col1\" >0.433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2f42_level1_row5\" class=\"row_heading level1 row5\" >Test Cow+Pig Pred</th>\n",
       "      <th id=\"T_b2f42_level2_row5\" class=\"row_heading level2 row5\" >Avg Neg Prediction</th>\n",
       "      <td id=\"T_b2f42_row5_col0\" class=\"data row5 col0\" >0.717</td>\n",
       "      <td id=\"T_b2f42_row5_col1\" class=\"data row5 col1\" >0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2f42_level0_row6\" class=\"row_heading level0 row6\" rowspan=\"3\">pig</th>\n",
       "      <th id=\"T_b2f42_level1_row6\" class=\"row_heading level1 row6\" >Test neg</th>\n",
       "      <th id=\"T_b2f42_level2_row6\" class=\"row_heading level2 row6\" >Avg Neg Prediction</th>\n",
       "      <td id=\"T_b2f42_row6_col0\" class=\"data row6 col0\" >0.594</td>\n",
       "      <td id=\"T_b2f42_row6_col1\" class=\"data row6 col1\" >0.477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2f42_level1_row7\" class=\"row_heading level1 row7\" >Test1 avg pred</th>\n",
       "      <th id=\"T_b2f42_level2_row7\" class=\"row_heading level2 row7\" >Avg Neg Prediction</th>\n",
       "      <td id=\"T_b2f42_row7_col0\" class=\"data row7 col0\" >0.538</td>\n",
       "      <td id=\"T_b2f42_row7_col1\" class=\"data row7 col1\" >0.447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2f42_level1_row8\" class=\"row_heading level1 row8\" >Test Cow+Pig Pred</th>\n",
       "      <th id=\"T_b2f42_level2_row8\" class=\"row_heading level2 row8\" >Avg Neg Prediction</th>\n",
       "      <td id=\"T_b2f42_row8_col0\" class=\"data row8 col0\" >0.717</td>\n",
       "      <td id=\"T_b2f42_row8_col1\" class=\"data row8 col1\" >0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2f42_level0_row9\" class=\"row_heading level0 row9\" rowspan=\"3\">rat</th>\n",
       "      <th id=\"T_b2f42_level1_row9\" class=\"row_heading level1 row9\" >Test neg</th>\n",
       "      <th id=\"T_b2f42_level2_row9\" class=\"row_heading level2 row9\" >Avg Neg Prediction</th>\n",
       "      <td id=\"T_b2f42_row9_col0\" class=\"data row9 col0\" >0.676</td>\n",
       "      <td id=\"T_b2f42_row9_col1\" class=\"data row9 col1\" >0.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2f42_level1_row10\" class=\"row_heading level1 row10\" >Test1 avg pred</th>\n",
       "      <th id=\"T_b2f42_level2_row10\" class=\"row_heading level2 row10\" >Avg Neg Prediction</th>\n",
       "      <td id=\"T_b2f42_row10_col0\" class=\"data row10 col0\" >0.804</td>\n",
       "      <td id=\"T_b2f42_row10_col1\" class=\"data row10 col1\" >0.612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b2f42_level1_row11\" class=\"row_heading level1 row11\" >Test Cow+Pig Pred</th>\n",
       "      <th id=\"T_b2f42_level2_row11\" class=\"row_heading level2 row11\" >Avg Neg Prediction</th>\n",
       "      <td id=\"T_b2f42_row11_col0\" class=\"data row11 col0\" >0.717</td>\n",
       "      <td id=\"T_b2f42_row11_col1\" class=\"data row11 col1\" >0.625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff69a2e7c70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EQN MODEL\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "def correlate():\n",
    "    rows = []\n",
    "    # Lists for correlation calculations\n",
    "    groups = ['Test','Test2', 'Test3', 'Test Cow+Pig']\n",
    "    preds = [pred_testPos, pred_test2_df, pred_test3_df, pred_test4_df]\n",
    "    trues = [doubled_testPos, doubled_test2_df, doubled_test3_df, doubled_test4_df]\n",
    "\n",
    "    # Calculate correlations\n",
    "    for group, pred_df, true_df in zip(groups, preds, trues):\n",
    "        x = true_df.squeeze()\n",
    "        y = pred_df.squeeze()\n",
    "        pearson, _ = scipy.stats.pearsonr(x, y)\n",
    "        spearman, _ = scipy.stats.spearmanr(x, y)\n",
    "        rows.append({'Group': group, 'Metric': 'Pearson', 'Value': pearson})\n",
    "        rows.append({'Group': group, 'Metric': 'Spearman', 'Value': spearman})\n",
    "          \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def negatives():\n",
    "    rows = []\n",
    "     # Lists for negative average calculations\n",
    "    negGroup = ['Test neg', 'Test1 avg pred', 'Test Cow+Pig Pred']\n",
    "    negValues = [pred_testNeg.mean().iloc[0], pred_test1_df.mean().iloc[0], pred_test5_df.mean().iloc[0]]\n",
    "    \n",
    "    # Add negative value averages\n",
    "    for group, negv in zip(negGroup, negValues):\n",
    "        rows.append({'Group': group, 'Metric': 'Avg Neg Prediction', 'Value': negv})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# --- Main Script ---\n",
    "all_results = []\n",
    "neg_results = []\n",
    "species_list = ['macaque', 'rat', 'cow', 'pig']\n",
    "model_list = ['mcf297qb', '7l12zan1']\n",
    "\n",
    "for species in species_list:\n",
    "    for model in model_list:\n",
    "        model_dir = f'{model}_FINAL'\n",
    "        #############################################################################\n",
    "\n",
    "        # load TEST ORTHO DFs\n",
    "        pred_TEST_ortho = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_{species}_TEST_orthologs.csv', header=None)\n",
    "        \n",
    "        testPos = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits_eqn/log_pos_LiuAll/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        testNeg = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/neg/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        testPos_len = 2*len(testPos)\n",
    "        testNeg_len = 2*len(testNeg)\n",
    "        \n",
    "        if len(pred_TEST_ortho) != testPos_len+testNeg_len:\n",
    "            print(f\"ERROR TEST ORTHO ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_testPos = pd.concat([testPos, testPos]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_testNeg = pd.concat([testNeg, testNeg]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_testPos = pred_TEST_ortho.head(testPos_len)\n",
    "        pred_testNeg = pred_TEST_ortho.tail(testNeg_len)\n",
    "\n",
    "\n",
    "        #############################################################################\n",
    "        # load TEST DFs\n",
    "        pred_TEST = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_{species}_TEST.csv', header=None)\n",
    "        \n",
    "        test1_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_LiuAll_test1/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        test2_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits_eqn/log_test2/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        test3_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits_eqn/log_test3/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        test1_len = 2*len(test1_df)\n",
    "        test2_len = 2*len(test2_df)\n",
    "        test3_len = 2*len(test3_df)\n",
    "        \n",
    "        if len(pred_TEST) != test1_len+test2_len+test3_len:\n",
    "            print(f\"ERROR TEST ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_test1_df = pd.concat([test1_df, test1_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_test2_df = pd.concat([test2_df, test2_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_test3_df = pd.concat([test3_df, test3_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_test1_df = pred_TEST.head(test1_len)\n",
    "        pred_test2_df = pred_TEST.iloc[test1_len:test1_len + test2_len]\n",
    "        pred_test3_df = pred_TEST.tail(test3_len)\n",
    "        \n",
    "        #############################################################################\n",
    "        # load TEST DFs\n",
    "        pred_cow_pig_TEST = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_cow_pig_TEST.csv', header=None)\n",
    "        \n",
    "        test4Pos_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits_eqn/log_test4/cow_pig_liver_pos_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        test5Neg_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_test5/cow_pig_liver_neg_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        test4_len = 2*len(test4Pos_df)\n",
    "        test5_len = 2*len(test5Neg_df)\n",
    "        \n",
    "        if len(pred_cow_pig_TEST) != test4_len+test5_len:\n",
    "            print(f\"ERROR TEST ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_test4_df = pd.concat([test4Pos_df, test4Pos_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_test5_df = pd.concat([test5Neg_df, test5Neg_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_test4_df = pred_cow_pig_TEST.head(test4_len)\n",
    "        pred_test5_df = pred_cow_pig_TEST.tail(test5_len)\n",
    "        \n",
    "        # Call the correlate function which now uses the globally available DFs\n",
    "        corr_df = correlate()\n",
    "        corr_df['species'] = species\n",
    "        corr_df['model'] = model\n",
    "        all_results.append(corr_df)\n",
    "\n",
    "        neg_df = negatives()\n",
    "        neg_df['species'] = species\n",
    "        neg_df['model'] = model\n",
    "        neg_results.append(neg_df)\n",
    "\n",
    "# #############################################################################\n",
    "# FINAL PROCESSING\n",
    "# #############################################################################\n",
    "\n",
    "summary_df = pd.concat(all_results)\n",
    "\n",
    "summary_neg_df = pd.concat(neg_results)\n",
    "\n",
    "# Define the custom order to place negative groups at the bottom.\n",
    "custom_group_order = [\n",
    "    'Test', 'Test2', 'Test3','Test Cow+Pig'\n",
    "]\n",
    "\n",
    "custom_group_order_neg = [\n",
    "    'Test neg', 'Test1 avg pred','Test Cow+Pig Pred'\n",
    "]\n",
    "\n",
    "# Convert 'group' to a categorical type with the specified order.\n",
    "summary_df['Group'] = pd.Categorical(summary_df['Group'], categories=custom_group_order, ordered=True)\n",
    "summary_neg_df['Group'] = pd.Categorical(summary_neg_df['Group'], categories=custom_group_order_neg, ordered=True)\n",
    "\n",
    "\n",
    "# Pivot so each model is a column\n",
    "pivot_df = summary_df.pivot_table(\n",
    "    index=['species', 'Group', 'Metric'],\n",
    "    columns='model',\n",
    "    values='Value'\n",
    ")\n",
    "\n",
    "pivot_neg_df = summary_neg_df.pivot_table(\n",
    "    index=['species', 'Group', 'Metric'],\n",
    "    columns='model',\n",
    "    values='Value'\n",
    ")\n",
    "\n",
    "# Sort the index to maintain a logical order (will now use the custom group order)\n",
    "pivot_df = pivot_df.sort_index(level=['species', 'Group', 'Metric'])\n",
    "pivot_neg_df = pivot_neg_df.sort_index(level=['species', 'Group', 'Metric'])\n",
    "\n",
    "pivot_df_eqn = pivot_df[model_list]\n",
    "pivot_neg_df_eqn = pivot_neg_df[model_list]\n",
    "\n",
    "# Display the final pivoted DataFrame\n",
    "print(\"--- Final Pivoted Results ---\")\n",
    "display(pivot_df_eqn.style.format(\"{:.3f}\"))\n",
    "display(pivot_neg_df_eqn.style.format(\"{:.3f}\"))\n",
    "\n",
    "# print(f'Results successfully saved to: {output_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59049dfc-37db-4a19-b6ab-167ee95049ce",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "output_filename = '/home/azstephe/liverRegression/regression_liver/data/figs/tables/2kb_log_model_eval_table_FINAL.tsv'\n",
    "pivot_df_2kb.to_csv(output_filename, sep='\\t', float_format='%.3f')\n",
    "\n",
    "output_neg_filename = '/home/azstephe/liverRegression/regression_liver/data/figs/tables/eqn_log_model_neg_table_FINAL.tsv'\n",
    "pivot_neg_df_eqn.to_csv(output_neg_filename, sep='\\t', float_format='%.3f')\n",
    "\n",
    "output_filename = '/home/azstephe/liverRegression/regression_liver/data/figs/tables/eqn_log_model_eval_table_FINAL.tsv'\n",
    "pivot_df_eqn.to_csv(output_filename, sep='\\t', float_format='%.3f')\n",
    "\n",
    "output_neg_filename = '/home/azstephe/liverRegression/regression_liver/data/figs/tables/2kb_log_model_neg_table_FINAL.tsv'\n",
    "pivot_neg_df_2kb.to_csv(output_neg_filename, sep='\\t', float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "690294e8-b7f0-451c-be8f-9c6389480dcb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>bdbi7l3n</th>\n",
       "      <th>7vsdq5k2</th>\n",
       "      <th>wnfdrgcc</th>\n",
       "      <th>8i7h7nsh</th>\n",
       "      <th>ph4wrpxu</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>species</th>\n",
       "      <th>Group</th>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">mouse</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">Train</th>\n",
       "      <th>Pearson</th>\n",
       "      <td>0.494</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pearson_p</th>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spearman</th>\n",
       "      <td>0.498</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spearman_p</th>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.39</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Validation</th>\n",
       "      <th>Pearson</th>\n",
       "      <td>0.483</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pearson_p</th>\n",
       "      <td>3.49e-232</td>\n",
       "      <td>2.26e-205</td>\n",
       "      <td>3.68e-213</td>\n",
       "      <td>4.93e-206</td>\n",
       "      <td>1.25e-198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spearman</th>\n",
       "      <td>0.491</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spearman_p</th>\n",
       "      <td>4.29e-244</td>\n",
       "      <td>5.50e-228</td>\n",
       "      <td>2.29e-240</td>\n",
       "      <td>1.13e-231</td>\n",
       "      <td>1.20e-235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.42</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Test</th>\n",
       "      <th>Pearson</th>\n",
       "      <td>0.496</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pearson_p</th>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spearman</th>\n",
       "      <td>0.502</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spearman_p</th>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.44</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model                           bdbi7l3n   7vsdq5k2   wnfdrgcc   8i7h7nsh  \\\n",
       "species Group      Metric                                                   \n",
       "mouse   Train      Pearson         0.494      0.497      0.507      0.485   \n",
       "                   Pearson_p    0.00e+00   0.00e+00   0.00e+00   0.00e+00   \n",
       "                   Spearman        0.498      0.509      0.521      0.502   \n",
       "                   Spearman_p   0.00e+00   0.00e+00   0.00e+00   0.00e+00   \n",
       "                   MSE              1.39       1.07       1.02       1.07   \n",
       "        Validation Pearson         0.483      0.457      0.465      0.458   \n",
       "                   Pearson_p   3.49e-232  2.26e-205  3.68e-213  4.93e-206   \n",
       "                   Spearman        0.491      0.477      0.488       0.48   \n",
       "                   Spearman_p  4.29e-244  5.50e-228  2.29e-240  1.13e-231   \n",
       "                   MSE              1.42       1.13       1.07       1.11   \n",
       "        Test       Pearson         0.496       0.48      0.496       0.48   \n",
       "                   Pearson_p    0.00e+00   0.00e+00   0.00e+00   0.00e+00   \n",
       "                   Spearman        0.502       0.49      0.509      0.498   \n",
       "                   Spearman_p   0.00e+00   0.00e+00   0.00e+00   0.00e+00   \n",
       "                   MSE              1.44       1.15       1.09       1.13   \n",
       "\n",
       "model                           ph4wrpxu  \n",
       "species Group      Metric                 \n",
       "mouse   Train      Pearson         0.478  \n",
       "                   Pearson_p    0.00e+00  \n",
       "                   Spearman        0.501  \n",
       "                   Spearman_p   0.00e+00  \n",
       "                   MSE              1.18  \n",
       "        Validation Pearson         0.451  \n",
       "                   Pearson_p   1.25e-198  \n",
       "                   Spearman        0.484  \n",
       "                   Spearman_p  1.20e-235  \n",
       "                   MSE              1.22  \n",
       "        Test       Pearson         0.483  \n",
       "                   Pearson_p    0.00e+00  \n",
       "                   Spearman        0.504  \n",
       "                   Spearman_p   0.00e+00  \n",
       "                   MSE              1.23  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5 BEST LOG MODELS MOUSE ONLY\n",
    "mhc = 200\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "def correlate():\n",
    "    rows = []\n",
    "    # Lists for correlation calculations\n",
    "    groups = ['Train', 'Validation', 'Test']\n",
    "    preds = [pred_trainPos, pred_valPos, pred_testPos ]\n",
    "    trues = [doubled_trainPos, doubled_valPos, doubled_testPos]\n",
    "\n",
    "    # Calculate correlations\n",
    "    for group, pred_df, true_df in zip(groups, preds, trues):\n",
    "        x = true_df.squeeze()\n",
    "        y = pred_df.squeeze()\n",
    "        pearson, pearson_p = scipy.stats.pearsonr(x, y)\n",
    "        spearman, spearman_p = scipy.stats.spearmanr(x, y)\n",
    "        mse = mean_squared_error(x, y)\n",
    "        pearson_p *= mhc\n",
    "        rows.append({'Group': group, 'Metric': 'Pearson', 'Value': pearson})\n",
    "        rows.append({'Group': group, 'Metric': 'Pearson_p', 'Value': pearson_p})\n",
    "        rows.append({'Group': group, 'Metric': 'Spearman', 'Value': spearman})\n",
    "        rows.append({'Group': group, 'Metric': 'Spearman_p', 'Value': spearman_p})\n",
    "        rows.append({'Group': group, 'Metric': 'MSE', 'Value': mse})\n",
    "          \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def negatives():\n",
    "    rows = []\n",
    "     # Lists for negative average calculations\n",
    "    negGroup = ['Val neg', 'Test neg']\n",
    "    negValues = [pred_valNeg.mean().iloc[0], pred_testNeg.mean().iloc[0]]\n",
    "    \n",
    "    # Add negative value averages\n",
    "    for group, negv in zip(negGroup, negValues):\n",
    "        rows.append({'Group': group, 'Metric': 'Avg Neg Prediction', 'Value': negv})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# --- Main Script ---\n",
    "all_results = []\n",
    "neg_results = []\n",
    "species_list = ['mouse']\n",
    "model_list = ['bdbi7l3n', '7vsdq5k2', 'wnfdrgcc', '8i7h7nsh', 'ph4wrpxu']\n",
    "\n",
    "for species in species_list:\n",
    "    for model in model_list:\n",
    "        model_dir = f'{model}_FINAL'\n",
    "        \n",
    "        # load TRAIN VAL DFs\n",
    "        pred_TRAIN_VAL = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_{species}_TRAIN_VAL.csv', header=None)\n",
    "        \n",
    "        trainPos = pd.read_csv('/home/azstephe/liverRegression/regression_liver/data/splits/logPos/mouse_liver_TRAINONLY.narrowPeak', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        valPos = pd.read_csv('/home/azstephe/liverRegression/regression_liver/data/splits/logPos/mouse_liver_VAL.narrowPeak', header=None, delim_whitespace=True).iloc[:,4] \n",
    "        valNeg = pd.read_csv('/home/azstephe/regression_liver/data/splits/negatives/nonMouse_liver_andRat_andCow_andPig_andMacaque_VAL_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "\n",
    "        trainPos_len = 2*len(trainPos)\n",
    "        valPos_len = 2*len(valPos)\n",
    "        valNeg_len = 2*len(valNeg)\n",
    "        \n",
    "        if len(pred_TRAIN_VAL) != trainPos_len+valPos_len+valNeg_len:\n",
    "            print(f\"ERROR TRAIN ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_trainPos = pd.concat([trainPos, trainPos]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_valPos = pd.concat([valPos, valPos]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_valNeg = pd.concat([valNeg, valNeg]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_trainPos = pred_TRAIN_VAL.head(trainPos_len)\n",
    "        pred_valPos = pred_TRAIN_VAL.iloc[trainPos_len:trainPos_len + valPos_len]\n",
    "        pred_valNeg = pred_TRAIN_VAL.tail(valNeg_len)\n",
    "\n",
    "        #############################################################################\n",
    "\n",
    "        # load TEST ORTHO DFs\n",
    "        pred_TEST_ortho = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_{species}_TEST.csv', header=None)\n",
    "        \n",
    "        testPos = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_pos/mouse_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        testNeg = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/neg/mouse_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        testPos_len = 2*len(testPos)\n",
    "        testNeg_len = 2*len(testNeg)\n",
    "        \n",
    "        if len(pred_TEST_ortho) != testPos_len+testNeg_len:\n",
    "            print(f\"ERROR TEST ORTHO ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_testPos = pd.concat([testPos, testPos]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_testNeg = pd.concat([testNeg, testNeg]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_testPos = pred_TEST_ortho.head(testPos_len)\n",
    "        pred_testNeg = pred_TEST_ortho.tail(testNeg_len)\n",
    "\n",
    "\n",
    "        # Call the correlate function which now uses the globally available DFs\n",
    "        corr_df = correlate()\n",
    "        corr_df['species'] = species\n",
    "        corr_df['model'] = model\n",
    "        all_results.append(corr_df)\n",
    "        \n",
    "        neg_df = negatives()\n",
    "        neg_df['species'] = species\n",
    "        neg_df['model'] = model\n",
    "        neg_results.append(neg_df)\n",
    "        \n",
    "\n",
    "# #############################################################################\n",
    "# FINAL PROCESSING\n",
    "# #############################################################################\n",
    "\n",
    "summary_df = pd.concat(all_results)\n",
    "\n",
    "summary_neg_df = pd.concat(neg_results)\n",
    "\n",
    "# Define the custom order to place negative groups at the bottom.\n",
    "custom_group_order = [\n",
    "    'Train', 'Validation', 'Test'\n",
    "]\n",
    "\n",
    "custom_group_order_neg = [\n",
    "    'Val neg', 'Test neg'\n",
    "]\n",
    "\n",
    "# Convert 'group' to a categorical type with the specified order.\n",
    "summary_df['Group'] = pd.Categorical(summary_df['Group'], categories=custom_group_order, ordered=True)\n",
    "summary_neg_df['Group'] = pd.Categorical(summary_neg_df['Group'], categories=custom_group_order_neg, ordered=True)\n",
    "\n",
    "\n",
    "# Pivot so each model is a column\n",
    "pivot_df = summary_df.pivot_table(\n",
    "    index=['species', 'Group', 'Metric'],\n",
    "    columns='model',\n",
    "    values='Value'\n",
    ")\n",
    "\n",
    "pivot_neg_df = summary_neg_df.pivot_table(\n",
    "    index=['species', 'Group', 'Metric'],\n",
    "    columns='model',\n",
    "    values='Value'\n",
    ")\n",
    "\n",
    "# Sort the index to maintain a logical order (will now use the custom group order)\n",
    "pivot_df = pivot_df.sort_index(level=['species', 'Group', 'Metric'])\n",
    "pivot_neg_df = pivot_neg_df.sort_index(level=['species', 'Group', 'Metric'])\n",
    "\n",
    "pivot_df_reordered = pivot_df[model_list]\n",
    "pivot_neg_df_reordered = pivot_neg_df[model_list]\n",
    "\n",
    "metric_vars = ['Pearson', 'Pearson_p', 'Spearman', 'Spearman_p', 'MSE']\n",
    "pivot_df_reordered = pivot_df_reordered.reindex(metric_vars, level='Metric')\n",
    "\n",
    "# Loop through each model's column to apply the formatting\n",
    "for col in pivot_df_reordered.columns:\n",
    "    pivot_df_reordered[col] = pivot_df_reordered.apply(\n",
    "        # Access the 'metric' from the index using row.name[2]\n",
    "        # (assuming it's the 3rd level of your index)\n",
    "        lambda row: format_value(row.name[2], row[col]),\n",
    "        axis=1)\n",
    "\n",
    "display(pivot_df_reordered)\n",
    "\n",
    "output_filename = '/home/azstephe/liverRegression/regression_liver/data/figs/tables/mouse_log_model_eval_table_FINAL_mse.tsv'\n",
    "pivot_df_reordered.to_csv(output_filename, sep='\\t', float_format='%.3f')\n",
    "\n",
    "# output_neg_filename = '/home/azstephe/liverRegression/regression_liver/data/figs/tables/mouse_log_model_neg_table_FINAL.tsv'\n",
    "# pivot_neg_df_reordered.to_csv(output_neg_filename, sep='\\t', float_format='%.3f')\n",
    "\n",
    "# print(f'Results successfully saved to: {output_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "848e9d47-333e-4cd3-99ff-f4dfb1731d65",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Final Pivoted Results ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_b0a59\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"index_name level0\" >model</th>\n",
       "      <th id=\"T_b0a59_level0_col0\" class=\"col_heading level0 col0\" >mcf297qb</th>\n",
       "      <th id=\"T_b0a59_level0_col1\" class=\"col_heading level0 col1\" >im88hepv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >species</th>\n",
       "      <th class=\"index_name level1\" >Group</th>\n",
       "      <th class=\"index_name level2\" >Metric</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b0a59_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"2\">mouse</th>\n",
       "      <th id=\"T_b0a59_level1_row0\" class=\"row_heading level1 row0\" rowspan=\"2\">Test</th>\n",
       "      <th id=\"T_b0a59_level2_row0\" class=\"row_heading level2 row0\" >Pearson</th>\n",
       "      <td id=\"T_b0a59_row0_col0\" class=\"data row0 col0\" >0.479</td>\n",
       "      <td id=\"T_b0a59_row0_col1\" class=\"data row0 col1\" >0.464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b0a59_level2_row1\" class=\"row_heading level2 row1\" >Spearman</th>\n",
       "      <td id=\"T_b0a59_row1_col0\" class=\"data row1 col0\" >0.477</td>\n",
       "      <td id=\"T_b0a59_row1_col1\" class=\"data row1 col1\" >0.464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff69c51ebb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_9ea9a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"index_name level0\" >model</th>\n",
       "      <th id=\"T_9ea9a_level0_col0\" class=\"col_heading level0 col0\" >mcf297qb</th>\n",
       "      <th id=\"T_9ea9a_level0_col1\" class=\"col_heading level0 col1\" >im88hepv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >species</th>\n",
       "      <th class=\"index_name level1\" >Group</th>\n",
       "      <th class=\"index_name level2\" >Metric</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9ea9a_level0_row0\" class=\"row_heading level0 row0\" >mouse</th>\n",
       "      <th id=\"T_9ea9a_level1_row0\" class=\"row_heading level1 row0\" >Test neg</th>\n",
       "      <th id=\"T_9ea9a_level2_row0\" class=\"row_heading level2 row0\" >Avg Neg Prediction</th>\n",
       "      <td id=\"T_9ea9a_row0_col0\" class=\"data row0 col0\" >0.541</td>\n",
       "      <td id=\"T_9ea9a_row0_col1\" class=\"data row0 col1\" >0.645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff69c6f1b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2KB + EQN MODEL MOUSE \n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "def correlate():\n",
    "    rows = []\n",
    "    # Lists for correlation calculations\n",
    "    groups = ['Test']\n",
    "    preds = [pred_testPos ]\n",
    "    trues = [doubled_testPos]\n",
    "\n",
    "    # Calculate correlations\n",
    "    for group, pred_df, true_df in zip(groups, preds, trues):\n",
    "        x = true_df.squeeze()\n",
    "        y = pred_df.squeeze()\n",
    "        pearson, _ = scipy.stats.pearsonr(x, y)\n",
    "        spearman, _ = scipy.stats.spearmanr(x, y)\n",
    "        rows.append({'Group': group, 'Metric': 'Pearson', 'Value': pearson})\n",
    "        rows.append({'Group': group, 'Metric': 'Spearman', 'Value': spearman})\n",
    "          \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def negatives():\n",
    "    rows = []\n",
    "     # Lists for negative average calculations\n",
    "    negGroup = ['Test neg']\n",
    "    negValues = [pred_testNeg.mean().iloc[0]]\n",
    "    \n",
    "    # Add negative value averages\n",
    "    for group, negv in zip(negGroup, negValues):\n",
    "        rows.append({'Group': group, 'Metric': 'Avg Neg Prediction', 'Value': negv})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "all_results = []\n",
    "neg_results = []\n",
    "species_list = ['mouse']\n",
    "model_list = ['mcf297qb', 'im88hepv']\n",
    "\n",
    "for species in species_list:\n",
    "    for model in model_list:\n",
    "        model_dir = f'{model}_FINAL'\n",
    "        \n",
    "        if model=='mcf297qb':\n",
    "            # load TEST ORTHO DFs\n",
    "            pred_TEST_ortho = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_{species}_TEST.csv', header=None)\n",
    "            \n",
    "            testPos = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits_eqn/log_pos/mouse_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "            testNeg = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/neg/mouse_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "            \n",
    "            testPos_len = 2*len(testPos)\n",
    "            testNeg_len = 2*len(testNeg)\n",
    "            \n",
    "            if len(pred_TEST_ortho) != testPos_len+testNeg_len:\n",
    "                print(f\"ERROR TEST ORTHO ({species}, {model}): predictions are a different length than validation sets\")\n",
    "            \n",
    "            doubled_testPos = pd.concat([testPos, testPos]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "            doubled_testNeg = pd.concat([testNeg, testNeg]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "            \n",
    "            pred_testPos = pred_TEST_ortho.head(testPos_len)\n",
    "            pred_testNeg = pred_TEST_ortho.tail(testNeg_len)  \n",
    "\n",
    "        else:\n",
    "            # load TEST ORTHO DFs\n",
    "            pred_TEST_ortho = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_{species}_TEST.csv', header=None)\n",
    "            \n",
    "            testPos = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits_2kb/log_pos/mouse_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "            testNeg = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits_2kb/neg/mouse_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "            \n",
    "            testPos_len = 2*len(testPos)\n",
    "            testNeg_len = 2*len(testNeg)\n",
    "            \n",
    "            if len(pred_TEST_ortho) != testPos_len+testNeg_len:\n",
    "                print(f\"ERROR TEST ORTHO ({species}, {model}): predictions are a different length than validation sets\")\n",
    "            \n",
    "            doubled_testPos = pd.concat([testPos, testPos]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "            doubled_testNeg = pd.concat([testNeg, testNeg]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "            \n",
    "            pred_testPos = pred_TEST_ortho.head(testPos_len)\n",
    "            pred_testNeg = pred_TEST_ortho.tail(testNeg_len)  \n",
    "            \n",
    "\n",
    "        # Call the correlate function which now uses the globally available DFs\n",
    "        corr_df = correlate()\n",
    "        corr_df['species'] = species\n",
    "        corr_df['model'] = model\n",
    "        all_results.append(corr_df)\n",
    "        \n",
    "        neg_df = negatives()\n",
    "        neg_df['species'] = species\n",
    "        neg_df['model'] = model\n",
    "        neg_results.append(neg_df)\n",
    "        \n",
    "\n",
    "# #############################################################################\n",
    "# FINAL PROCESSING\n",
    "# #############################################################################\n",
    "\n",
    "summary_df = pd.concat(all_results)\n",
    "\n",
    "summary_neg_df = pd.concat(neg_results)\n",
    "\n",
    "# Define the custom order to place negative groups at the bottom.\n",
    "custom_group_order = [\n",
    "    'Train', 'Validation', 'Test'\n",
    "]\n",
    "\n",
    "custom_group_order_neg = [\n",
    "    'Val neg', 'Test neg'\n",
    "]\n",
    "\n",
    "# Convert 'group' to a categorical type with the specified order.\n",
    "summary_df['Group'] = pd.Categorical(summary_df['Group'], categories=custom_group_order, ordered=True)\n",
    "summary_neg_df['Group'] = pd.Categorical(summary_neg_df['Group'], categories=custom_group_order_neg, ordered=True)\n",
    "\n",
    "\n",
    "# Pivot so each model is a column\n",
    "pivot_df = summary_df.pivot_table(\n",
    "    index=['species', 'Group', 'Metric'],\n",
    "    columns='model',\n",
    "    values='Value'      \n",
    ")\n",
    "\n",
    "pivot_neg_df = summary_neg_df.pivot_table(\n",
    "    index=['species', 'Group', 'Metric'],\n",
    "    columns='model',\n",
    "    values='Value'\n",
    ")\n",
    "\n",
    "# Sort the index to maintain a logical order (will now use the custom group order)\n",
    "pivot_df = pivot_df.sort_index(level=['species', 'Group', 'Metric'])\n",
    "pivot_neg_df = pivot_neg_df.sort_index(level=['species', 'Group', 'Metric'])\n",
    "\n",
    "pivot_df_reordered = pivot_df[model_list]\n",
    "pivot_neg_df_reordered = pivot_neg_df[model_list]\n",
    "\n",
    "# Display the final pivoted DataFrame\n",
    "print(\"--- Final Pivoted Results ---\")\n",
    "display(pivot_df_reordered.style.format(\"{:.3f}\"))\n",
    "display(pivot_neg_df_reordered.style.format(\"{:.3f}\"))\n",
    "\n",
    "output_filename = '/home/azstephe/liverRegression/regression_liver/data/figs/tables/mouse_eqn_2kb_log_model_eval_table_FINAL.tsv'\n",
    "# pivot_df_reordered.to_csv(output_filename, sep='\\t', float_format='%.3f')\n",
    "\n",
    "output_neg_filename = '/home/azstephe/liverRegression/regression_liver/data/figs/tables/mouse_eqn_2kb_log_model_neg_table_FINAL.tsv'\n",
    "# pivot_neg_df_reordered.to_csv(output_neg_filename, sep='\\t', float_format='%.3f')\n",
    "\n",
    "# print(f'Results successfully saved to: {output_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85574786-f948-4b44-a1d4-9a14fb828c1f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Final Pivoted Results ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_88f5d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"index_name level0\" >model</th>\n",
       "      <th id=\"T_88f5d_level0_col0\" class=\"col_heading level0 col0\" >bdbi7l3n</th>\n",
       "      <th id=\"T_88f5d_level0_col1\" class=\"col_heading level0 col1\" >kf8188qf</th>\n",
       "      <th id=\"T_88f5d_level0_col2\" class=\"col_heading level0 col2\" >cq45eb2s</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >species</th>\n",
       "      <th class=\"index_name level1\" >Group</th>\n",
       "      <th class=\"index_name level2\" >Metric</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_88f5d_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"6\">mouse</th>\n",
       "      <th id=\"T_88f5d_level1_row0\" class=\"row_heading level1 row0\" rowspan=\"2\">Train</th>\n",
       "      <th id=\"T_88f5d_level2_row0\" class=\"row_heading level2 row0\" >Pearson</th>\n",
       "      <td id=\"T_88f5d_row0_col0\" class=\"data row0 col0\" >0.494</td>\n",
       "      <td id=\"T_88f5d_row0_col1\" class=\"data row0 col1\" >0.644</td>\n",
       "      <td id=\"T_88f5d_row0_col2\" class=\"data row0 col2\" >0.645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88f5d_level2_row1\" class=\"row_heading level2 row1\" >Spearman</th>\n",
       "      <td id=\"T_88f5d_row1_col0\" class=\"data row1 col0\" >0.498</td>\n",
       "      <td id=\"T_88f5d_row1_col1\" class=\"data row1 col1\" >0.640</td>\n",
       "      <td id=\"T_88f5d_row1_col2\" class=\"data row1 col2\" >0.639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88f5d_level1_row2\" class=\"row_heading level1 row2\" rowspan=\"2\">Validation</th>\n",
       "      <th id=\"T_88f5d_level2_row2\" class=\"row_heading level2 row2\" >Pearson</th>\n",
       "      <td id=\"T_88f5d_row2_col0\" class=\"data row2 col0\" >0.483</td>\n",
       "      <td id=\"T_88f5d_row2_col1\" class=\"data row2 col1\" >0.584</td>\n",
       "      <td id=\"T_88f5d_row2_col2\" class=\"data row2 col2\" >0.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88f5d_level2_row3\" class=\"row_heading level2 row3\" >Spearman</th>\n",
       "      <td id=\"T_88f5d_row3_col0\" class=\"data row3 col0\" >0.491</td>\n",
       "      <td id=\"T_88f5d_row3_col1\" class=\"data row3 col1\" >0.582</td>\n",
       "      <td id=\"T_88f5d_row3_col2\" class=\"data row3 col2\" >0.588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88f5d_level1_row4\" class=\"row_heading level1 row4\" rowspan=\"2\">Test</th>\n",
       "      <th id=\"T_88f5d_level2_row4\" class=\"row_heading level2 row4\" >Pearson</th>\n",
       "      <td id=\"T_88f5d_row4_col0\" class=\"data row4 col0\" >0.496</td>\n",
       "      <td id=\"T_88f5d_row4_col1\" class=\"data row4 col1\" >0.600</td>\n",
       "      <td id=\"T_88f5d_row4_col2\" class=\"data row4 col2\" >0.628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88f5d_level2_row5\" class=\"row_heading level2 row5\" >Spearman</th>\n",
       "      <td id=\"T_88f5d_row5_col0\" class=\"data row5 col0\" >0.502</td>\n",
       "      <td id=\"T_88f5d_row5_col1\" class=\"data row5 col1\" >0.601</td>\n",
       "      <td id=\"T_88f5d_row5_col2\" class=\"data row5 col2\" >0.626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff69ce7afa0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_24640\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"index_name level0\" >model</th>\n",
       "      <th id=\"T_24640_level0_col0\" class=\"col_heading level0 col0\" >bdbi7l3n</th>\n",
       "      <th id=\"T_24640_level0_col1\" class=\"col_heading level0 col1\" >kf8188qf</th>\n",
       "      <th id=\"T_24640_level0_col2\" class=\"col_heading level0 col2\" >cq45eb2s</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >species</th>\n",
       "      <th class=\"index_name level1\" >Group</th>\n",
       "      <th class=\"index_name level2\" >Metric</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_24640_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"2\">mouse</th>\n",
       "      <th id=\"T_24640_level1_row0\" class=\"row_heading level1 row0\" >Val neg</th>\n",
       "      <th id=\"T_24640_level2_row0\" class=\"row_heading level2 row0\" >Avg Neg Prediction</th>\n",
       "      <td id=\"T_24640_row0_col0\" class=\"data row0 col0\" >0.619</td>\n",
       "      <td id=\"T_24640_row0_col1\" class=\"data row0 col1\" >0.460</td>\n",
       "      <td id=\"T_24640_row0_col2\" class=\"data row0 col2\" >0.429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_24640_level1_row1\" class=\"row_heading level1 row1\" >Test neg</th>\n",
       "      <th id=\"T_24640_level2_row1\" class=\"row_heading level2 row1\" >Avg Neg Prediction</th>\n",
       "      <td id=\"T_24640_row1_col0\" class=\"data row1 col0\" >0.609</td>\n",
       "      <td id=\"T_24640_row1_col1\" class=\"data row1 col1\" >0.446</td>\n",
       "      <td id=\"T_24640_row1_col2\" class=\"data row1 col2\" >0.424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7ff699146700>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1 3 5 LOG MODELS MOUSE\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "def correlate():\n",
    "    rows = []\n",
    "    # Lists for correlation calculations\n",
    "    groups = ['Train', 'Validation', 'Test']\n",
    "    preds = [pred_trainPos, pred_valPos, pred_testPos ]\n",
    "    trues = [doubled_trainPos, doubled_valPos, doubled_testPos]\n",
    "\n",
    "    # Calculate correlations\n",
    "    for group, pred_df, true_df in zip(groups, preds, trues):\n",
    "        x = true_df.squeeze()\n",
    "        y = pred_df.squeeze()\n",
    "        pearson, _ = scipy.stats.pearsonr(x, y)\n",
    "        spearman, _ = scipy.stats.spearmanr(x, y)\n",
    "        rows.append({'Group': group, 'Metric': 'Pearson', 'Value': pearson})\n",
    "        rows.append({'Group': group, 'Metric': 'Spearman', 'Value': spearman})\n",
    "          \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def negatives():\n",
    "    rows = []\n",
    "     # Lists for negative average calculations\n",
    "    negGroup = ['Val neg', 'Test neg']\n",
    "    negValues = [pred_valNeg.mean().iloc[0], pred_testNeg.mean().iloc[0]]\n",
    "    \n",
    "    # Add negative value averages\n",
    "    for group, negv in zip(negGroup, negValues):\n",
    "        rows.append({'Group': group, 'Metric': 'Avg Neg Prediction', 'Value': negv})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# --- Main Script ---\n",
    "all_results = []\n",
    "neg_results = []\n",
    "species_list = ['mouse']\n",
    "model_list = ['bdbi7l3n', 'kf8188qf', 'cq45eb2s']\n",
    "\n",
    "for species in species_list:\n",
    "    for model in model_list:\n",
    "        model_dir = f'{model}_FINAL'\n",
    "        \n",
    "        # load TRAIN VAL DFs\n",
    "        pred_TRAIN_VAL = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_{species}_TRAIN_VAL.csv', header=None)\n",
    "        \n",
    "        trainPos = pd.read_csv('/home/azstephe/liverRegression/regression_liver/data/splits/logPos/mouse_liver_TRAINONLY.narrowPeak', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        valPos = pd.read_csv('/home/azstephe/liverRegression/regression_liver/data/splits/logPos/mouse_liver_VAL.narrowPeak', header=None, delim_whitespace=True).iloc[:,4] \n",
    "        valNeg = pd.read_csv('/home/azstephe/regression_liver/data/splits/negatives/nonMouse_liver_andRat_andCow_andPig_andMacaque_VAL_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "\n",
    "        trainPos_len = 2*len(trainPos)\n",
    "        valPos_len = 2*len(valPos)\n",
    "        valNeg_len = 2*len(valNeg)\n",
    "        \n",
    "        if len(pred_TRAIN_VAL) != trainPos_len+valPos_len+valNeg_len:\n",
    "            print(f\"ERROR TRAIN ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_trainPos = pd.concat([trainPos, trainPos]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_valPos = pd.concat([valPos, valPos]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_valNeg = pd.concat([valNeg, valNeg]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_trainPos = pred_TRAIN_VAL.head(trainPos_len)\n",
    "        pred_valPos = pred_TRAIN_VAL.iloc[trainPos_len:trainPos_len + valPos_len]\n",
    "        pred_valNeg = pred_TRAIN_VAL.tail(valNeg_len)\n",
    "\n",
    "        #############################################################################\n",
    "\n",
    "        # load TEST ORTHO DFs\n",
    "        pred_TEST_ortho = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_{species}_TEST.csv', header=None)\n",
    "        \n",
    "        testPos = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_pos/mouse_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        testNeg = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/neg/mouse_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        testPos_len = 2*len(testPos)\n",
    "        testNeg_len = 2*len(testNeg)\n",
    "        \n",
    "        if len(pred_TEST_ortho) != testPos_len+testNeg_len:\n",
    "            print(f\"ERROR TEST ORTHO ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_testPos = pd.concat([testPos, testPos]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_testNeg = pd.concat([testNeg, testNeg]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_testPos = pred_TEST_ortho.head(testPos_len)\n",
    "        pred_testNeg = pred_TEST_ortho.tail(testNeg_len)\n",
    "\n",
    "\n",
    "        # Call the correlate function which now uses the globally available DFs\n",
    "        corr_df = correlate()\n",
    "        corr_df['species'] = species\n",
    "        corr_df['model'] = model\n",
    "        all_results.append(corr_df)\n",
    "        \n",
    "        neg_df = negatives()\n",
    "        neg_df['species'] = species\n",
    "        neg_df['model'] = model\n",
    "        neg_results.append(neg_df)\n",
    "        \n",
    "\n",
    "# #############################################################################\n",
    "# FINAL PROCESSING\n",
    "# #############################################################################\n",
    "\n",
    "summary_df = pd.concat(all_results)\n",
    "\n",
    "summary_neg_df = pd.concat(neg_results)\n",
    "\n",
    "# Define the custom order to place negative groups at the bottom.\n",
    "custom_group_order = [\n",
    "    'Train', 'Validation', 'Test'\n",
    "]\n",
    "\n",
    "custom_group_order_neg = [\n",
    "    'Val neg', 'Test neg'\n",
    "]\n",
    "\n",
    "# Convert 'group' to a categorical type with the specified order.\n",
    "summary_df['Group'] = pd.Categorical(summary_df['Group'], categories=custom_group_order, ordered=True)\n",
    "summary_neg_df['Group'] = pd.Categorical(summary_neg_df['Group'], categories=custom_group_order_neg, ordered=True)\n",
    "\n",
    "\n",
    "# Pivot so each model is a column\n",
    "pivot_df = summary_df.pivot_table(\n",
    "    index=['species', 'Group', 'Metric'],\n",
    "    columns='model',\n",
    "    values='Value'\n",
    ")\n",
    "\n",
    "pivot_neg_df = summary_neg_df.pivot_table(\n",
    "    index=['species', 'Group', 'Metric'],\n",
    "    columns='model',\n",
    "    values='Value'\n",
    ")\n",
    "\n",
    "# Sort the index to maintain a logical order (will now use the custom group order)\n",
    "pivot_df = pivot_df.sort_index(level=['species', 'Group', 'Metric'])\n",
    "pivot_neg_df = pivot_neg_df.sort_index(level=['species', 'Group', 'Metric'])\n",
    "\n",
    "pivot_df_reordered = pivot_df[model_list]\n",
    "pivot_neg_df_reordered = pivot_neg_df[model_list]\n",
    "\n",
    "# Display the final pivoted DataFrame\n",
    "print(\"--- Final Pivoted Results ---\")\n",
    "display(pivot_df_reordered.style.format(\"{:.3f}\"))\n",
    "display(pivot_neg_df_reordered.style.format(\"{:.3f}\"))\n",
    "\n",
    "output_filename = '/home/azstephe/liverRegression/regression_liver/data/figs/tables/mouse_log_model_eval_table_FINAL.tsv'\n",
    "# pivot_df_reordered.to_csv(output_filename, sep='\\t', float_format='%.3f')\n",
    "\n",
    "output_neg_filename = '/home/azstephe/liverRegression/regression_liver/data/figs/tables/mouse_log_model_neg_table_FINAL.tsv'\n",
    "# pivot_neg_df_reordered.to_csv(output_neg_filename, sep='\\t', float_format='%.3f')\n",
    "\n",
    "# print(f'Results successfully saved to: {output_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f506d70f-3f0b-4c18-b37b-706ce6d86bbb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bdbi7l3n\n",
      "0.612\n",
      "7vsdq5k2\n",
      "0.584\n",
      "wnfdrgcc\n",
      "0.648\n",
      "8i7h7nsh\n",
      "0.671\n",
      "ph4wrpxu\n",
      "0.674\n",
      "im88hepv\n",
      "0.646\n",
      "mcf297qb\n",
      "0.443\n",
      "kf8188qf\n",
      "0.403\n",
      "cq45eb2s\n",
      "0.401\n"
     ]
    }
   ],
   "source": [
    "# MOUSE TRAIN NEG\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "model_list = ['bdbi7l3n', '7vsdq5k2', 'wnfdrgcc', '8i7h7nsh', 'ph4wrpxu', 'im88hepv', 'mcf297qb', 'kf8188qf', 'cq45eb2s']\n",
    "\n",
    "\n",
    "for model in model_list:\n",
    "    print(model)\n",
    "    model_dir = f'{model}_FINAL'\n",
    "\n",
    "    if model=='im88hepv':\n",
    "        pred_trainNeg = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_mouse_TRAIN_NEG.csv', header=None)\n",
    "        \n",
    "    else:\n",
    "        pred_trainNeg = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_mouse_TRAIN_NEG.csv', header=None)\n",
    "\n",
    "    mean_value = pred_trainNeg.mean().iloc[0]\n",
    "    print(f'{mean_value:.3f}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32417c7c-6391-40e2-8d7a-66bbbb80b16e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
