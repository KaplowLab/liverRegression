{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b930f27-0ff2-4f16-93db-e215812a9569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:22:21.139147: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "def one_hot_encode(sequence: str,\n",
    "                   alphabet: str = 'ACGT',\n",
    "                   neutral_alphabet: str = 'N',\n",
    "                   neutral_value: Any = 0,\n",
    "                   dtype=np.float32) -> np.ndarray:\n",
    "  \"\"\"One-hot encode sequence.\"\"\"\n",
    "  def to_uint8(string):\n",
    "    return np.frombuffer(string.encode('ascii'), dtype=np.uint8)\n",
    "  hash_table = np.zeros((np.iinfo(np.uint8).max, len(alphabet)), dtype=dtype)\n",
    "  hash_table[to_uint8(alphabet)] = np.eye(len(alphabet), dtype=dtype)\n",
    "  hash_table[to_uint8(neutral_alphabet)] = neutral_value\n",
    "  hash_table = hash_table.astype(dtype)\n",
    "  return hash_table[to_uint8(sequence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3636306-5fd0-4624-b520-3feb15721504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "GPU Details: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-06 13:22:27.537329: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2026-01-06 13:22:27.565620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: NVIDIA RTX A6000 computeCapability: 8.6\n",
      "coreClock: 1.8GHz coreCount: 84 deviceMemorySize: 47.54GiB deviceMemoryBandwidth: 715.34GiB/s\n",
      "2026-01-06 13:22:27.565657: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2026-01-06 13:22:27.774236: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2026-01-06 13:22:27.774326: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2026-01-06 13:22:27.842019: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2026-01-06 13:22:27.916030: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2026-01-06 13:22:27.962079: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2026-01-06 13:22:28.000950: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2026-01-06 13:22:28.020184: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2026-01-06 13:22:28.020978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(gpu_devices))\n",
    "\n",
    "if gpu_devices:\n",
    "    print(\"GPU Details:\", gpu_devices)\n",
    "else:\n",
    "    print(\"TensorFlow is NOT using the GPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "05434f94-b1f5-4d5f-b97a-4e152cdb6e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "species = 'mouse'\n",
    "narrowPeak_file = species + '_liver_pos_ALL.narrowPeak'\n",
    "\n",
    "chrom_dir = '/home/azstephe/liverRegression/regression_liver/data/chrom_sizes/'\n",
    "chrom_sizes = pd.read_csv(chrom_dir + 'mm10.chrom.sizes', sep='\\t', names=['chrom', 'chrom_len'])\n",
    "chrom_map = dict(zip(chrom_sizes['chrom'], chrom_sizes['chrom_len']))\n",
    "\n",
    "with open('/home/azstephe/liverRegression/regression_liver/data/chrom_sizes/' + species + '_chrom_sizes.json', 'w') as f:\n",
    "    json.dump(chrom_map, f)\n",
    "\n",
    "# narrowPeak_dir = '/home/azstephe/liverRegression/regression_liver/data/raw/'\n",
    "\n",
    "# cols = ['chrom', 'start', 'end', 'name', 'score', 'strand', 'signal', 'p', 'q', 'peak_offset']\n",
    "# df = pd.read_csv(narrowPeak_dir + narrowPeak_file, sep='\\t', names=cols)\n",
    "\n",
    "# extension = 196608\n",
    "# df['summit'] = df['start'] + df['peak_offset']\n",
    "# df['new_start'] = df['summit'] - extension\n",
    "# df['new_end'] = df['summit'] + extension\n",
    "\n",
    "# # 4. Filter for boundaries\n",
    "# # Get the max length for the specific chromosome of each peak\n",
    "# df['max_len'] = df['chrom'].map(chrom_map)\n",
    "\n",
    "# # Keep only if start >= 0 AND end <= chromosome length\n",
    "# valid_sections = df[(df['new_start'] >= 0) & (df['new_end'] <= df['max_len'])].copy()\n",
    "\n",
    "# print(f\"Original peaks: {len(df)}\")\n",
    "# print(f\"Peaks kept: {len(valid_sections)}\")\n",
    "# print(f\"Peaks lost: {len(df) - len(valid_sections)}\")\n",
    "\n",
    "# outdir = '/home/azstephe/liverRegression/regression_liver/data/enformer_inputs/'\n",
    "# valid_sections[['chrom', 'new_start', 'new_end', 'name', 'signal']].to_csv(outdir + narrowPeak_file, sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c89adb01-c16a-472c-960a-df66dc3bbcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "species = 'macaque'\n",
    "\n",
    "chrom_dir = '/home/azstephe/liverRegression/regression_liver/data/chrom_sizes/'\n",
    "chrom_sizes = pd.read_csv(chrom_dir + 'rheMac8.chrom.sizes', sep='\\t', names=['chrom', 'chrom_len'])\n",
    "chrom_map = dict(zip(chrom_sizes['chrom'], chrom_sizes['chrom_len']))\n",
    "with open('/home/azstephe/liverRegression/regression_liver/data/chrom_sizes/' + species + '_chrom_sizes.json', 'w') as f:\n",
    "    json.dump(chrom_map, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37ef2d0b-b44f-43a4-92e9-0f18e248b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "species = 'pig'\n",
    "narrowPeak_file = species + '_liver_pos_ALL.narrowPeak'\n",
    "\n",
    "chrom_dir = '/home/azstephe/liverRegression/regression_liver/data/chrom_sizes/'\n",
    "chrom_sizes = pd.read_csv(chrom_dir + 'susScr3.chrom.sizes', sep='\\t', names=['chrom', 'chrom_len'])\n",
    "chrom_map = dict(zip(chrom_sizes['chrom'], chrom_sizes['chrom_len']))\n",
    "with open('/home/azstephe/liverRegression/regression_liver/data/chrom_sizes/' + species + '_chrom_sizes.json', 'w') as f:\n",
    "    json.dump(chrom_map, f)\n",
    "# narrowPeak_dir = '/home/azstephe/liverRegression/regression_liver/data/raw/'\n",
    "\n",
    "# cols = ['chrom', 'start', 'end', 'name', 'score', 'strand', 'signal', 'p', 'q', 'peak_offset']\n",
    "# df = pd.read_csv(narrowPeak_dir + narrowPeak_file, sep='\\t', names=cols)\n",
    "\n",
    "# extension = 196608\n",
    "# df['summit'] = df['start'] + df['peak_offset']\n",
    "# df['new_start'] = df['summit'] - extension\n",
    "# df['new_end'] = df['summit'] + extension\n",
    "\n",
    "# # 4. Filter for boundaries\n",
    "# # Get the max length for the specific chromosome of each peak\n",
    "# df['max_len'] = df['chrom'].map(chrom_map)\n",
    "\n",
    "# # Keep only if start >= 0 AND end <= chromosome length\n",
    "# valid_sections = df[(df['new_start'] >= 0) & (df['new_end'] <= df['max_len'])].copy()\n",
    "\n",
    "# print(f\"Original peaks: {len(df)}\")\n",
    "# print(f\"Peaks kept: {len(valid_sections)}\")\n",
    "# print(f\"Peaks lost: {len(df) - len(valid_sections)}\")\n",
    "\n",
    "# outdir = '/home/azstephe/liverRegression/regression_liver/data/enformer_inputs/'\n",
    "# valid_sections[['chrom', 'new_start', 'new_end', 'name', 'signal']].to_csv(outdir + narrowPeak_file, sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21dd666f-d97e-41f1-8ac9-5deaebc1cc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "species = 'rat'\n",
    "narrowPeak_file = species + '_liver_pos_ALL.narrowPeak'\n",
    "\n",
    "chrom_dir = '/home/azstephe/liverRegression/regression_liver/data/chrom_sizes/'\n",
    "chrom_sizes = pd.read_csv(chrom_dir + 'rn6.chrom.sizes', sep='\\t', names=['chrom', 'chrom_len'])\n",
    "chrom_map = dict(zip(chrom_sizes['chrom'], chrom_sizes['chrom_len']))\n",
    "with open('/home/azstephe/liverRegression/regression_liver/data/chrom_sizes/' + species + '_chrom_sizes.json', 'w') as f:\n",
    "    json.dump(chrom_map, f)\n",
    "# narrowPeak_dir = '/home/azstephe/liverRegression/regression_liver/data/raw/'\n",
    "\n",
    "# cols = ['chrom', 'start', 'end', 'name', 'score', 'strand', 'signal', 'p', 'q', 'peak_offset']\n",
    "# df = pd.read_csv(narrowPeak_dir + narrowPeak_file, sep='\\t', names=cols)\n",
    "\n",
    "# extension = 196608\n",
    "# df['summit'] = df['start'] + df['peak_offset']\n",
    "# df['new_start'] = df['summit'] - extension\n",
    "# df['new_end'] = df['summit'] + extension\n",
    "\n",
    "# # 4. Filter for boundaries\n",
    "# # Get the max length for the specific chromosome of each peak\n",
    "# df['max_len'] = df['chrom'].map(chrom_map)\n",
    "\n",
    "# # Keep only if start >= 0 AND end <= chromosome length\n",
    "# valid_sections = df[(df['new_start'] >= 0) & (df['new_end'] <= df['max_len'])].copy()\n",
    "\n",
    "# print(f\"Original peaks: {len(df)}\")\n",
    "# print(f\"Peaks kept: {len(valid_sections)}\")\n",
    "# print(f\"Peaks lost: {len(df) - len(valid_sections)}\")\n",
    "\n",
    "# outdir = '/home/azstephe/liverRegression/regression_liver/data/enformer_inputs/'\n",
    "# valid_sections[['chrom', 'new_start', 'new_end', 'name', 'signal']].to_csv(outdir + narrowPeak_file, sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4faf57e8-2dac-46d7-8723-29a99ac311be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "species = 'cow'\n",
    "narrowPeak_file = species + '_liver_pos_ALL_refSeqName.bed'\n",
    "\n",
    "chrom_dir = '/home/azstephe/liverRegression/regression_liver/data/chrom_sizes/'\n",
    "chrom_sizes = pd.read_csv(chrom_dir + 'Btau_5.0.1.chrom.sizes', sep='\\t', names=['chrom', 'chrom_len'])\n",
    "chrom_map = dict(zip(chrom_sizes['chrom'], chrom_sizes['chrom_len']))\n",
    "with open('/home/azstephe/liverRegression/regression_liver/data/chrom_sizes/' + species + '_chrom_sizes.json', 'w') as f:\n",
    "    json.dump(chrom_map, f)\n",
    "# narrowPeak_dir = '/home/azstephe/liverRegression/regression_liver/data/raw/'\n",
    "\n",
    "# cols = ['chrom', 'start', 'end', 'name', 'score', 'strand', 'signal', 'p', 'q', 'peak_offset']\n",
    "# df = pd.read_csv(narrowPeak_dir + narrowPeak_file, sep='\\t', names=cols)\n",
    "\n",
    "# extension = 196608\n",
    "# df['summit'] = df['start'] + df['peak_offset']\n",
    "# df['new_start'] = df['summit'] - extension\n",
    "# df['new_end'] = df['summit'] + extension\n",
    "\n",
    "# # 4. Filter for boundaries\n",
    "# # Get the max length for the specific chromosome of each peak\n",
    "# df['max_len'] = df['chrom'].map(chrom_map)\n",
    "\n",
    "# # Keep only if start >= 0 AND end <= chromosome length\n",
    "# valid_sections = df[(df['new_start'] >= 0) & (df['new_end'] <= df['max_len'])].copy()\n",
    "\n",
    "# print(f\"Original peaks: {len(df)}\")\n",
    "# print(f\"Peaks kept: {len(valid_sections)}\")\n",
    "# print(f\"Peaks lost: {len(df) - len(valid_sections)}\")\n",
    "\n",
    "# outdir = '/home/azstephe/liverRegression/regression_liver/data/enformer_inputs/'\n",
    "# valid_sections[['chrom', 'new_start', 'new_end', 'name', 'signal']].to_csv(outdir + species + '_liver_pos_ALL_refSeqName.narrowPeak', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "50c58d72-9846-4c27-9732-ad2e555b6dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3143 entries from original JSON.\n",
      "✅ Created /home/azstephe/liverRegression/regression_liver/data/chrom_sizes/cow_chrom_sizes.json\n",
      "✅ Created /home/azstephe/liverRegression/regression_liver/data/chrom_sizes/cow_chrom_names.sizes\n",
      "\n",
      "--- Preview of New Mapping ---\n",
      "Chromosome chr1: 158972876 bp\n",
      "Chromosome chr2: 137479425 bp\n",
      "Chromosome chr3: 121888057 bp\n",
      "Chromosome chr4: 121284772 bp\n",
      "Chromosome chr5: 121584146 bp\n"
     ]
    }
   ],
   "source": [
    "mapping_file_path = '/home/azstephe/liverRegression/regression_liver/data/genomes/ChromNameToRefSeqName_Btau_5.0.1.txt'\n",
    "input_json_path = '/home/azstephe/liverRegression/regression_liver/data/chrom_sizes/cow_chrom_sizes_RefSeq.json'\n",
    "output_json_path = '/home/azstephe/liverRegression/regression_liver/data/chrom_sizes/cow_chrom_sizes.json'\n",
    "output_txt_path = '/home/azstephe/liverRegression/regression_liver/data/chrom_sizes/cow_chrom_names.sizes'\n",
    "\n",
    "# 2. Load the mapping file {RefSeq: ChromName}\n",
    "# Assumption based on filename: Col 0 = ChromName, Col 1 = RefSeqName\n",
    "mapping = {}\n",
    "if os.path.exists(mapping_file_path):\n",
    "    with open(mapping_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.strip() and not line.startswith('#'):\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 2:\n",
    "                    chrom_name = parts[0]\n",
    "                    refseq_id = parts[1]\n",
    "                    mapping[refseq_id] = chrom_name\n",
    "\n",
    "if os.path.exists(input_json_path):\n",
    "    with open(input_json_path, 'r') as f:\n",
    "        old_data = json.load(f)\n",
    "    print(f\"Loaded {len(old_data)} entries from original JSON.\")\n",
    "\n",
    "    # 4. Create the new dictionary with ChromNames\n",
    "    # We only keep keys that exist in our mapping file\n",
    "    new_data = {mapping[k]: v for k, v in old_data.items() if k in mapping}\n",
    "    \n",
    "    # 5. Save the results\n",
    "    # Save as JSON\n",
    "    with open(output_json_path, 'w') as f:\n",
    "        json.dump(new_data, f, indent=4)\n",
    "        \n",
    "    # Save as standard tab-separated .sizes file\n",
    "    with open(output_txt_path, 'w') as f:\n",
    "        for k, v in sorted(new_data.items()):\n",
    "            f.write(f\"{k}\\t{v}\\n\")\n",
    "            \n",
    "    print(f\"✅ Created {output_json_path}\")\n",
    "    print(f\"✅ Created {output_txt_path}\")\n",
    "    \n",
    "    # 6. Preview the first 5 entries\n",
    "    print(\"\\n--- Preview of New Mapping ---\")\n",
    "    for i, (k, v) in enumerate(list(new_data.items())[:5]):\n",
    "        print(f\"Chromosome {k}: {v} bp\")\n",
    "else:\n",
    "    print(f\"❌ Error: Input JSON {input_json_path} not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "306ac566-e11f-493c-8c90-41816fb65d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/azstephe/liverRegression/regression_liver/data/test_splits/log_pos_LiuAll/cow_liver_TEST_500bp.bed\n",
      "Original peaks: 1284\n",
      "Peaks kept: 1280\n",
      "Peaks lost: 4\n",
      "/home/azstephe/liverRegression/regression_liver/data/test_splits/log_pos_LiuAll/macaque_liver_TEST_500bp.bed\n",
      "Original peaks: 2624\n",
      "Peaks kept: 2619\n",
      "Peaks lost: 5\n",
      "/home/azstephe/liverRegression/regression_liver/data/test_splits/log_pos_LiuAll/rat_liver_TEST_500bp.bed\n",
      "Original peaks: 2576\n",
      "Peaks kept: 2575\n",
      "Peaks lost: 1\n",
      "/home/azstephe/liverRegression/regression_liver/data/test_splits/log_pos_LiuAll/pig_liver_TEST_500bp.bed\n",
      "Original peaks: 1627\n",
      "Peaks kept: 1624\n",
      "Peaks lost: 3\n",
      "/home/azstephe/liverRegression/regression_liver/data/test_splits/neg/pig_liver_TEST_500bp.bed\n",
      "Original peaks: 3057\n",
      "Peaks kept: 2860\n",
      "Peaks lost: 197\n",
      "/home/azstephe/liverRegression/regression_liver/data/test_splits/neg/rat_liver_TEST_500bp.bed\n",
      "Original peaks: 4405\n",
      "Peaks kept: 4404\n",
      "Peaks lost: 1\n",
      "/home/azstephe/liverRegression/regression_liver/data/test_splits/neg/macaque_liver_TEST_500bp.bed\n",
      "Original peaks: 3477\n",
      "Peaks kept: 3470\n",
      "Peaks lost: 7\n",
      "/home/azstephe/liverRegression/regression_liver/data/test_splits/neg/cow_liver_TEST_500bp.bed\n",
      "Original peaks: 3720\n",
      "Peaks kept: 2969\n",
      "Peaks lost: 751\n",
      "/home/azstephe/liverRegression/regression_liver/data/test_splits/neg/mouse_liver_TEST_500bp.bed\n",
      "Original peaks: 3698\n",
      "Peaks kept: 3698\n",
      "Peaks lost: 0\n",
      "/home/azstephe/liverRegression/regression_liver/data/test_splits/log_LiuAll_test1/macaque_liver_TEST_500bp.bed\n",
      "Original peaks: 1157\n",
      "Peaks kept: 1155\n",
      "Peaks lost: 2\n",
      "/home/azstephe/liverRegression/regression_liver/data/test_splits/log_LiuAll_test1/cow_liver_TEST_500bp.bed\n",
      "Original peaks: 1096\n",
      "Peaks kept: 1096\n",
      "Peaks lost: 0\n",
      "/home/azstephe/liverRegression/regression_liver/data/test_splits/log_LiuAll_test1/pig_liver_TEST_500bp.bed\n",
      "Original peaks: 940\n",
      "Peaks kept: 871\n",
      "Peaks lost: 69\n",
      "/home/azstephe/liverRegression/regression_liver/data/test_splits/log_LiuAll_test1/rat_liver_TEST_500bp.bed\n",
      "Original peaks: 1241\n",
      "Peaks kept: 1241\n",
      "Peaks lost: 0\n",
      "/home/azstephe/liverRegression/regression_liver/data/test_splits/log_test2/macaque_liver_TEST_500bp.bed\n",
      "Original peaks: 472\n",
      "Peaks kept: 472\n",
      "Peaks lost: 0\n",
      "/home/azstephe/liverRegression/regression_liver/data/test_splits/log_test2/pig_liver_TEST_500bp.bed\n",
      "Original peaks: 293\n",
      "Peaks kept: 293\n",
      "Peaks lost: 0\n",
      "/home/azstephe/liverRegression/regression_liver/data/test_splits/log_test2/rat_liver_TEST_500bp.bed\n",
      "Original peaks: 723\n",
      "Peaks kept: 723\n",
      "Peaks lost: 0\n",
      "/home/azstephe/liverRegression/regression_liver/data/test_splits/log_test2/cow_liver_TEST_500bp.bed\n",
      "Original peaks: 337\n",
      "Peaks kept: 336\n",
      "Peaks lost: 1\n",
      "/home/azstephe/liverRegression/regression_liver/data/test_splits/log_test3/rat_liver_TEST_500bp.bed\n",
      "Original peaks: 1025\n",
      "Peaks kept: 1024\n",
      "Peaks lost: 1\n",
      "/home/azstephe/liverRegression/regression_liver/data/test_splits/log_test3/pig_liver_TEST_500bp.bed\n",
      "Original peaks: 716\n",
      "Peaks kept: 715\n",
      "Peaks lost: 1\n",
      "/home/azstephe/liverRegression/regression_liver/data/test_splits/log_test3/cow_liver_TEST_500bp.bed\n",
      "Original peaks: 694\n",
      "Peaks kept: 694\n",
      "Peaks lost: 0\n",
      "/home/azstephe/liverRegression/regression_liver/data/test_splits/log_test3/macaque_liver_TEST_500bp.bed\n",
      "Original peaks: 1263\n",
      "Peaks kept: 1261\n",
      "Peaks lost: 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "keyword = '_liver_TEST_500bp.bed'\n",
    "test_dir = '/home/azstephe/liverRegression/regression_liver/data/test_splits/'\n",
    "\n",
    "out_dir = '/home/azstephe/liverRegression/regression_liver/data/enformer_inputs/'\n",
    "\n",
    "for d in ['log_pos_LiuAll', 'neg', 'log_LiuAll_test1', 'log_test2', 'log_test3']:\n",
    "    dr = os.path.join(test_dir, d)\n",
    "    for file in os.listdir(dr):\n",
    "        filepath = os.path.join(dr, file)\n",
    "        if 'non' not in filepath and keyword in filepath:\n",
    "            species = filepath.split('/')[-1].split('_')[0]\n",
    "            cols = ['chrom', 'start', 'end', 'peak', 'signal']\n",
    "            df = pd.read_csv(filepath, sep='\\t', names=cols)\n",
    "            \n",
    "            extension = 196608\n",
    "            df['new_start'] = df['start'] - extension + 250\n",
    "            df['new_end'] = df['end'] + extension - 250\n",
    "\n",
    "            with open('/home/azstephe/liverRegression/regression_liver/data/chrom_sizes/' + species + '_chrom_sizes.json', 'r') as f:\n",
    "                chrom_map = json.load(f)\n",
    "\n",
    "            df['max_len'] = df['chrom'].map(chrom_map)\n",
    "\n",
    "            valid_sections = df[(df['new_start'] >= 0) & (df['new_end'] <= df['max_len'])].copy()\n",
    "\n",
    "            print(filepath)\n",
    "            print(f\"Original peaks: {len(df)}\")\n",
    "            print(f\"Peaks kept: {len(valid_sections)}\")\n",
    "            print(f\"Peaks lost: {len(df) - len(valid_sections)}\")\n",
    "\n",
    "            out_dr = os.path.join(out_dir, d)\n",
    "            if not os.path.exists(out_dr):\n",
    "                os.makedirs(out_dr)\n",
    "            valid_sections[['chrom', 'new_start', 'new_end', 'peak', 'signal']].to_csv(os.path.join(out_dr, file), sep='\\t', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa1ac29c-8d28-4425-9dac-29af4d28bc0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cow_chrom_map'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chrom_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f073f6-96e8-40d5-b5b8-af0d57146717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b147f506-aced-431e-aded-b0e304de5dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2e35f1-8825-4c03-9927-3a7ec10ef3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "enformer = hub.Module('https://tfhub.dev/deepmind/enformer/1')\n",
    "\n",
    "SEQ_LENGTH = 393_216\n",
    "\n",
    "# Numpy array [batch_size, SEQ_LENGTH, 4] one hot encoded in order 'ACGT'. The\n",
    "# `one_hot_encode` function is available in `enformer.py` and outputs can be\n",
    "# stacked to form a batch.\n",
    "inputs = tf.zeros((1, SEQ_LENGTH, 4), dtype=tf.float32)\n",
    "predictions = enformer.predict_on_batch(inputs)\n",
    "predictions['human'].shape  # [batch_size, 896, 5313]\n",
    "predictions[mouse].shape  # [batch_size, 896, 1643]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdbfe35-c9c4-4cd0-b79a-3adc2d3b11cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "enformer_model = hub.load(\"https://tfhub.dev/deepmind/enformer/1\").signatures['serving_default']\n",
    "\n",
    "def prepare_input(sequence: str):\n",
    "    target_length = 393216\n",
    "    if len(sequence) != target_length:\n",
    "        print(\"input length != 393216\")\n",
    "        return\n",
    "\n",
    "    # Use your encoding function\n",
    "    encoded = one_hot_encode(sequence)\n",
    "    \n",
    "    # Add the Batch Dimension: (393216, 4) -> (1, 393216, 4)\n",
    "    return encoded[np.newaxis, ...]\n",
    "\n",
    "# 2. Run Inference\n",
    "input_tensor = tf.convert_to_tensor(prepare_input(\"ATCG...\"), dtype=tf.float32)\n",
    "outputs = enformer_model(input_tensor)\n",
    "\n",
    "# The outputs are a dictionary: 'human' and 'mouse'\n",
    "human_predictions = outputs['human'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4563b5-e22e-4280-86c6-ce624dc08b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedtools getfasta -fi GCF_000003205.7_Btau_5.0.1_genomic.fna -bed enformer_inputs.bed -fo enformer_sequences.fa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enformer",
   "language": "python",
   "name": "enformer_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
