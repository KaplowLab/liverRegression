{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "464ea045-69fe-4185-9656-d2fcd153f9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def correlations(pred_df, true_df, group):\n",
    "    x = true_df.squeeze()\n",
    "    y = pred_df.squeeze()\n",
    "    \n",
    "    pearson_corr, pearson_p_test = scipy.stats.pearsonr(x, y)\n",
    "    print(f\"Pearson correlation coefficient for {group}: {pearson_corr:.4f}, p-test: {pearson_p_test:.4g}\")\n",
    "    \n",
    "    spearman_corr, spearman_p_test = scipy.stats.spearmanr(x, y)\n",
    "    print(f\"Spearman correlation coefficient for {group}: {spearman_corr:.4f}, p-test: {spearman_p_test:.4g}\")\n",
    "def scatter(pred_df, true_df, title, xlabel, ylabel):\n",
    "    x = true_df.squeeze()\n",
    "    y = pred_df.squeeze() \n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.xlim(0, 4)\n",
    "    plt.ylim(0, 4)\n",
    "    plt.plot([0, 4], [0, 4], color='#015088', linestyle='--', label='y = x')\n",
    "    # plt.gcf().set_facecolor('#f3f0dfff')\n",
    "    # plt.gca().set_facecolor('#f3f0dfff')\n",
    "    plt.scatter(x, y, alpha=0.2)\n",
    "    plt.xlabel(f'{xlabel}')\n",
    "    plt.ylabel(f'{ylabel}')\n",
    "    plt.title(f'{title}')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def histogram(pred_df, title, xlabel):\n",
    "    plt.hist(pred_df, bins=50) #, color='#015088'\n",
    "    plt.xlim(0, 4)\n",
    "    # plt.gcf().set_facecolor('#f3f0dfff')\n",
    "    # plt.gca().set_facecolor('#f3f0dfff')\n",
    "    plt.xlabel(f'{xlabel}')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(f'{title}')\n",
    "    plt.show()\n",
    "\n",
    "def add_stats(df):\n",
    "    df['mean'] = df.mean(axis=1)\n",
    "    df['range'] = df.max(axis=1)-df.min(axis=1)\n",
    "    df['std'] = df.std(axis=1)\n",
    "\n",
    "def do_scatter(x, y, xlabel, ylabel, title, combined):\n",
    "    plt.scatter(x, y, alpha=0.2)\n",
    "    sc = plt.scatter(x, y, c=combined['std'], cmap='coolwarm', alpha=0.6)  # 'coolwarm' goes from blue to red\n",
    "    plt.colorbar(sc, label='Standard Deviation')  # adds a color bar legend\n",
    "    plt.xlabel(f'{xlabel}')\n",
    "    plt.ylabel(f'{ylabel}')\n",
    "    plt.title(f'{title}')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "def bayesian_scatter(combined, xaxis, yaxis):\n",
    "    x = combined[f'{xaxis}']\n",
    "    y = combined[f'{yaxis}']\n",
    "    \n",
    "    do_scatter(x, y, f'{xaxis}', f'{yaxis}', 'predicted all', combined)\n",
    "    \n",
    "    x = combined[combined['label'] == 'val1'][f'{xaxis}']\n",
    "    y = combined[combined['label'] == 'val1'][f'{yaxis}']\n",
    "    \n",
    "    do_scatter(x, y, f'{xaxis}', f'{yaxis}', 'predicted val1', combined[combined['label'] == 'val1'])\n",
    "    \n",
    "    x = combined[combined['label'] == 'val2'][f'{xaxis}']\n",
    "    y = combined[combined['label'] == 'val2'][f'{yaxis}']\n",
    "    \n",
    "    do_scatter(x, y, f'{xaxis}', f'{yaxis}', 'predicted val2', combined[combined['label'] == 'val2'])\n",
    "    \n",
    "    x = combined[combined['label'] == 'val3'][f'{xaxis}']\n",
    "    y = combined[combined['label'] == 'val3'][f'{yaxis}']\n",
    "    \n",
    "    do_scatter(x, y, f'{xaxis}', f'{yaxis}', 'predicted val3', combined[combined['label'] == 'val3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a45650d8-fc73-428d-9cff-f3eedb779daa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "macaque\n",
      "\n",
      "bdbi7l3n\n",
      "Pearson correlation coefficient for val2: 0.4373, p-test: 2.669e-32\n",
      "Spearman correlation coefficient for val2: 0.4312, p-test: 2.358e-31\n",
      "Pearson correlation coefficient for test2: 0.2895, p-test: 1.114e-19\n",
      "Spearman correlation coefficient for test2: 0.2737, p-test: 1.119e-17\n",
      "Pearson correlation coefficient for val3: 0.3299, p-test: 2.59e-46\n",
      "Spearman correlation coefficient for val3: 0.3453, p-test: 7.484e-51\n",
      "Pearson correlation coefficient for test3: 0.3354, p-test: 9.074e-64\n",
      "Spearman correlation coefficient for test3: 0.3595, p-test: 1.174e-73\n",
      "\n",
      "\n",
      "Pearson correlation coefficient for mouse orthologs: 0.3266, p-test: 1.034e-130\n",
      "Spearman correlation coefficient for mouse orthologs: 0.3461, p-test: 1.444e-147\n",
      "\n",
      "7vsdq5k2\n",
      "Pearson correlation coefficient for val2: 0.3985, p-test: 1.267e-26\n",
      "Spearman correlation coefficient for val2: 0.4231, p-test: 3.885e-30\n",
      "Pearson correlation coefficient for test2: 0.2824, p-test: 9.166e-19\n",
      "Spearman correlation coefficient for test2: 0.2789, p-test: 2.492e-18\n",
      "Pearson correlation coefficient for val3: 0.3780, p-test: 2.439e-61\n",
      "Spearman correlation coefficient for val3: 0.3898, p-test: 1.88e-65\n",
      "Pearson correlation coefficient for test3: 0.3802, p-test: 7.485e-83\n",
      "Spearman correlation coefficient for test3: 0.4002, p-test: 2.227e-92\n",
      "\n",
      "\n",
      "Pearson correlation coefficient for mouse orthologs: 0.3386, p-test: 6.4e-141\n",
      "Spearman correlation coefficient for mouse orthologs: 0.3652, p-test: 2.826e-165\n",
      "\n",
      "rat\n",
      "\n",
      "bdbi7l3n\n",
      "Pearson correlation coefficient for val2: 0.2256, p-test: 8.828e-11\n",
      "Spearman correlation coefficient for val2: 0.2051, p-test: 4.011e-09\n",
      "Pearson correlation coefficient for test2: 0.2586, p-test: 1.6e-23\n",
      "Spearman correlation coefficient for test2: 0.2504, p-test: 4.204e-22\n",
      "Pearson correlation coefficient for val3: 0.3080, p-test: 8.731e-31\n",
      "Spearman correlation coefficient for val3: 0.3006, p-test: 2.423e-29\n",
      "Pearson correlation coefficient for test3: 0.3174, p-test: 3.38e-49\n",
      "Spearman correlation coefficient for test3: 0.3085, p-test: 1.861e-46\n",
      "\n",
      "\n",
      "Pearson correlation coefficient for mouse orthologs: 0.3326, p-test: 2.833e-133\n",
      "Spearman correlation coefficient for mouse orthologs: 0.3322, p-test: 5.37e-133\n",
      "\n",
      "7vsdq5k2\n",
      "Pearson correlation coefficient for val2: 0.1956, p-test: 2.082e-08\n",
      "Spearman correlation coefficient for val2: 0.2058, p-test: 3.516e-09\n",
      "Pearson correlation coefficient for test2: 0.2191, p-test: 3.518e-17\n",
      "Spearman correlation coefficient for test2: 0.2232, p-test: 8.805e-18\n",
      "Pearson correlation coefficient for val3: 0.3053, p-test: 2.91e-30\n",
      "Spearman correlation coefficient for val3: 0.2927, p-test: 7.732e-28\n",
      "Pearson correlation coefficient for test3: 0.3084, p-test: 2.031e-46\n",
      "Spearman correlation coefficient for test3: 0.3059, p-test: 1.194e-45\n",
      "\n",
      "\n",
      "Pearson correlation coefficient for mouse orthologs: 0.3196, p-test: 1.113e-122\n",
      "Spearman correlation coefficient for mouse orthologs: 0.3275, p-test: 4.801e-129\n",
      "\n",
      "cow\n",
      "\n",
      "bdbi7l3n\n",
      "Pearson correlation coefficient for val2: 0.5468, p-test: 1.237e-31\n",
      "Spearman correlation coefficient for val2: 0.5396, p-test: 1.074e-30\n",
      "Pearson correlation coefficient for test2: 0.3636, p-test: 1.686e-22\n",
      "Spearman correlation coefficient for test2: 0.3636, p-test: 1.728e-22\n",
      "Pearson correlation coefficient for val3: 0.2561, p-test: 4.111e-18\n",
      "Spearman correlation coefficient for val3: 0.2635, p-test: 4.089e-19\n",
      "Pearson correlation coefficient for test3: 0.3185, p-test: 4.22e-34\n",
      "Spearman correlation coefficient for test3: 0.3212, p-test: 1.106e-34\n",
      "\n",
      "\n",
      "Pearson correlation coefficient for mouse orthologs: 0.3769, p-test: 7.767e-113\n",
      "Spearman correlation coefficient for mouse orthologs: 0.3852, p-test: 3.353e-118\n",
      "\n",
      "7vsdq5k2\n",
      "Pearson correlation coefficient for val2: 0.5108, p-test: 3.57e-27\n",
      "Spearman correlation coefficient for val2: 0.5043, p-test: 2.02e-26\n",
      "Pearson correlation coefficient for test2: 0.3548, p-test: 2.027e-21\n",
      "Spearman correlation coefficient for test2: 0.3506, p-test: 6.311e-21\n",
      "Pearson correlation coefficient for val3: 0.2671, p-test: 1.282e-19\n",
      "Spearman correlation coefficient for val3: 0.2878, p-test: 1.177e-22\n",
      "Pearson correlation coefficient for test3: 0.3033, p-test: 6.324e-31\n",
      "Spearman correlation coefficient for test3: 0.3040, p-test: 4.566e-31\n",
      "\n",
      "\n",
      "Pearson correlation coefficient for mouse orthologs: 0.3631, p-test: 2.976e-104\n",
      "Spearman correlation coefficient for mouse orthologs: 0.3716, p-test: 1.705e-109\n",
      "\n",
      "pig\n",
      "\n",
      "bdbi7l3n\n",
      "Pearson correlation coefficient for val2: 0.4560, p-test: 3.033e-18\n",
      "Spearman correlation coefficient for val2: 0.4502, p-test: 9.047e-18\n",
      "Pearson correlation coefficient for test2: 0.3506, p-test: 2.147e-18\n",
      "Spearman correlation coefficient for test2: 0.3415, p-test: 1.792e-17\n",
      "Pearson correlation coefficient for val3: 0.2742, p-test: 7.542e-18\n",
      "Spearman correlation coefficient for val3: 0.2694, p-test: 2.901e-17\n",
      "Pearson correlation coefficient for test3: 0.3371, p-test: 2.134e-39\n",
      "Spearman correlation coefficient for test3: 0.3373, p-test: 1.945e-39\n",
      "\n",
      "\n",
      "Pearson correlation coefficient for mouse orthologs: 0.3884, p-test: 1.118e-117\n",
      "Spearman correlation coefficient for mouse orthologs: 0.3945, p-test: 1.257e-121\n",
      "\n",
      "7vsdq5k2\n",
      "Pearson correlation coefficient for val2: 0.3813, p-test: 8.561e-13\n",
      "Spearman correlation coefficient for val2: 0.3768, p-test: 1.675e-12\n",
      "Pearson correlation coefficient for test2: 0.2927, p-test: 4.888e-13\n",
      "Spearman correlation coefficient for test2: 0.2901, p-test: 7.969e-13\n",
      "Pearson correlation coefficient for val3: 0.3039, p-test: 9.58e-22\n",
      "Spearman correlation coefficient for val3: 0.2996, p-test: 3.683e-21\n",
      "Pearson correlation coefficient for test3: 0.3352, p-test: 6.167e-39\n",
      "Spearman correlation coefficient for test3: 0.3273, p-test: 4.149e-37\n",
      "\n",
      "\n",
      "Pearson correlation coefficient for mouse orthologs: 0.3666, p-test: 4.374e-104\n",
      "Spearman correlation coefficient for mouse orthologs: 0.3720, p-test: 2.449e-107\n"
     ]
    }
   ],
   "source": [
    "def correlate():\n",
    "    correlations(pred_val2_df, doubled_val2_df, 'val2')\n",
    "    correlations(pred_test2_df, doubled_test2_df, 'test2')\n",
    "    correlations(pred_val3_df, doubled_val3_df, 'val3')\n",
    "    correlations(pred_test3_df, doubled_test3_df, 'test3')\n",
    "\n",
    "    print('\\n')\n",
    "    correlations(pred_pos_df, doubled_pos_df, 'mouse orthologs')\n",
    "    \n",
    "species_list = ['macaque', 'rat', 'cow', 'pig']\n",
    "# species_list = ['rat']\n",
    "model_list = ['bdbi7l3n', '7vsdq5k2']\n",
    "for species in species_list:\n",
    "    print(f'\\n{species}')\n",
    "    for model in model_list:\n",
    "        print(f'\\n{model}')\n",
    "        \n",
    "        # load all the DFs\n",
    "        pred_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model}/activations_{species}_TEST.csv', header=None)\n",
    "        \n",
    "        test1_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/amy_test1/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        test2_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_test2/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        test3_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_test3/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        test1_len = 2*len(test1_df)\n",
    "        test2_len = 2*len(test2_df)\n",
    "        test3_len = 2*len(test3_df)\n",
    "        \n",
    "        # input sanity check\n",
    "        if len(pred_df) != test1_len+test2_len+test3_len:\n",
    "            print(\"ERROR: predictions are a different length than testidation sets\")\n",
    "        \n",
    "        doubled_test1_df = pd.concat([test1_df, test1_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_test2_df = pd.concat([test2_df, test2_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_test3_df = pd.concat([test3_df, test3_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_test1_df = pred_df.head(test1_len)\n",
    "        pred_test2_df = pred_df.iloc[test1_len:test1_len + test2_len]\n",
    "        pred_test3_df = pred_df.tail(test3_len)\n",
    "\n",
    "        # print(f'average test1 prediction: {pred_test1_df.mean()}')\n",
    "        \n",
    "        #############\n",
    "        pred_orthologs_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model}/activations_{species}_TEST_orthologs.csv', header=None)\n",
    "        \n",
    "        neg_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/neg/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        pos_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_pos/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        neg_len = 2*len(neg_df)\n",
    "        pos_len = 2*len(pos_df)\n",
    "        \n",
    "        # input sanity check\n",
    "        if len(pred_orthologs_df) != neg_len+pos_len:\n",
    "            print(\"ERROR: predictions are a different length than testidation sets\")\n",
    "\n",
    "        doubled_neg_df = pd.concat([neg_df, neg_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_pos_df = pd.concat([pos_df, pos_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_pos_df = pred_orthologs_df.head(pos_len)\n",
    "        pred_neg_df = pred_orthologs_df.tail(neg_len)\n",
    "\n",
    "        # print(f'average neg test prediction: {pred_neg_df.mean()}')\n",
    "\n",
    "        neg = 'nonMacaque_liver_andRat_andCow_andPig_VAL_500bp.bed'\n",
    "        if species == 'rat':\n",
    "            neg = 'nonRat_liver_andMacaque_andCow_andPig_VAL_500bp.bed'\n",
    "        elif species == 'cow':\n",
    "            neg = 'nonCow_liver_andMacaque_andRat_andPig_VAL_500bp.bed'\n",
    "        elif species == 'pig':\n",
    "            neg = 'nonPig_liver_andMacaque_andRat_andCow_VAL_500bp.bed'\n",
    "        \n",
    "        # load all the DFs\n",
    "        pred_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model}/activations_{species}_VAL.csv', header=None)\n",
    "        \n",
    "        val1_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/splits/val1/{species}_liver_VAL.narrowPeak', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        val2_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/splits/log_val2/{species}_liver_VAL.narrowPeak', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        val3_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/splits/log_val3/{species}_liver_VAL.narrowPeak', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        val1_len = 2*len(val1_df)\n",
    "        val2_len = 2*len(val2_df)\n",
    "        val3_len = 2*len(val3_df)\n",
    "        \n",
    "        # input sanity check\n",
    "        if len(pred_df) != val1_len+val2_len+val3_len:\n",
    "            print(\"ERROR: predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_val1_df = pd.concat([val1_df, val1_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_val2_df = pd.concat([val2_df, val2_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_val3_df = pd.concat([val3_df, val3_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_val1_df = pred_df.head(val1_len)\n",
    "        pred_val2_df = pred_df.iloc[val1_len:val1_len + val2_len]\n",
    "        pred_val3_df = pred_df.tail(val3_len)\n",
    "        \n",
    "        doubled_combined = pd.concat([doubled_val1_df, doubled_val2_df, doubled_val3_df])\n",
    "\n",
    "        # print(f'average val1 prediction: {pred_val1_df.mean()}')\n",
    "        \n",
    "        correlate()\n",
    "\n",
    "\n",
    "\n",
    "        # scatter(pred_test2_df, doubled_test2_df, 'True vs predicted for test2', 'True', 'Predicted')\n",
    "        # scatter(pred_test3_df, doubled_test3_df, 'True vs predicted for test3', 'True', 'Predicted')\n",
    "        # scatter(pred_pos_df, doubled_pos_df, 'True vs predicted for orthologs', 'True', 'Predicted')\n",
    "\n",
    "\n",
    "        # histogram(pred_test1_df, 'test1 predictions', 'Predicted signal')\n",
    "        # histogram(pred_test2_df, 'test2 predictions', 'Predicted signal')\n",
    "        # histogram(pred_test3_df, 'test3 predictions', 'Predicted signal')\n",
    "    \n",
    "        # histogram(pred_neg_df, 'negative test predictions', 'Predicted signal')\n",
    "        # histogram(pred_pos_df, 'positive test predictions', 'Predicted signal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b355f3bf-5ee0-49b7-b438-d6a84d9ffc2d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bdbi7l3n\n",
      "average neg test prediction: 0    0.609153\n",
      "dtype: float64\n",
      "average neg val prediction: 0    0.61926\n",
      "dtype: float64\n",
      "Pearson correlation coefficient for train, pos only: 0.4937, p-test: 0\n",
      "Spearman correlation coefficient for train, pos only: 0.4982, p-test: 0\n",
      "Pearson correlation coefficient for val, pos only: 0.4827, p-test: 1.745e-234\n",
      "Spearman correlation coefficient for val, pos only: 0.4913, p-test: 4.294e-244\n",
      "Pearson correlation coefficient for test, pos only: 0.4958, p-test: 0\n",
      "Spearman correlation coefficient for test, pos only: 0.5022, p-test: 0\n",
      "\n",
      "7vsdq5k2\n",
      "average neg test prediction: 0    0.590392\n",
      "dtype: float64\n",
      "average neg val prediction: 0    0.599513\n",
      "dtype: float64\n",
      "Pearson correlation coefficient for train, pos only: 0.4967, p-test: 0\n",
      "Spearman correlation coefficient for train, pos only: 0.5094, p-test: 0\n",
      "Pearson correlation coefficient for val, pos only: 0.4574, p-test: 1.128e-207\n",
      "Spearman correlation coefficient for val, pos only: 0.4768, p-test: 5.493e-228\n",
      "Pearson correlation coefficient for test, pos only: 0.4798, p-test: 0\n",
      "Spearman correlation coefficient for test, pos only: 0.4896, p-test: 0\n"
     ]
    }
   ],
   "source": [
    "def correlate():\n",
    "    correlations(pred_train_df, doubled_train_df, 'train, pos only')\n",
    "    correlations(pred_val_df, doubled_val_df, 'val, pos only')\n",
    "    correlations(pred_pos_df, doubled_pos_df, 'test, pos only')\n",
    "    \n",
    "model_list = ['bdbi7l3n', '7vsdq5k2']\n",
    "species = 'mouse'\n",
    "for model in model_list:\n",
    "    print(f'\\n{model}')\n",
    "        \n",
    "     # load all the DFs\n",
    "    pred_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model}/activations_{species}_TEST.csv', header=None)\n",
    "        \n",
    "    pos_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_pos/mouse_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "    neg_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/neg/mouse_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "    pos_len = 2*len(pos_df)\n",
    "    neg_len = 2*len(neg_df)\n",
    "        \n",
    "        # input sanity check\n",
    "    if len(pred_df) != pos_len+neg_len:\n",
    "        print(\"ERROR: predictions are a different length than testidation sets\")\n",
    "        \n",
    "    doubled_pos_df = pd.concat([pos_df, pos_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "    doubled_neg_df = pd.concat([neg_df, neg_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "    pred_pos_df = pred_df.head(pos_len)\n",
    "    pred_neg_df = pred_df.tail(neg_len)\n",
    "\n",
    "    print(f'average neg test prediction: {pred_neg_df.mean()}')\n",
    "        \n",
    "    pred_val_train_mouse = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model}/activations_{species}_VAL_TRAIN.csv', header=None, sep='\\t')\n",
    "    \n",
    "    neg_df = pd.read_csv(f'/home/azstephe/regression_liver/data/splits/negatives/nonMouse_liver_andRat_andCow_andPig_andMacaque_VAL_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "    val_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/splits/logPos/{species}_liver_VAL.narrowPeak', header=None, delim_whitespace=True).iloc[:,4]\n",
    "    train_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/splits/logPos/{species}_liver_TRAINONLY.narrowPeak', header=None, delim_whitespace=True).iloc[:,4]\n",
    "    \n",
    "    val1_len = 2*len(neg_df)\n",
    "    val2_len = 2*len(val_df)\n",
    "    val3_len = 2*len(train_df)\n",
    "    \n",
    "    # input sanity check\n",
    "    if len(pred_val_train_mouse) != val1_len+val2_len+val3_len:\n",
    "        print(\"ERROR: predictions are a different length than validation sets\")\n",
    "    \n",
    "    doubled_neg_df = pd.concat([neg_df, neg_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "    doubled_val_df = pd.concat([val_df, val_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "    doubled_train_df = pd.concat([train_df, train_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "    \n",
    "    pred_neg_df = pred_val_train_mouse.head(val1_len)\n",
    "    pred_val_df = pred_val_train_mouse.iloc[val1_len:val1_len + val2_len]\n",
    "    pred_train_df = pred_val_train_mouse.tail(val3_len)\n",
    "\n",
    "    pred_neg_pos_val_mouse = pd.concat([pred_neg_df, pred_val_df]).reset_index(drop=True)\n",
    "    \n",
    "    doubled_combined_val_train = pd.concat([doubled_neg_df, doubled_val_df, doubled_train_df]).reset_index(drop=True)\n",
    "    mouse_combined = pd.concat([doubled_combined_val_train, pred_val_train_mouse])\n",
    "    print(f'average neg val prediction: {pred_neg_df.mean()}')\n",
    "    correlate()\n",
    "\n",
    "\n",
    "\n",
    "        # scatter(pred_test2_df, doubled_test2_df, 'True vs predicted for test2', 'True', 'Predicted')\n",
    "        # scatter(pred_test3_df, doubled_test3_df, 'True vs predicted for test3', 'True', 'Predicted')\n",
    "        # scatter(pred_pos_df, doubled_pos_df, 'True vs predicted for orthologs', 'True', 'Predicted')\n",
    "\n",
    "\n",
    "        # histogram(pred_test1_df, 'test1 predictions', 'Predicted signal')\n",
    "        # histogram(pred_test2_df, 'test2 predictions', 'Predicted signal')\n",
    "        # histogram(pred_test3_df, 'test3 predictions', 'Predicted signal')\n",
    "    \n",
    "        # histogram(pred_neg_df, 'negative test predictions', 'Predicted signal')\n",
    "        # histogram(pred_pos_df, 'positive test predictions', 'Predicted signal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "50b988aa-9025-4e91-b726-da7b5e30fd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "macaque\n",
      "\n",
      "bdbi7l3n_bayesian\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/azstephe/liverRegression/regression_liver/data/model_outputs/bdbi7l3n_bayesian/activations_macaque_TEST_orthologs.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 46\u001b[0m\n\u001b[1;32m     41\u001b[0m pred_test3_df \u001b[38;5;241m=\u001b[39m pred_df\u001b[38;5;241m.\u001b[39mtail(test3_len)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# print(f'average test1 prediction: {pred_test1_df.mean()}')\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#############\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m pred_orthologs_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/azstephe/liverRegression/regression_liver/data/model_outputs/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/activations_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mspecies\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_TEST_orthologs.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m neg_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/azstephe/liverRegression/regression_liver/data/test_splits/neg/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspecies\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_liver_TEST_500bp.bed\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, delim_whitespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m     49\u001b[0m pos_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/azstephe/liverRegression/regression_liver/data/test_splits/log_pos/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspecies\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_liver_TEST_500bp.bed\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, delim_whitespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m4\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/azstephe/liverRegression/regression_liver/data/model_outputs/bdbi7l3n_bayesian/activations_macaque_TEST_orthologs.csv'"
     ]
    }
   ],
   "source": [
    "# non mouse bayesian\n",
    "def correlate():\n",
    "    correlations(pred_val2_df, doubled_val2_df, 'val2')\n",
    "    correlations(pred_test2_df, doubled_test2_df, 'test2')\n",
    "    correlations(pred_val3_df, doubled_val3_df, 'val3')\n",
    "    correlations(pred_test3_df, doubled_test3_df, 'test3')\n",
    "\n",
    "    print('\\n')\n",
    "    correlations(pred_pos_df, doubled_pos_df, 'mouse orthologs')\n",
    "    \n",
    "species_list = ['macaque', 'rat', 'cow', 'pig']\n",
    "# species_list = ['rat']\n",
    "model_list = ['7vsdq5k2']\n",
    "for species in species_list:\n",
    "    print(f'\\n{species}')\n",
    "    for model in model_list:\n",
    "        print(f'\\n{model}')\n",
    "        \n",
    "        # load all the DFs\n",
    "        pred_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model}_bayesian/activations_{species}_TEST.csv', header=None)\n",
    "        \n",
    "        test1_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/amy_test1/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        test2_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_test2/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        test3_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_test3/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        test1_len = 2*len(test1_df)\n",
    "        test2_len = 2*len(test2_df)\n",
    "        test3_len = 2*len(test3_df)\n",
    "        \n",
    "        # input sanity check\n",
    "        if len(pred_df) != test1_len+test2_len+test3_len:\n",
    "            print(\"ERROR: predictions are a different length than testidation sets\")\n",
    "        \n",
    "        doubled_test1_df = pd.concat([test1_df, test1_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_test2_df = pd.concat([test2_df, test2_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_test3_df = pd.concat([test3_df, test3_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_test1_df = pred_df.head(test1_len)\n",
    "        pred_test2_df = pred_df.iloc[test1_len:test1_len + test2_len]\n",
    "        pred_test3_df = pred_df.tail(test3_len)\n",
    "\n",
    "        # print(f'average test1 prediction: {pred_test1_df.mean()}')\n",
    "        \n",
    "        #############\n",
    "        pred_orthologs_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model}/activations_{species}_TEST_orthologs.csv', header=None)\n",
    "        \n",
    "        neg_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/neg/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        pos_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_pos/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        neg_len = 2*len(neg_df)\n",
    "        pos_len = 2*len(pos_df)\n",
    "        \n",
    "        # input sanity check\n",
    "        if len(pred_orthologs_df) != neg_len+pos_len:\n",
    "            print(\"ERROR: predictions are a different length than testidation sets\")\n",
    "\n",
    "        doubled_neg_df = pd.concat([neg_df, neg_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_pos_df = pd.concat([pos_df, pos_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_pos_df = pred_orthologs_df.head(pos_len)\n",
    "        pred_neg_df = pred_orthologs_df.tail(neg_len)\n",
    "\n",
    "        # print(f'average neg test prediction: {pred_neg_df.mean()}')\n",
    "\n",
    "        neg = 'nonMacaque_liver_andRat_andCow_andPig_VAL_500bp.bed'\n",
    "        if species == 'rat':\n",
    "            neg = 'nonRat_liver_andMacaque_andCow_andPig_VAL_500bp.bed'\n",
    "        elif species == 'cow':\n",
    "            neg = 'nonCow_liver_andMacaque_andRat_andPig_VAL_500bp.bed'\n",
    "        elif species == 'pig':\n",
    "            neg = 'nonPig_liver_andMacaque_andRat_andCow_VAL_500bp.bed'\n",
    "        \n",
    "        # load all the DFs\n",
    "        pred_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model}/activations_{species}_VAL.csv', header=None)\n",
    "        \n",
    "        val1_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/splits/val1/{species}_liver_VAL.narrowPeak', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        val2_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/splits/log_val2/{species}_liver_VAL.narrowPeak', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        val3_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/splits/log_val3/{species}_liver_VAL.narrowPeak', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        val1_len = 2*len(val1_df)\n",
    "        val2_len = 2*len(val2_df)\n",
    "        val3_len = 2*len(val3_df)\n",
    "        \n",
    "        # input sanity check\n",
    "        if len(pred_df) != val1_len+val2_len+val3_len:\n",
    "            print(\"ERROR: predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_val1_df = pd.concat([val1_df, val1_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_val2_df = pd.concat([val2_df, val2_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_val3_df = pd.concat([val3_df, val3_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_val1_df = pred_df.head(val1_len)\n",
    "        pred_val2_df = pred_df.iloc[val1_len:val1_len + val2_len]\n",
    "        pred_val3_df = pred_df.tail(val3_len)\n",
    "        \n",
    "        doubled_combined = pd.concat([doubled_val1_df, doubled_val2_df, doubled_val3_df])\n",
    "\n",
    "        # print(f'average val1 prediction: {pred_val1_df.mean()}')\n",
    "        \n",
    "        correlate()\n",
    "\n",
    "\n",
    "\n",
    "        # scatter(pred_test2_df, doubled_test2_df, 'True vs predicted for test2', 'True', 'Predicted')\n",
    "        # scatter(pred_test3_df, doubled_test3_df, 'True vs predicted for test3', 'True', 'Predicted')\n",
    "        # scatter(pred_pos_df, doubled_pos_df, 'True vs predicted for orthologs', 'True', 'Predicted')\n",
    "\n",
    "\n",
    "        # histogram(pred_test1_df, 'test1 predictions', 'Predicted signal')\n",
    "        # histogram(pred_test2_df, 'test2 predictions', 'Predicted signal')\n",
    "        # histogram(pred_test3_df, 'test3 predictions', 'Predicted signal')\n",
    "    \n",
    "        # histogram(pred_neg_df, 'negative test predictions', 'Predicted signal')\n",
    "        # histogram(pred_pos_df, 'positive test predictions', 'Predicted signal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2f675f1c-2cd7-4a55-afd3-8dc3be48fccd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'do_scatter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m combined[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_diff\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(combined[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m combined[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     51\u001b[0m combined\n\u001b[0;32m---> 52\u001b[0m \u001b[43mbayesian_scatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m bayesian_scatter(combined, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     54\u001b[0m bayesian_scatter(combined, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[44], line 51\u001b[0m, in \u001b[0;36mbayesian_scatter\u001b[0;34m(combined, xaxis, yaxis)\u001b[0m\n\u001b[1;32m     48\u001b[0m x \u001b[38;5;241m=\u001b[39m combined[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mxaxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     49\u001b[0m y \u001b[38;5;241m=\u001b[39m combined[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myaxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 51\u001b[0m \u001b[43mdo_scatter\u001b[49m(x, y, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mxaxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myaxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted all\u001b[39m\u001b[38;5;124m'\u001b[39m, combined)\n\u001b[1;32m     53\u001b[0m x \u001b[38;5;241m=\u001b[39m combined[combined[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval1\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mxaxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     54\u001b[0m y \u001b[38;5;241m=\u001b[39m combined[combined[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval1\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myaxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'do_scatter' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "species='macaque'\n",
    "model='7vsdq5k2'\n",
    "\n",
    "# load all the DFs\n",
    "pred_baye = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model}_bayesian/activations_{species}_TEST.csv', header=None, delim_whitespace=True)\n",
    "add_stats(pred_baye)\n",
    "\n",
    "test1_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/amy_test1/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "test1_df = test1_df.replace(-1, 0)\n",
    "test2_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_test2/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "test3_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_test3/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "\n",
    "test1_len = 2*len(test1_df)\n",
    "test2_len = 2*len(test2_df)\n",
    "test3_len = 2*len(test3_df)\n",
    "\n",
    "# input sanity check\n",
    "if len(pred_baye) != test1_len+test2_len+test3_len:\n",
    "    print(\"ERROR: predictions are a different length than testidation sets\")\n",
    "\n",
    "doubled_test1_df = pd.concat([test1_df, test1_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "doubled_test2_df = pd.concat([test2_df, test2_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "doubled_test3_df = pd.concat([test3_df, test3_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "\n",
    "baye_test1_df = pred_baye.head(test1_len)\n",
    "baye_test2_df = pred_baye.iloc[test1_len:test1_len + test2_len]\n",
    "baye_test3_df = pred_baye.tail(test3_len)\n",
    "\n",
    "doubled_combined = pd.concat([doubled_test1_df, doubled_test2_df, doubled_test3_df])\n",
    "doubled_combined = doubled_combined.reset_index(drop=True)\n",
    "\n",
    "pred_df = pred_df.reset_index(drop=True)\n",
    "pred_baye = pred_baye.reset_index(drop=True)\n",
    "\n",
    "doubled_combined = doubled_combined.to_frame(name='true')\n",
    "\n",
    "doubled_combined.loc[0:test1_len-1, 'label'] = 'test1'\n",
    "doubled_combined.loc[test1_len:test1_len + test2_len - 1, 'label'] = 'test2'\n",
    "doubled_combined.loc[test1_len + test2_len:, 'label'] = 'test3'\n",
    "\n",
    "combined = pd.concat([pred_baye, doubled_combined], axis=1)\n",
    "\n",
    "squared_errors = (combined.loc[:, 0:63].subtract(combined['true'], axis=0)) ** 2\n",
    "combined['mse'] = squared_errors.mean(axis=1)\n",
    "combined['mean_diff'] = abs(combined['mean'] - combined['true'])\n",
    "combined\n",
    "bayesian_scatter(combined, 'mean', 'std')\n",
    "bayesian_scatter(combined, 'mean', 'mse')\n",
    "bayesian_scatter(combined, 'std', 'mse')\n",
    "\n",
    "correlations(combined[combined['label']=='test2']['std'], combined[combined['label']=='test2']['mse'], 'test2 macaque')\n",
    "correlations(combined[combined['label']=='test3']['std'], combined[combined['label']=='test3']['mse'], 'test3 macaque')\n",
    "bayesian_scatter(combined, 'mean_diff', 'mse')\n",
    "bayesian_scatter(combined, 'mean_diff', 'std')\n",
    "\n",
    "# threshold_correlate(combined, 'std', 0.3)\n",
    "# print('\\n')\n",
    "# threshold_correlate(combined, 'std', 0.4)\n",
    "# threshold_scatter(combined, 'std', 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cf422536-e15e-46ba-ba0b-9d40afeae75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>134484347</td>\n",
       "      <td>134484847</td>\n",
       "      <td>peak10605</td>\n",
       "      <td>2.718037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>135389947</td>\n",
       "      <td>135390447</td>\n",
       "      <td>peak72645</td>\n",
       "      <td>1.816486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>136913858</td>\n",
       "      <td>136914358</td>\n",
       "      <td>peak78586</td>\n",
       "      <td>1.616586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1</td>\n",
       "      <td>136927092</td>\n",
       "      <td>136927592</td>\n",
       "      <td>peak51393</td>\n",
       "      <td>2.061906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1</td>\n",
       "      <td>136988427</td>\n",
       "      <td>136988927</td>\n",
       "      <td>peak44530</td>\n",
       "      <td>2.097141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>chr9</td>\n",
       "      <td>25033115</td>\n",
       "      <td>25033615</td>\n",
       "      <td>peak73344</td>\n",
       "      <td>1.760068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>chr9</td>\n",
       "      <td>26594127</td>\n",
       "      <td>26594627</td>\n",
       "      <td>peak15914</td>\n",
       "      <td>2.700721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>chr9</td>\n",
       "      <td>26594644</td>\n",
       "      <td>26595144</td>\n",
       "      <td>peak87593</td>\n",
       "      <td>1.435739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>chr9</td>\n",
       "      <td>41267864</td>\n",
       "      <td>41268364</td>\n",
       "      <td>peak61898</td>\n",
       "      <td>2.040823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>chrUn_NW_014830195v1</td>\n",
       "      <td>49699</td>\n",
       "      <td>50199</td>\n",
       "      <td>peak95697</td>\n",
       "      <td>1.270415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1192 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0          1          2          3         4\n",
       "0                     chr1  134484347  134484847  peak10605  2.718037\n",
       "1                     chr1  135389947  135390447  peak72645  1.816486\n",
       "2                     chr1  136913858  136914358  peak78586  1.616586\n",
       "3                     chr1  136927092  136927592  peak51393  2.061906\n",
       "4                     chr1  136988427  136988927  peak44530  2.097141\n",
       "...                    ...        ...        ...        ...       ...\n",
       "1187                  chr9   25033115   25033615  peak73344  1.760068\n",
       "1188                  chr9   26594127   26594627  peak15914  2.700721\n",
       "1189                  chr9   26594644   26595144  peak87593  1.435739\n",
       "1190                  chr9   41267864   41268364  peak61898  2.040823\n",
       "1191  chrUn_NW_014830195v1      49699      50199  peak95697  1.270415\n",
       "\n",
       "[1192 rows x 5 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_test3/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe01c9e8-98b4-45cc-94be-9ac41e59caef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
