{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c8366af-113f-408e-be5f-7fc273e00fcf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Correlating model predictions with real signal values.\n",
    "\n",
    "This notebook assesses model accuracy by comparing predicted to real signal values.\n",
    "\n",
    "### Correlation Analysis: \n",
    "Measures linear (Pearson $r$) and rank-based (Spearman $\\rho$) relationships. Uses Mean Squared Error (MSE) to measure prediction deviation. Organizes performance metrics by Species and Group (e.g., Test sets).\n",
    "\n",
    "### Example output table \n",
    "\n",
    "| Species | Group | Metric | Model ID |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| Cow | Test | Pearson ($r$) | 0.422 |\n",
    "| | | Pearson $p$-val | $1.88 \\times 10^{-109}$ |\n",
    "| | | Spearman ($\\rho$) | 0.43 |\n",
    "| | | Spearman $p$-val | $2.47 \\times 10^{-114}$ |\n",
    "| | | MSE | 2.52 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1303eeae-4361-47de-85b9-e73b5e49b197",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# helper functions\n",
    "\n",
    "def pearson_spearman(x, y):\n",
    "    pearson_corr, pearson_p_value = scipy.stats.pearsonr(x, y)\n",
    "    print(f\"Pearson correlation coefficient: {pearson_corr:.4f}, p-value: {pearson_p_value:.4g}\")\n",
    "\n",
    "    spearman_corr, spearman_p_value = scipy.stats.spearmanr(x, y)\n",
    "    print(f\"Spearman correlation coefficient: {spearman_corr:.4f}, p-value: {spearman_p_value:.4g}\")\n",
    "\n",
    "species_list = ['macaque', 'rat', 'cow', 'pig']\n",
    "\n",
    "def mean_squared_error(x, y):\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    return np.mean((x - y) ** 2)\n",
    "\n",
    "def format_value(metric_name, value):\n",
    "    \"\"\"Format values depending on whether it's a P-value metric or not.\"\"\"\n",
    "    # Check for '_p' which is more general for 'pearson_p', 'spearman_p' etc.\n",
    "    if \"_p\" in metric_name:\n",
    "        return f\"{value:.2e}\"  # Scientific notation for p-values\n",
    "    else:\n",
    "        return f\"{value:.3g}\"  # General format for other metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b0d3ca-005d-463e-b842-3fb66d68275b",
   "metadata": {},
   "source": [
    "### Set global parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "096b1a1f-1943-4b6c-97cd-b77771e2aca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple hypothesis correction coefficient\n",
    "MHC = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d679f4f5-df4c-48dc-b41f-4ad2a6c47b33",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "\n",
    "`correlate` calculates the Pearson correlation coefficient ($r$), the Spearman rank correlation coefficient ($\\rho$), and the Mean Squared Error (MSE) for the positive signal regions: training, validation, and test sets as well as the subsets (val2, val3, test2, and test3).\n",
    "\n",
    "Goal: correlation coefficients ~ 1; MSE ~ 0\n",
    "\n",
    "`negatives` calculates average prediction values (APV) for the inaccessible regions: training, validation, and test sets as well as the subsets (val1 and test1).\n",
    "\n",
    "Goal: APV ~ 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a5fc814d-e80c-40d0-91b7-0f7ee986e06c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def correlate(mhc):\n",
    "    rows = []\n",
    "    # Lists for correlation calculations\n",
    "    groups = ['Train', 'Validation', 'Test', 'Val2', 'Val3', 'Test2', 'Test3']\n",
    "    preds = [pred_trainPos, pred_valPos, pred_testPos, pred_val2_df, pred_val3_df, pred_test2_df, pred_test3_df]\n",
    "    trues = [doubled_trainPos, doubled_valPos, doubled_testPos, doubled_val2_df, doubled_val3_df, doubled_test2_df, doubled_test3_df]\n",
    "\n",
    "    # Calculate correlations\n",
    "    for group, pred_df, true_df in zip(groups, preds, trues):\n",
    "        x = true_df.squeeze()\n",
    "        y = pred_df.squeeze()\n",
    "        pearson, pearson_p = scipy.stats.pearsonr(x, y)\n",
    "        spearman, spearman_p = scipy.stats.spearmanr(x, y)\n",
    "        mse = mean_squared_error(x, y)\n",
    "        pearson_p *= mhc\n",
    "        spearman_p *= mhc\n",
    "        \n",
    "        rows.append({'Group': group, 'Metric': 'Pearson', 'Value': pearson})\n",
    "        rows.append({'Group': group, 'Metric': 'Pearson_p', 'Value': pearson_p})\n",
    "        rows.append({'Group': group, 'Metric': 'Spearman', 'Value': spearman})\n",
    "        rows.append({'Group': group, 'Metric': 'Spearman_p', 'Value': spearman_p})\n",
    "        rows.append({'Group': group, 'Metric': 'MSE', 'Value': mse})\n",
    "          \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def negatives():\n",
    "    rows = []\n",
    "     # Lists for negative average calculations\n",
    "    negGroup = ['Train neg', 'Val neg', 'Test neg', 'Val1 avg pred', 'Test1 avg pred']\n",
    "    negValues = [pred_trainNeg.mean().iloc[0], pred_valNeg.mean().iloc[0], pred_testNeg.mean().iloc[0], pred_val1_df.mean().iloc[0], pred_test1_df.mean().iloc[0]]\n",
    "    \n",
    "    # Add negative value averages\n",
    "    for group, negv in zip(negGroup, negValues):\n",
    "        rows.append({'Group': group, 'Metric': 'Avg Neg Prediction', 'Value': negv})\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e7f760-4eeb-4074-85da-55ccf157b37f",
   "metadata": {},
   "source": [
    "### Declare the species and model lists for evaluation\n",
    "Note that mouse is processed separately since it does not have the evaluation subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "060555c4-47e8-4300-abe6-9b009057d716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: \n",
    "species_list = ['macaque', 'rat', 'cow', 'pig']\n",
    "model_list = ['bdbi7l3n'] # Can list any set of models that are trained on data with same processing strategy (ie. 500bp log-transofrmed signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7eeef5-2611-44c9-a25a-3592fff34a66",
   "metadata": {},
   "source": [
    "### Code for non-mouse species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c794c89a-34b2-4dbc-939c-07bbeec49dd2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>bdbi7l3n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>species</th>\n",
       "      <th>Group</th>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">cow</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">Train</th>\n",
       "      <th>Pearson</th>\n",
       "      <td>0.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pearson_p</th>\n",
       "      <td>0.00e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spearman</th>\n",
       "      <td>0.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spearman_p</th>\n",
       "      <td>0.00e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>2.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">rat</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">Test3</th>\n",
       "      <th>Pearson</th>\n",
       "      <td>0.317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pearson_p</th>\n",
       "      <td>6.76e-47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spearman</th>\n",
       "      <td>0.309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spearman_p</th>\n",
       "      <td>3.72e-44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "model                     bdbi7l3n\n",
       "species Group Metric              \n",
       "cow     Train Pearson        0.406\n",
       "              Pearson_p   0.00e+00\n",
       "              Spearman       0.401\n",
       "              Spearman_p  0.00e+00\n",
       "              MSE             2.27\n",
       "...                            ...\n",
       "rat     Test3 Pearson        0.317\n",
       "              Pearson_p   6.76e-47\n",
       "              Spearman       0.309\n",
       "              Spearman_p  3.72e-44\n",
       "              MSE              1.8\n",
       "\n",
       "[140 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_results = []\n",
    "neg_results = []\n",
    "\n",
    "for species in species_list:\n",
    "    for model in model_list:\n",
    "        model_dir = f'{model}_FINAL'\n",
    "\n",
    "        # Load and process all dfs so correlate() function can access them\n",
    "        #############################################################################\n",
    "\n",
    "        # Load pos and neg TRAIN DFs\n",
    "\n",
    "        # Update the negative training path based on the current species being processed.\n",
    "        # These filenames follow a specific 'nonSpecies_andOthers' naming convention.\n",
    "        negTrainPath = f'/home/azstephe/liverRegression/regression_liver/data/splits/negatives/nonRat_liver_andMacaque_andCow_andPig_TRAIN_500bp.bed'\n",
    "        if species == 'macaque':\n",
    "            negTrainPath = f'/home/azstephe/liverRegression/regression_liver/data/splits/negatives/nonMacaque_liver_andRat_andCow_andPig_TRAIN_500bp.bed'\n",
    "        elif species == 'cow':\n",
    "            negTrainPath = f'/home/azstephe/liverRegression/regression_liver/data/splits/negatives/nonCow_liver_andMacaque_andRat_andPig_TRAIN_500bp.bed'\n",
    "        elif species == 'pig':\n",
    "            negTrainPath = f'/home/azstephe/liverRegression/regression_liver/data/splits/negatives/nonPig_liver_andMacaque_andRat_andCow_TRAIN_500bp.bed'\n",
    "\n",
    "        # Load the model's output (activations) for the entire training set (Pos + Neg).\n",
    "        pred_TRAIN = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_{species}_TRAIN.csv', header=None)\n",
    "\n",
    "        # Load metadata for the Positive and Negative training sets.\n",
    "        # iloc[:,4] extracts the 5th column (signal value) for comparison.\n",
    "        trainPos = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/splits/logPos/{species}_liver_TRAINONLY.narrowPeak', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        trainNeg = pd.read_csv(negTrainPath, header=None, delim_whitespace=True).iloc[:,4]\n",
    "\n",
    "        trainPos_len = 2*len(trainPos)\n",
    "        trainNeg_len = 2*len(trainNeg)\n",
    "        \n",
    "        if len(pred_TRAIN) != trainPos_len+trainNeg_len:\n",
    "            print(f\"ERROR TRAIN ({species}, {model}): predictions are a different length than validation sets\")\n",
    "\n",
    "        # The model generates predictions for both the original sequence and its Reverse Complement (RC).\n",
    "        # To align the original metadata with these predictions, we duplicate each row and interleave \n",
    "        # them so that each sequence index appears twice in a row (e.g., Index 0, 0, 1, 1...).\n",
    "        doubled_trainPos = pd.concat([trainPos, trainPos]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_trainNeg = pd.concat([trainNeg, trainNeg]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "\n",
    "        # Extract the actual predictions from the consolidated model output (pred_TRAIN)\n",
    "        # This assumes pred_TRAIN contains all positive predictions followed by all negative predictions.\n",
    "        pred_trainPos = pred_TRAIN.head(trainPos_len)\n",
    "        pred_trainNeg = pred_TRAIN.tail(trainNeg_len)\n",
    "\n",
    "        #############################################################################\n",
    "\n",
    "        # Load pos and neg VAL DFs\n",
    "\n",
    "        negValPath = f'/home/azstephe/liverRegression/regression_liver/data/splits/negatives/nonRat_liver_andMacaque_andCow_andPig_VAL_500bp.bed'\n",
    "        if species == 'macaque':\n",
    "            negValPath = f'/home/azstephe/liverRegression/regression_liver/data/splits/negatives/nonMacaque_liver_andRat_andCow_andPig_VAL_500bp.bed'\n",
    "        elif species == 'cow':\n",
    "            negValPath = f'/home/azstephe/liverRegression/regression_liver/data/splits/negatives/nonCow_liver_andMacaque_andRat_andPig_VAL_500bp.bed'\n",
    "        elif species == 'pig':\n",
    "            negValPath = f'/home/azstephe/liverRegression/regression_liver/data/splits/negatives/nonPig_liver_andMacaque_andRat_andCow_VAL_500bp.bed'\n",
    "        \n",
    "        pred_VAL_ortho = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_{species}_VAL_orthologs.csv', header=None)\n",
    "        \n",
    "        valPos = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/splits/logPos/{species}_liver_VAL.narrowPeak', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        valNeg = pd.read_csv(negValPath, header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        valPos_len = 2*len(valPos)\n",
    "        valNeg_len = 2*len(valNeg)\n",
    "        \n",
    "        if len(pred_VAL_ortho) != valPos_len+valNeg_len:\n",
    "            print(f\"ERROR VALORTHO ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_valPos = pd.concat([valPos, valPos]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_valNeg = pd.concat([valNeg, valNeg]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_valPos = pred_VAL_ortho.head(valPos_len)\n",
    "        pred_valNeg = pred_VAL_ortho.tail(valNeg_len)\n",
    "\n",
    "        #############################################################################\n",
    "\n",
    "        # Load pos and neg TEST DFs\n",
    "        pred_TEST_ortho = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_{species}_TEST_orthologs.csv', header=None)\n",
    "        \n",
    "        testPos = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_pos_LiuAll/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        testNeg = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/neg/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        testPos_len = 2*len(testPos)\n",
    "        testNeg_len = 2*len(testNeg)\n",
    "        \n",
    "        if len(pred_TEST_ortho) != testPos_len+testNeg_len:\n",
    "            print(f\"ERROR TEST ORTHO ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        doubled_testPos = pd.concat([testPos, testPos]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_testNeg = pd.concat([testNeg, testNeg]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_testPos = pred_TEST_ortho.head(testPos_len)\n",
    "        \n",
    "        pred_testNeg = pred_TEST_ortho.tail(testNeg_len)\n",
    "\n",
    "        #############################################################################\n",
    "        # Load VAL SET 1,2,3 DFs\n",
    "        pred_VAL = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_{species}_VAL.csv', header=None)\n",
    "        \n",
    "        val1_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/val_splits/val1/{species}_liver_VAL_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        val2_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/splits/log_val2/{species}_liver_VAL.narrowPeak', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        val3_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/splits/log_val3/{species}_liver_VAL.narrowPeak', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        val1_len = 2*len(val1_df)\n",
    "        val2_len = 2*len(val2_df)\n",
    "        val3_len = 2*len(val3_df)\n",
    "        \n",
    "        if len(pred_VAL) != val1_len+val2_len+val3_len:\n",
    "            print(f\"ERROR VAL ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_val1_df = pd.concat([val1_df, val1_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_val2_df = pd.concat([val2_df, val2_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_val3_df = pd.concat([val3_df, val3_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_val1_df = pred_VAL.head(val1_len)\n",
    "        pred_val2_df = pred_VAL.iloc[val1_len:val1_len + val2_len]\n",
    "        pred_val3_df = pred_VAL.tail(val3_len)\n",
    "\n",
    "        #############################################################################\n",
    "        # Load TEST SET 1,2,3  DFs\n",
    "        pred_TEST = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_{species}_TEST.csv', header=None)\n",
    "        \n",
    "        test1_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_LiuAll_test1/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        test2_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_test2/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        test3_df = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_test3/{species}_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        test1_len = 2*len(test1_df)\n",
    "        test2_len = 2*len(test2_df)\n",
    "        test3_len = 2*len(test3_df)\n",
    "        \n",
    "        if len(pred_TEST) != test1_len+test2_len+test3_len:\n",
    "            print(f\"ERROR TEST ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_test1_df = pd.concat([test1_df, test1_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_test2_df = pd.concat([test2_df, test2_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_test3_df = pd.concat([test3_df, test3_df]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_test1_df = pred_TEST.head(test1_len)\n",
    "        pred_test2_df = pred_TEST.iloc[test1_len:test1_len + test2_len]\n",
    "        pred_test3_df = pred_TEST.tail(test3_len)\n",
    "\n",
    "        # Call the correlate function which now uses the globally available DFs\n",
    "        corr_df = correlate(MHC)\n",
    "        corr_df['species'] = species\n",
    "        corr_df['model'] = model\n",
    "        all_results.append(corr_df)\n",
    "        \n",
    "        neg_df = negatives()\n",
    "        neg_df['species'] = species\n",
    "        neg_df['model'] = model\n",
    "        neg_results.append(neg_df)\n",
    "\n",
    "# #############################################################################\n",
    "# FINAL PROCESSING\n",
    "# #############################################################################\n",
    "\n",
    "summary_df = pd.concat(all_results)\n",
    "\n",
    "summary_neg_df = pd.concat(neg_results)\n",
    "\n",
    "# Define the custom order to place negative groups at the bottom.\n",
    "custom_group_order = [\n",
    "    'Train', 'Validation', 'Test', 'Val2', 'Val3', 'Test2', 'Test3'\n",
    "]\n",
    "\n",
    "custom_group_order_neg = [\n",
    "    'Train neg', 'Val neg', 'Test neg', 'Val1 avg pred', 'Test1 avg pred'\n",
    "]\n",
    "\n",
    "# Convert 'group' to a categorical type with the specified order.\n",
    "summary_df['Group'] = pd.Categorical(summary_df['Group'], categories=custom_group_order, ordered=True)\n",
    "summary_neg_df['Group'] = pd.Categorical(summary_neg_df['Group'], categories=custom_group_order_neg, ordered=True)\n",
    "\n",
    "\n",
    "# Pivot so each model is a column\n",
    "pivot_df = summary_df.pivot_table(\n",
    "    index=['species', 'Group', 'Metric'],\n",
    "    columns='model',\n",
    "    values='Value'\n",
    ")\n",
    "\n",
    "pivot_neg_df = summary_neg_df.pivot_table(\n",
    "    index=['species', 'Group', 'Metric'],\n",
    "    columns='model',\n",
    "    values='Value'\n",
    ")\n",
    "\n",
    "# Sort the index to maintain custom order\n",
    "pivot_df = pivot_df.sort_index(level=['species', 'Group', 'Metric'])\n",
    "pivot_neg_df = pivot_neg_df.sort_index(level=['species', 'Group', 'Metric'])\n",
    "\n",
    "pivot_df_reordered = pivot_df[model_list]\n",
    "pivot_neg_df_reordered = pivot_neg_df[model_list]\n",
    "\n",
    "metric_vars = ['Pearson', 'Pearson_p', 'Spearman', 'Spearman_p', 'MSE']\n",
    "pivot_df_reordered = pivot_df_reordered.reindex(metric_vars, level='Metric')\n",
    "\n",
    "# Loop through each model's column to apply the formatting\n",
    "for col in pivot_df_reordered.columns:\n",
    "    pivot_df_reordered[col] = pivot_df_reordered.apply(\n",
    "        lambda row: format_value(row.name[2], row[col]),\n",
    "        axis=1)\n",
    "\n",
    "# display(pivot_df_reordered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99373245-1890-483e-b502-f888bddfa6d8",
   "metadata": {},
   "source": [
    "### Helper functions for mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c900d3d7-6447-4533-ba8b-ebf978e6f244",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def correlate_mouse():\n",
    "    rows = []\n",
    "    # Lists for correlation calculations\n",
    "    groups = ['Train', 'Validation', 'Test']\n",
    "    preds = [pred_trainPos, pred_valPos, pred_testPos ]\n",
    "    trues = [doubled_trainPos, doubled_valPos, doubled_testPos]\n",
    "\n",
    "    # Calculate correlations\n",
    "    for group, pred_df, true_df in zip(groups, preds, trues):\n",
    "        x = true_df.squeeze()\n",
    "        y = pred_df.squeeze()\n",
    "        pearson, pearson_p = scipy.stats.pearsonr(x, y)\n",
    "        spearman, spearman_p = scipy.stats.spearmanr(x, y)\n",
    "        mse = mean_squared_error(x, y)\n",
    "        pearson_p *= mhc\n",
    "        spearman_p *= mhc\n",
    "        rows.append({'Group': group, 'Metric': 'Pearson', 'Value': pearson})\n",
    "        rows.append({'Group': group, 'Metric': 'Pearson_p', 'Value': pearson_p})\n",
    "        rows.append({'Group': group, 'Metric': 'Spearman', 'Value': spearman})\n",
    "        rows.append({'Group': group, 'Metric': 'Spearman_p', 'Value': spearman_p})\n",
    "        rows.append({'Group': group, 'Metric': 'MSE', 'Value': mse})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def negatives_mouse():\n",
    "    rows = []\n",
    "     # Lists for negative average calculations\n",
    "    negGroup = ['Val neg', 'Test neg']\n",
    "    negValues = [pred_valNeg.mean().iloc[0], pred_testNeg.mean().iloc[0]]\n",
    "    \n",
    "    # Add negative value averages\n",
    "    for group, negv in zip(negGroup, negValues):\n",
    "        rows.append({'Group': group, 'Metric': 'Avg Neg Prediction', 'Value': negv})\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "16365554-e28c-4587-9ca6-81b071d601a8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "all_results = []\n",
    "neg_results = []\n",
    "species_list = ['mouse']\n",
    "\n",
    "for species in species_list:\n",
    "    for model in model_list:\n",
    "        model_dir = f'{model}_FINAL'\n",
    "        \n",
    "        # load TRAIN VAL DFs\n",
    "        pred_TRAIN_VAL = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_{species}_TRAIN_VAL.csv', header=None)\n",
    "        \n",
    "        trainPos = pd.read_csv('/home/azstephe/liverRegression/regression_liver/data/splits/logPos/mouse_liver_TRAINONLY.narrowPeak', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        valPos = pd.read_csv('/home/azstephe/liverRegression/regression_liver/data/splits/logPos/mouse_liver_VAL.narrowPeak', header=None, delim_whitespace=True).iloc[:,4] \n",
    "        valNeg = pd.read_csv('/home/azstephe/regression_liver/data/splits/negatives/nonMouse_liver_andRat_andCow_andPig_andMacaque_VAL_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "\n",
    "        trainPos_len = 2*len(trainPos)\n",
    "        valPos_len = 2*len(valPos)\n",
    "        valNeg_len = 2*len(valNeg)\n",
    "        \n",
    "        if len(pred_TRAIN_VAL) != trainPos_len+valPos_len+valNeg_len:\n",
    "            print(f\"ERROR TRAIN ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_trainPos = pd.concat([trainPos, trainPos]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_valPos = pd.concat([valPos, valPos]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_valNeg = pd.concat([valNeg, valNeg]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_trainPos = pred_TRAIN_VAL.head(trainPos_len)\n",
    "        pred_valPos = pred_TRAIN_VAL.iloc[trainPos_len:trainPos_len + valPos_len]\n",
    "        pred_valNeg = pred_TRAIN_VAL.tail(valNeg_len)\n",
    "\n",
    "        #############################################################################\n",
    "\n",
    "        # load TEST ORTHO DFs\n",
    "        pred_TEST_ortho = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/model_outputs/{model_dir}/activations_{species}_TEST.csv', header=None)\n",
    "        \n",
    "        testPos = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/log_pos/mouse_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        testNeg = pd.read_csv(f'/home/azstephe/liverRegression/regression_liver/data/test_splits/neg/mouse_liver_TEST_500bp.bed', header=None, delim_whitespace=True).iloc[:,4]\n",
    "        \n",
    "        testPos_len = 2*len(testPos)\n",
    "        testNeg_len = 2*len(testNeg)\n",
    "        \n",
    "        if len(pred_TEST_ortho) != testPos_len+testNeg_len:\n",
    "            print(f\"ERROR TEST ORTHO ({species}, {model}): predictions are a different length than validation sets\")\n",
    "        \n",
    "        doubled_testPos = pd.concat([testPos, testPos]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        doubled_testNeg = pd.concat([testNeg, testNeg]).sort_index(kind='mergesort').reset_index(drop=True)\n",
    "        \n",
    "        pred_testPos = pred_TEST_ortho.head(testPos_len)\n",
    "        pred_testNeg = pred_TEST_ortho.tail(testNeg_len)\n",
    "\n",
    "\n",
    "        # Call the correlate function which now uses the globally available DFs\n",
    "        corr_df = correlate_mouse()\n",
    "        corr_df['species'] = species\n",
    "        corr_df['model'] = model\n",
    "        all_results.append(corr_df)\n",
    "        \n",
    "        neg_df = negatives_mouse()\n",
    "        neg_df['species'] = species\n",
    "        neg_df['model'] = model\n",
    "        neg_results.append(neg_df)\n",
    "        \n",
    "\n",
    "# #############################################################################\n",
    "# FINAL PROCESSING\n",
    "# #############################################################################\n",
    "\n",
    "summary_df = pd.concat(all_results)\n",
    "\n",
    "summary_neg_df = pd.concat(neg_results)\n",
    "\n",
    "# Define the custom order to place negative groups at the bottom.\n",
    "custom_group_order = [\n",
    "    'Train', 'Validation', 'Test'\n",
    "]\n",
    "\n",
    "custom_group_order_neg = [\n",
    "    'Val neg', 'Test neg'\n",
    "]\n",
    "\n",
    "# Convert 'group' to a categorical type with the specified order.\n",
    "summary_df['Group'] = pd.Categorical(summary_df['Group'], categories=custom_group_order, ordered=True)\n",
    "summary_neg_df['Group'] = pd.Categorical(summary_neg_df['Group'], categories=custom_group_order_neg, ordered=True)\n",
    "\n",
    "\n",
    "# Pivot so each model is a column\n",
    "pivot_df = summary_df.pivot_table(\n",
    "    index=['species', 'Group', 'Metric'],\n",
    "    columns='model',\n",
    "    values='Value'\n",
    ")\n",
    "\n",
    "pivot_neg_df = summary_neg_df.pivot_table(\n",
    "    index=['species', 'Group', 'Metric'],\n",
    "    columns='model',\n",
    "    values='Value'\n",
    ")\n",
    "\n",
    "# Sort the index to maintain a logical order (will now use the custom group order)\n",
    "pivot_df = pivot_df.sort_index(level=['species', 'Group', 'Metric'])\n",
    "pivot_neg_df = pivot_neg_df.sort_index(level=['species', 'Group', 'Metric'])\n",
    "\n",
    "pivot_df_reordered_mouse = pivot_df[model_list]\n",
    "pivot_neg_df_reordered_mouse = pivot_neg_df[model_list]\n",
    "\n",
    "metric_vars = ['Pearson', 'Pearson_p', 'Spearman', 'Spearman_p', 'MSE']\n",
    "pivot_df_reordered_mouse = pivot_df_reordered_mouse.reindex(metric_vars, level='Metric')\n",
    "\n",
    "# Loop through each model's column to apply the formatting\n",
    "for col in pivot_df_reordered_mouse.columns:\n",
    "    pivot_df_reordered_mouse[col] = pivot_df_reordered_mouse.apply(\n",
    "        # Access the 'metric' from the index using row.name[2]\n",
    "        # (assuming it's the 3rd level of your index)\n",
    "        lambda row: format_value(row.name[2], row[col]),\n",
    "        axis=1)\n",
    "\n",
    "# display(pivot_df_reordered_mouse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81163401-911e-4447-92fe-1942d787b935",
   "metadata": {},
   "source": [
    "### Clean up final table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3137e75a-4b30-4a93-bb30-80d1507feea3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# concatenate mouse and the rest of the species into one dataframe\n",
    "pos_predictions_eval_df = pd.concat([pivot_df_reordered, pivot_df_reordered_mouse])\n",
    "neg_predictions_eval_df = pd.concat([pivot_neg_df_reordered, pivot_neg_df_reordered_mouse])\n",
    "\n",
    "output_pos_filename = '~/data/tables/pos_log_model_eval_table.tsv'\n",
    "# pos_predictions_eval_df.to_csv(output_pos_filename, sep='\\t', float_format='%.3f')\n",
    "\n",
    "output_neg_filename = '~/data/tables/neg_log_model_eval_table.tsv'\n",
    "# neg_predictions_eval_df.to_csv(output_neg_filename, sep='\\t', float_format='%.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce587fd-4b40-469c-949e-1ef8e7f0031c",
   "metadata": {},
   "source": [
    "### Final Outputs:\n",
    "`~/data/tables/pos_log_model_eval_table.tsv`\n",
    "\n",
    "`~/data/tables/neg_log_model_eval_table.tsv`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
